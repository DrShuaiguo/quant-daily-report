[
  {
    "title": "EXFormer: A Multi-Scale Trend-Aware Transformer with Dynamic Variable Selection for Foreign Exchange Returns Prediction",
    "url": "https://arxiv.org/pdf/2512.12727v1",
    "source": "ArXiv",
    "date": "2025-12-14",
    "abstract": "Accurately forecasting daily exchange rate returns represents a longstanding challenge in international finance, as the exchange rate returns are driven by a multitude of correlated market factors and exhibit high-frequency fluctuations. This paper proposes EXFormer, a novel Transformer-based architecture specifically designed for forecasting the daily exchange rate returns. We introduce a multi-scale trend-aware self-attention mechanism that employs parallel convolutional branches with differing receptive fields to align observations on the basis of local slopes, preserving long-range dependencies while remaining sensitive to regime shifts. A dynamic variable selector assigns time-varying importance weights to 28 exogenous covariates related to exchange rate returns, providing pre-hoc interpretability. An embedded squeeze-and-excitation block recalibrates channel responses to emphasize informative features and depress noise in the forecasting. Using the daily data for EUR/USD, USD/JPY, and GBP/USD, we conduct out-of-sample evaluations across five different sliding windows. EXFormer consistently outperforms the random walk and other baselines, improving directional accuracy by a statistically significant margin of up to 8.5--22.8%. In nearly one year of trading backtests, the model converts these gains into cumulative returns of 18%, 25%, and 18% for the three pairs, with Sharpe ratios exceeding 1.8. When conservative transaction costs and slippage are accounted for, EXFormer retains cumulative returns of 7%, 19%, and 9%, while other baselines achieve negative. The robustness checks further confirm the model's superiority under high-volatility and bear-market regimes. EXFormer furnishes both economically valuable forecasts and transparent, time-varying insights into the drivers of exchange rate dynamics for international investors, corporations, and central bank practitioners.",
    "broker": "Cornell Univ",
    "score": 9,
    "summary": "EXFormer：一种用于外汇收益率预测的多尺度趋势感知Transformer，具有动态变量选择功能。该论文提出了一种新颖的基于Transformer的架构，专门用于预测每日汇率收益率。它引入了多尺度趋势感知自注意力机制，采用具有不同感受野的并行卷积分支，以基于局部斜率对齐观测值，在保持长程依赖性的同时对制度转换保持敏感。动态变量选择器为28个与汇率收益率相关的外生协变量分配时变重要性权重，提供先验可解释性。嵌入的挤压-激励块重新校准通道响应，以强调信息特征并抑制预测中的噪声。使用欧元/美元、美元/日元和英镑/美元的每日数据，在五个不同的滑动窗口上进行了样本外评估。EXFormer始终优于随机游走和其他基线模型，提高了方向准确性。",
    "fetch_date": "2025-12-26",
    "id": "20251226_95743fd6"
  },
  {
    "title": "Stochastic Volatility Modelling with LSTM Networks: A Hybrid Approach for S&P 500 Index Volatility Forecasting",
    "url": "https://arxiv.org/pdf/2512.12250v1",
    "source": "ArXiv",
    "date": "2025-12-13",
    "abstract": "Accurate volatility forecasting is essential in banking, investment, and risk management, because expectations about future market movements directly influence current decisions. This study proposes a hybrid modelling framework that integrates a Stochastic Volatility model with a Long Short Term Memory neural network. The SV model improves statistical precision and captures latent volatility dynamics, especially in response to unforeseen events, while the LSTM network enhances the model's ability to detect complex nonlinear patterns in financial time series. The forecasting is conducted using daily data from the S and P 500 index, covering the period from January 1 1998 to December 31 2024. A rolling window approach is employed to train the model and generate one step ahead volatility forecasts. The performance of the hybrid SV-LSTM model is evaluated through both statistical testing and investment simulations. The results show that the hybrid approach outperforms both the standalone SV and LSTM models and contributes to the development of volatility modelling techniques, providing a foundation for improving risk assessment and strategic investment planning in the context of the S and P 500.",
    "broker": "Cornell Univ",
    "score": 9,
    "summary": "该研究提出了一种混合建模框架，将随机波动率模型与长短期记忆神经网络相结合，用于标普500指数的波动率预测。SV模型提升了统计精度并捕捉了潜在的波动动态，特别是在应对突发事件时；LSTM网络则增强了模型检测金融时间序列中复杂非线性模式的能力。研究采用滚动窗口方法训练模型并生成一步超前波动率预测，通过统计测试和投资模拟评估了混合SV-LSTM模型的性能。结果表明，该混合方法优于单独的SV和LSTM模型，为改进风险评估和战略投资规划提供了基础。",
    "fetch_date": "2025-12-26",
    "id": "20251226_36f39515"
  },
  {
    "title": "Deep Hedging with Reinforcement Learning: A Practical Framework for Option Risk Management",
    "url": "https://arxiv.org/pdf/2512.12420v1",
    "source": "ArXiv",
    "date": "2025-12-13",
    "abstract": "We present a reinforcement-learning (RL) framework for dynamic hedging of equity index option exposures under realistic transaction costs and position limits. We hedge a normalized option-implied equity exposure (one unit of underlying delta, offset via SPY) by trading the underlying index ETF, using the option surface and macro variables only as state information and not as a direct pricing engine. Building on the \"deep hedging\" paradigm of Buehler et al. (2019), we design a leak-free environment, a cost-aware reward function, and a lightweight stochastic actor-critic agent trained on daily end-of-day panel data constructed from SPX/SPY implied volatility term structure, skew, realized volatility, and macro rate context. On a fixed train/validation/test split, the learned policy improves risk-adjusted performance versus no-hedge, momentum, and volatility-targeting baselines (higher point-estimate Sharpe); only the GAE policy's test-sample Sharpe is statistically distinguishable from zero, although confidence intervals overlap with a long-SPY benchmark so we stop short of claiming formal dominance. Turnover remains controlled and the policy is robust to doubled transaction costs. The modular codebase, comprising a data pipeline, simulator, and training scripts, is engineered for extensibility to multi-asset overlays, alternative objectives (e.g., drawdown or CVaR), and intraday data. From a portfolio management perspective, the learned overlay is designed to sit on top of an existing SPX or SPY allocation, improving the portfolio's mean-variance trade-off with controlled turnover and drawdowns. We discuss practical implications for portfolio overlays and outline avenues for future work.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "本文提出了一种基于强化学习的深度对冲框架，用于在现实交易成本和头寸限制下动态管理股指期权风险敞口。该方法采用无泄漏环境设计、成本感知的奖励函数和轻量级随机演员-评论家智能体，使用SPX/SPY隐含波动率期限结构、偏度、已实现波动率和宏观利率等日频面板数据进行训练。在固定训练/验证/测试集划分下，学习到的策略相比无对冲、动量策略和波动率目标基准展现出更高的风险调整后绩效（夏普比率点估计值更高），且交易周转率受控，策略对加倍交易成本具有稳健性。",
    "fetch_date": "2025-12-26",
    "id": "20251226_dfaa45fb"
  },
  {
    "title": "VERAFI: Verified Agentic Financial Intelligence through Neurosymbolic Policy Generation",
    "url": "https://arxiv.org/pdf/2512.14744v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "Financial AI systems suffer from a critical blind spot: while Retrieval-Augmented Generation (RAG) excels at finding relevant documents, language models still generate calculation errors and regulatory violations during reasoning, even with perfect retrieval. This paper introduces VERAFI (Verified Agentic Financial Intelligence), an agentic framework with neurosymbolic policy generation for verified financial intelligence. VERAFI combines state-of-the-art dense retrieval and cross-encoder reranking with financial tool-enabled agents and automated reasoning policies covering GAAP compliance, SEC requirements, and mathematical validation. Our comprehensive evaluation on FinanceBench demonstrates remarkable improvements: while traditional dense retrieval with reranking achieves only 52.4\\% factual correctness, VERAFI's integrated approach reaches 94.7\\%, an 81\\% relative improvement. The neurosymbolic policy layer alone contributes a 4.3 percentage point gain over pure agentic processing, specifically targeting persistent mathematical and logical errors. By integrating financial domain expertise directly into the reasoning process, VERAFI offers a practical pathway toward trustworthy financial AI that meets the stringent accuracy demands of regulatory compliance, investment decisions, and risk management.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "论文《VERAFI：通过神经符号策略生成实现可验证的代理金融智能》针对金融AI系统在推理中产生计算错误和违反监管规定（即使检索完美）的盲点，提出了一个结合神经符号策略生成的代理框架。VERAFI融合了最先进的密集检索与交叉编码器重排序、支持金融工具的代理，以及覆盖GAAP合规性、SEC要求和数学验证的自动化推理策略。在FinanceBench上的综合评估显示显著改进：传统密集检索加重排序仅实现52.4%的事实正确率，而VERAFI的综合方法达到94.7%，相对提升81%。神经符号策略层本身比纯代理处理贡献了4.3个百分点的增益，专门针对持续的数学和逻辑错误。通过将金融领域专业知识直接整合到推理过程中，VERAFI为在实战交易中实现可信赖的金融智能提供了一条实用路径。",
    "fetch_date": "2025-12-26",
    "id": "20251226_b47b6951"
  },
  {
    "title": "Transfer Learning (Il)liquidity",
    "url": "https://arxiv.org/pdf/2512.11731v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "The estimation of the Risk Neutral Density (RND) implicit in option prices is challenging, especially in illiquid markets. We introduce the Deep Log-Sum-Exp Neural Network, an architecture that leverages Deep and Transfer learning to address RND estimation in the presence of irregular and illiquid strikes. We prove key statistical properties of the model and the consistency of the estimator. We illustrate the benefits of transfer learning to improve the estimation of the RND in severe illiquidity conditions through Monte Carlo simulations, and we test it empirically on SPX data, comparing it with popular estimation methods. Overall, our framework shows recovery of the RND in conditions of extreme illiquidity with as few as three option quotes.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "论文《迁移学习（非）流动性》提出了一种用于估计期权价格中隐含风险中性密度（RND）的深度对数求和指数神经网络架构，特别针对非流动性和不规则行权价市场。该模型利用深度学习和迁移学习技术，在极端流动性不足条件下（仅需三个期权报价）仍能有效恢复RND，并通过蒙特卡洛模拟和SPX数据实证验证了其优于传统方法的性能。",
    "fetch_date": "2025-12-26",
    "id": "20251226_f3dbe600"
  },
  {
    "title": "What's the Price of Monotonicity? A Multi-Dataset Benchmark of Monotone-Constrained Gradient Boosting for Credit PD",
    "url": "https://arxiv.org/pdf/2512.17945v1",
    "source": "ArXiv",
    "date": "2025-12-14",
    "abstract": "Financial institutions face a trade-off between predictive accuracy and interpretability when deploying machine learning models for credit risk. Monotonicity constraints align model behavior with domain knowledge, but their performance cost - the price of monotonicity - is not well quantified. This paper benchmarks monotone-constrained versus unconstrained gradient boosting models for credit probability of default across five public datasets and three libraries. We define the Price of Monotonicity (PoM) as the relative change in standard performance metrics when moving from unconstrained to constrained models, estimated via paired comparisons with bootstrap uncertainty. In our experiments, PoM in AUC ranges from essentially zero to about 2.9 percent: constraints are almost costless on large datasets (typically less than 0.2 percent, often indistinguishable from zero) and most costly on smaller datasets with extensive constraint coverage (around 2-3 percent). Thus, appropriately specified monotonicity constraints can often deliver interpretability with small accuracy losses, particularly in large-scale credit portfolios.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "金融机构在部署机器学习模型进行信用风险评估时，面临预测准确性与可解释性之间的权衡。单调性约束使模型行为与领域知识保持一致，但其性能成本——即“单调性的代价”——尚未得到充分量化。本文在五个公共数据集和三个库上，对信用违约概率的单调约束与无约束梯度提升模型进行了基准测试。我们将单调性代价定义为从无约束模型转向约束模型时标准性能指标的相对变化，通过配对比较和自助法不确定性进行估计。实验结果表明，AUC的单调性代价范围从基本为零到约2.9%：在大型数据集上约束几乎无成本（通常低于0.2%，常与零无异），而在约束覆盖广泛的小型数据集上成本最高（约2-3%）。因此，适当指定的单调性约束通常能以较小的准确性损失提供可解释性，特别是在大规模信用组合中。",
    "fetch_date": "2025-12-26",
    "id": "20251226_b992ef93"
  },
  {
    "title": "The Impact of Bitcoin ETF Approval on Bitcoin's Hedging Properties Against Traditional Assets",
    "url": "https://arxiv.org/pdf/2512.12815v1",
    "source": "ArXiv",
    "date": "2025-12-14",
    "abstract": "The approval of the Bitcoin Spot ETF in January 2024 marked a transformative event in cryptocurrency markets, signaling increased institutional adoption and integration into traditional finance. This study examines Bitcoin's changing relationships with traditional assets, including equities, gold, and fiat currencies, following this milestone. Using rolling correlation analysis, Chow tests, and DCC-GARCH models, we found that Bitcoin's correlation with the S\\&P 500 increased significantly post-ETF approval, indicating stronger alignment with equities. Its relationship with gold stabilized near zero, while its correlation with the U.S. Dollar Index remained consistently negative, reflecting its continued independence from fiat currencies. These findings offer insights into Bitcoin's evolving role in portfolios, implications for market stability, and future research opportunities on cryptocurrency integration into traditional financial systems.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "2024年1月比特币现货ETF获批标志着加密货币市场进入机构化与主流金融整合的新阶段。本研究通过滚动相关性分析、邹检验和DCC-GARCH模型，实证分析了该事件后比特币与传统资产（股票、黄金、法币）的动态关系。核心发现：比特币与标普500指数的相关性显著增强，表明其与股票市场联动性提升；与黄金的相关性稳定在零值附近；与美元指数的负相关性持续，保持对法币的独立性。这些结果为投资组合配置、市场稳定性评估及加密货币与传统金融体系融合研究提供了实证依据。",
    "fetch_date": "2025-12-26",
    "id": "20251226_aa031b92"
  },
  {
    "title": "Institutionalizing risk curation in decentralized credit",
    "url": "https://arxiv.org/pdf/2512.11976v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "This paper maps the emerging market for decentralized credit in which ERC 4626 vaults and third-party curators, rather than monolithic lending protocols alone, increasingly determine underwriting and leverage decisions. We show that modular vaults differ in capital utilization, cross-chain and cross asset concentration, and liquidity risk structure. Further, we show that a small set of curators intermediates a disproportionate share of system TVL, exhibits clustered tail co movement, and captures markedly different fee margins despite broadly similar collateral composition. These findings indicate that the main locus of risk in DeFi lending has migrated upward from base protocols, where underwriting is effectively centralized in a single DAO governed parameter set, to a permissionless curator layer in which competing vault managers decide which assets and loans are originated. We argue that this shift requires a corresponding upgrade in transparency standards and outline a simple set of onchain disclosures that would allow users and DAOs to evaluate curator strategies on a comparable, money market style basis.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文研究了去中心化信贷市场中ERC 4626金库和第三方策展人（而非单一借贷协议）日益主导承销和杠杆决策的新兴格局。研究发现模块化金库在资本利用率、跨链跨资产集中度及流动性风险结构方面存在差异，少数策展人中介了不成比例的系统总锁定价值（TVL），表现出聚集性尾部联动，且尽管抵押品构成相似却获得显著不同的费用边际。这表明DeFi借贷的主要风险点已从基础协议（承销权集中于单一DAO治理参数集）上移至无需许可的策展层，由竞争性金库管理者决定资产和贷款的发起。作者主张需相应提升透明度标准，并提出一套简单的链上披露方案，使用户和DAO能以可比的货币市场风格评估策展策略。",
    "fetch_date": "2025-12-26",
    "id": "20251226_470ff790"
  },
  {
    "title": "Empirical Mode Decomposition and Graph Transformation of the MSCI World Index: A Multiscale Topological Analysis for Graph Neural Network Modeling",
    "url": "https://arxiv.org/pdf/2512.12526v1",
    "source": "ArXiv",
    "date": "2025-12-14",
    "abstract": "This study applies Empirical Mode Decomposition (EMD) to the MSCI World index and converts the resulting intrinsic mode functions (IMFs) into graph representations to enable modeling with graph neural networks (GNNs). Using CEEMDAN, we extract nine IMFs spanning high-frequency fluctuations to long-term trends. Each IMF is transformed into a graph using four time-series-to-graph methods: natural visibility, horizontal visibility, recurrence, and transition graphs. Topological analysis shows clear scale-dependent structure: high-frequency IMFs yield dense, highly connected small-world graphs, whereas low-frequency IMFs produce sparser networks with longer characteristic path lengths. Visibility-based methods are more sensitive to amplitude variability and typically generate higher clustering, while recurrence graphs better preserve temporal dependencies. These results provide guidance for designing GNN architectures tailored to the structural properties of decomposed components, supporting more effective predictive modeling of financial time series.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "本研究对MSCI世界指数应用经验模态分解（EMD），将得到的本征模态函数（IMFs）转化为图表示，以便用图神经网络（GNNs）建模。使用CEEMDAN提取了九个IMF，涵盖高频波动到长期趋势。每个IMF通过四种时间序列到图的方法（自然可见性、水平可见性、递归图和转移图）转化为图。拓扑分析显示明显的尺度依赖结构：高频IMF产生密集、高度连接的小世界图，而低频IMF产生更稀疏、特征路径长度更长的网络。基于可见性的方法对振幅变化更敏感，通常产生更高的聚类，而递归图更好地保留了时间依赖性。这些结果为设计针对分解成分结构特性的GNN架构提供了指导，支持更有效的金融时间序列预测建模。",
    "fetch_date": "2025-12-26",
    "id": "20251226_17fa87b6"
  },
  {
    "title": "Explainable Prediction of Economic Time Series Using IMFs and Neural Networks",
    "url": "https://arxiv.org/pdf/2512.12499v1",
    "source": "ArXiv",
    "date": "2025-12-13",
    "abstract": "This study investigates the contribution of Intrinsic Mode Functions (IMFs) derived from economic time series to the predictive performance of neural network models, specifically Multilayer Perceptrons (MLP) and Long Short-Term Memory (LSTM) networks. To enhance interpretability, DeepSHAP is applied, which estimates the marginal contribution of each IMF while keeping the rest of the series intact. Results show that the last IMFs, representing long-term trends, are generally the most influential according to DeepSHAP, whereas high-frequency IMFs contribute less and may even introduce noise, as evidenced by improved metrics upon their removal. Differences between MLP and LSTM highlight the effect of model architecture on feature relevance distribution, with LSTM allocating importance more evenly across IMFs.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "本研究探讨了从经济时间序列中提取的本征模态函数（IMFs）对神经网络模型（特别是多层感知机MLP和长短期记忆网络LSTM）预测性能的贡献。为增强可解释性，应用DeepSHAP方法评估每个IMF的边际贡献，同时保持序列其余部分不变。结果表明，根据DeepSHAP分析，代表长期趋势的最后几个IMF通常最具影响力，而高频IMF贡献较小甚至可能引入噪声——移除这些高频分量后模型指标得到改善。MLP与LSTM之间的差异凸显了模型架构对特征相关性分布的影响，其中LSTM在IMF间的权重分配更为均匀。",
    "fetch_date": "2025-12-26",
    "id": "20251226_b8bacb63"
  },
  {
    "title": "Unified Approach to Portfolio Optimization using the `Gain Probability Density Function' and Applications",
    "url": "https://arxiv.org/pdf/2512.11649v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "This article proposes a unified framework for portfolio optimization (PO), recognizing an object called the `gain probability density function (PDF)' as the fundamental object of the problem from which any objective function could be derived. The gain PDF has the advantage of being 1-dimensional for any given portfolio and thus is easy to visualize and interpret. The framework allows us to naturally incorporate all existing approaches (Markowitz, CVaR-deviation, higher moments...) and represents an interesting basis to develop new approaches. It leads us to propose a method to directly match a target PDF defined by the portfolio manager, giving them maximal control on the PO problem and moving beyond approaches that focus only on expected return and risk. As an example, we develop an application involving a new objective function to control high profits, to be applied after a conventional PO (including expected return and risk criteria) and thus leading to sub-optimality w.r.t. the conventional objective function. We then propose a methodology to quantify a cost associated with this optimality deviation in a common budget unit, providing a meaningful information to portfolio managers. Numerical experiments considering portfolios with energy-producing assets illustrate our approach. The framework is flexible and can be applied to other sectors (financial assets, etc).",
    "broker": "Cornell Univ",
    "score": 5,
    "summary": "本文提出了一种基于“收益概率密度函数（PDF）”的统一投资组合优化框架，该框架将收益PDF视为问题的基本对象，任何目标函数均可从中推导。该PDF具有一维特性，易于可视化和解释，能够自然整合现有方法（如马科维茨、CVaR-偏差、高阶矩等），并为开发新方法提供了基础。文章提出了一种直接匹配投资组合经理定义的目标PDF的方法，使其能超越仅关注预期收益和风险的传统方法，对优化问题实现最大控制。作为示例，文章开发了一种在传统优化后控制高利润的新目标函数应用，这会导致相对于传统目标函数的次优性，并提出了一种以通用预算单位量化这种最优性偏差成本的方法，为投资组合经理提供有意义的信息。",
    "fetch_date": "2025-12-26",
    "id": "20251226_32dbca85"
  },
  {
    "title": "Extending the application of dynamic Bayesian networks in calculating market risk: Standard and stressed expected shortfall",
    "url": "https://arxiv.org/pdf/2512.12334v1",
    "source": "ArXiv",
    "date": "2025-12-13",
    "abstract": "In the last five years, expected shortfall (ES) and stressed ES (SES) have become key required regulatory measures of market risk in the banking sector, especially following events such as the global financial crisis. Thus, finding ways to optimize their estimation is of great importance. We extend the application of dynamic Bayesian networks (DBNs) to the estimation of 10-day 97.5% ES and stressed ES, building on prior work applying DBNs to value at risk. Using the S&P 500 index as a proxy for the equities trading desk of a US bank, we compare the performance of three DBN structure-learning algorithms with several traditional market risk models, using either the normal or the skewed Student's t return distributions. Backtesting shows that all models fail to produce statistically accurate ES and SES forecasts at the 2.5% level, reflecting the difficulty of modeling extreme tail behavior. For ES, the EGARCH(1,1) model (normal) produces the most accurate forecasts, while, for SES, the GARCH(1,1) model (normal) performs best. All distribution-dependent models deteriorate substantially when using the skewed Student's t distribution. The DBNs perform comparably to the historical simulation model, but their contribution to tail prediction is limited by the small weight assigned to their one-day-ahead forecasts within the return distribution. Future research should examine weighting schemes that enhance the influence of forward-looking DBN forecasts on tail risk estimation.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文扩展了动态贝叶斯网络（DBN）在计算市场风险中的应用，用于估计10天97.5%的预期损失（ES）和压力预期损失（SES）。研究以标普500指数为代理，比较了三种DBN结构学习算法与多种传统市场风险模型（使用正态或偏斜t分布）的表现。回测显示，所有模型在2.5%水平下均未能产生统计上准确的ES和SES预测，反映了建模极端尾部行为的困难。对于ES，EGARCH(1,1)模型（正态）预测最准确；对于SES，GARCH(1,1)模型（正态）表现最佳。所有依赖分布的模型在使用偏斜t分布时性能显著下降。DBN的表现与历史模拟法相当。",
    "fetch_date": "2025-12-26",
    "id": "20251226_5b6423f9"
  },
  {
    "title": "Universal Dynamics of Financial Bubbles in Isolated Markets: Evidence from the Iranian Stock Market",
    "url": "https://arxiv.org/pdf/2512.12054v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "Speculative bubbles exhibit common statistical signatures across many financial markets, suggesting the presence of universal underlying mechanisms. We test this hypothesis in the Iranian stock market, an economy that is highly isolated, subject to capital controls, and largely inaccessible to foreign investors. Using the Log-Periodic Power Law Singularity (LPPLS) model, we analyze two major bubble episodes in 2020 and 2023. The estimated critical exponents beta around 0.46 and 0.20 fall within the empirical ranges documented for canonical historical bubbles such as the 1929 DJIA crash and the 2000 Nasdaq episode. The Tehran Stock Exchange displays clear LPPLS hallmarks, including faster-than-exponential price acceleration, log-periodic corrections, and stable estimates of the critical time horizon. These results indicate that endogenous herding, imitation, and positive-feedback dynamics, rather than exogenous shocks, play a dominant role even in politically and economically isolated markets. By showing that an emerging and semi-closed financial system conforms to the same dynamical patterns observed in global markets, this paper provides new empirical support for the universality of bubble dynamics. To the best of our knowledge, it also presents the first systematic LPPLS analysis of bubbles in the Tehran Stock Exchange. The findings highlight the usefulness of LPPLS-based diagnostic tools for monitoring systemic risk in emerging or restricted economies.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文通过应用对数周期幂律奇异性（LPPLS）模型，分析了伊朗股市（一个高度孤立、受资本管制且外国投资者难以进入的市场）在2020年和2023年的两次主要泡沫事件。研究发现，其估算的关键指数β值（约0.46和0.20）与历史上经典泡沫（如1929年道琼斯工业平均指数崩盘和2000年纳斯达克泡沫）的经验范围一致。德黑兰证券交易所显示出清晰的LPPLS特征，包括快于指数的价格加速、对数周期性修正以及关键时间范围的稳定估计。结果表明，即使是在政治和经济上孤立的市场中，内生的羊群效应、模仿行为和正反馈动态，而非外生冲击，也起着主导作用。通过展示一个新兴的半封闭金融体系遵循与全球市场相同的动态模式，该论文为泡沫动力学的普适性提供了新的实证支持。",
    "fetch_date": "2025-12-26",
    "id": "20251226_16dc055e"
  },
  {
    "title": "High-Frequency Analysis of a Trading Game with Transient Price Impact",
    "url": "https://arxiv.org/pdf/2512.11765v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "We study the high-frequency limit of an $n$-trader optimal execution game in discrete time. Traders face transient price impact of Obizhaeva--Wang type in addition to quadratic instantaneous trading costs $θ(ΔX_t)^2$ on each transaction $ΔX_t$. There is a unique Nash equilibrium in which traders choose liquidation strategies minimizing expected execution costs. In the high-frequency limit where the grid of trading dates converges to the continuous interval $[0,T]$, the discrete equilibrium inventories converge at rate $1/N$ to the continuous-time equilibrium of an Obizhaeva--Wang model with additional quadratic costs $\\vartheta_0(ΔX_0)^2$ and $\\vartheta_T(ΔX_T)^2$ on initial and terminal block trades, where $\\vartheta_0=(n-1)/2$ and $\\vartheta_T=1/2$. The latter model was introduced by Campbell and Nutz as the limit of continuous-time equilibria with vanishing instantaneous costs. Our results extend and refine previous results of Schied, Strehle, and Zhang for the particular case $n=2$ where $\\vartheta_0=\\vartheta_T=1/2$. In particular, we show how the coefficients $\\vartheta_0=(n-1)/2$ and $\\vartheta_T=1/2$ arise endogenously in the high-frequency limit: the initial and terminal block costs of the continuous-time model are identified as the limits of the cumulative discrete instantaneous costs incurred over small neighborhoods of $0$ and $T$, respectively, and these limits are independent of $θ>0$. By contrast, when $θ=0$ the discrete-time equilibrium strategies and costs exhibit persistent oscillations and admit no high-frequency limit, mirroring the non-existence of continuous-time equilibria without boundary block costs. Our results show that two different types of trading frictions -- a fine time discretization and small instantaneous costs in continuous time -- have similar regularizing effects and select a canonical model in the limit.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文研究了具有瞬态价格影响的n交易者最优执行博弈的高频极限。交易者面临Obizhaeva-Wang型瞬态价格影响以及每笔交易ΔX_t的二次瞬时交易成本θ(ΔX_t)^2。存在唯一的纳什均衡，交易者选择最小化预期执行成本的清算策略。在高频极限下，离散均衡库存以1/N的速率收敛于具有额外二次成本ϑ_0(ΔX_0)^2和ϑ_T(ΔX_T)^2的Obizhaeva-Wang模型的连续时间均衡，其中ϑ_0=(n-1)/2，ϑ_T=1/2。该结果扩展并改进了先前针对n=2情况的研究。",
    "fetch_date": "2025-12-26",
    "id": "20251226_54f3bc58"
  },
  {
    "title": "Risk Limited Asset Allocation with a Budget Threshold Utility Function and Leptokurtotic Distributions of Returns",
    "url": "https://arxiv.org/pdf/2512.11666v2",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "An analytical solution to single-horizon asset allocation for an investor with a piecewise-linear utility function, called herein the \"budget threshold utility,\" and exogenous position limits is presented. The resulting functional form has a surprisingly simple structure and can be readily interpreted as representing the addition of a simple \"risk cost\" to otherwise frictionless trading.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文针对具有预算阈值效用函数和外部头寸限制的投资者，提出了单期资产配置的解析解。该解具有简洁的结构，可解释为在无摩擦交易基础上增加了简单的“风险成本”。",
    "fetch_date": "2025-12-26",
    "id": "20251226_2daddc47"
  },
  {
    "title": "Sources and Nonlinearity of High Volume Return Premium: An Empirical Study on the Differential Effects of Investor Identity versus Trading Intensity (2020-2024)",
    "url": "https://arxiv.org/pdf/2512.14134v2",
    "source": "ArXiv",
    "date": "2025-12-16",
    "abstract": "Chae and Kang (2019, \\textit{Pacific-Basin Finance Journal}) documented a puzzling Low Volume Return Premium (LVRP) in Korea -- contradicting global High Volume Return Premium (HVRP) evidence. We resolve this puzzle. Using Korean market data (2020-2024), we demonstrate that HVRP exists in Korea but is masked by (1) pooling heterogeneous investor types and (2) using inappropriate intensity normalization. When institutional buying intensity is normalized by market capitalization rather than trading value, a perfect monotonic relationship emerges: highest-conviction institutional buying (Q4) generates +\\institutionLedQFourDayPlusFiftyCAR\\ cumulative abnormal returns over 50 days, while lowest-intensity trades (Q1) yield modest returns (+\\institutionLedQOneDayPlusFiftyCAR). Retail investors exhibit a flat pattern -- their trading generates near-zero returns regardless of conviction level -- confirming the pure noise trader hypothesis. During the Donghak Ant Movement (2020-2021), however, coordinated retail investors temporarily transformed from noise traders to liquidity providers, generating returns comparable to institutional trading. Our findings reconcile conflicting international evidence and demonstrate that detecting informed trading signals requires investor-type decomposition, nonlinear quartile analysis, and conviction-based (market cap) rather than participation-based (trading value) measurement.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "该研究（2020-2024）通过分析韩国市场数据，解决了韩国市场低成交量回报溢价（LVRP）与全球高成交量回报溢价（HVRP）证据相矛盾的谜题。研究发现，当按市值（而非交易额）对机构买入强度进行标准化时，HVRP在韩国市场显现：机构最高确信度买入（Q4）在50天内产生显著累积异常收益（+\\institutionLedQFourDayPlusFiftyCAR），而最低强度交易（Q1）收益较低（+\\institutionLedQOneDayPlusFiftyCAR）。散户交易则呈现平坦模式，收益接近零，符合纯噪声交易者假说；但在东学蚂蚁运动（2020-2021）期间，协调行动的散户暂时转变为流动性提供者，产生与机构相当的收益。研究通过区分投资者身份（机构vs散户）和交易强度标准化方法，调和了国际上的矛盾发现，对实战交易中识别机构驱动信号、优化因子构建具有直接价值。",
    "fetch_date": "2025-12-25",
    "id": "20251225_63fdd5c4"
  },
  {
    "title": "Interpretable Hypothesis-Driven Trading:A Rigorous Walk-Forward Validation Framework for Market Microstructure Signals",
    "url": "https://arxiv.org/pdf/2512.12924v1",
    "source": "ArXiv",
    "date": "2025-12-15",
    "abstract": "We develop a rigorous walk-forward validation framework for algorithmic trading designed to mitigate overfitting and lookahead bias. Our methodology combines interpretable hypothesis-driven signal generation with reinforcement learning and strict out-of-sample testing. The framework enforces strict information set discipline, employs rolling window validation across 34 independent test periods, maintains complete interpretability through natural language hypothesis explanations, and incorporates realistic transaction costs and position constraints. Validating five market microstructure patterns across 100 US equities from 2015 to 2024, the system yields modest annualized returns (0.55%, Sharpe ratio 0.33) with exceptional downside protection (maximum drawdown -2.76%) and market-neutral characteristics (beta = 0.058). Performance exhibits strong regime dependence, generating positive returns during high-volatility periods (0.60% quarterly, 2020-2024) while underperforming in stable markets (-0.16%, 2015-2019). We report statistically insignificant aggregate results (p-value 0.34) to demonstrate a reproducible, honest validation protocol that prioritizes interpretability and extends naturally to advanced hypothesis generators, including large language models. The key empirical finding reveals that daily OHLCV-based microstructure signals require elevated information arrival and trading activity to function effectively. The framework provides complete mathematical specifications and open-source implementation, establishing a template for rigorous trading system evaluation that addresses the reproducibility crisis in quantitative finance research. For researchers, practitioners, and regulators, this work demonstrates that interpretable algorithmic trading strategies can be rigorously validated without sacrificing transparency or regulatory compliance.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "本文提出了一种可解释的假设驱动交易框架，采用严格的向前滚动验证方法，旨在减少过拟合和前瞻性偏差。该框架结合了可解释的假设驱动信号生成与强化学习，并执行严格的样本外测试。方法包括：严格执行信息集纪律、在34个独立测试期进行滚动窗口验证、通过自然语言假设解释保持完全可解释性、纳入实际交易成本和头寸约束。在2015-2024年间对100只美国股票验证五种市场微观结构模式，系统产生适中的年化收益（0.55%，夏普比率0.33），具有出色的下行保护（最大回撤-2.76%）和市场中性特征（beta=0.058）。表现呈现强烈的制度依赖性，在高波动期（2020-2024年，季度收益0.60%）产生正收益，而在稳定市场（2015-2019年，-0.16%）表现不佳。报告统计上不显著的总体结果（p值0.34），以展示一个可重复、诚实的验证协议，优先考虑可解释性。",
    "fetch_date": "2025-12-25",
    "id": "20251225_8db06af9"
  },
  {
    "title": "Deep reinforcement learning for quantitative trading: Challenges and opportunities",
    "url": "https://ieeexplore.ieee.org/abstract/document/9779600/",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… rise of quantitative trading (QT), which refers to automatically generating trading signals with … for more than 70% and 40% of the trading volume in developed markets (eg, USA) and …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文探讨了深度强化学习在量化交易中的应用，量化交易指通过算法自动生成交易信号，在发达市场（如美国）已占据超过70%和40%的交易量。论文分析了深度强化学习在量化交易领域面临的挑战与机遇，对实战交易具有较高参考价值。",
    "fetch_date": "2025-12-25",
    "id": "20251225_e3153d4f"
  },
  {
    "title": "Trademaster: A holistic quantitative trading platform empowered by reinforcement learning",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/b8f6f7f2ba4137124ac976286eacb611-Abstract-Datasets_and_Benchmarks.html",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… As shown in Figure 2, we formulate quantitative trading tasks as a Markov Decision Process (MDP) following a standard RL scenario, where an agent (investor) interacts with an …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "Trademaster是一个基于强化学习的综合性量化交易平台。该研究将量化交易任务建模为马尔可夫决策过程，遵循标准强化学习框架，其中智能体（投资者）与环境交互进行决策。",
    "fetch_date": "2025-12-25",
    "id": "20251225_fe85737d"
  },
  {
    "title": "FinRL: Deep reinforcement learning framework to automate trading in quantitative finance",
    "url": "https://dl.acm.org/doi/abs/10.1145/3490354.3494366",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… In this paper, we present the first open-source framework FinRL as a full pipeline to help quantitative traders overcome the steep learning curve. FinRL is featured with simplicity, …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "本文提出了首个开源框架FinRL，作为一个完整的流程，旨在帮助量化交易员克服陡峭的学习曲线。FinRL以简洁性为特点，利用深度强化学习自动化量化金融中的交易。",
    "fetch_date": "2025-12-25",
    "id": "20251225_f95bf03c"
  },
  {
    "title": "Deep reinforcement learning for quantitative trading",
    "url": "https://ieeexplore.ieee.org/abstract/document/10626209/",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… In this section, we explore the distinctive attributes of Quantitative Trading (QT) and elaborate on the rationale behind framing the entire QT process as a Partially Observable Markov …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文探讨了将深度强化学习应用于量化交易，将整个量化交易过程建模为部分可观测马尔可夫决策过程，具有实战价值。",
    "fetch_date": "2025-12-25",
    "id": "20251225_d085e88f"
  },
  {
    "title": "Reinforcement Learning Framework for Quantitative Trading",
    "url": "https://arxiv.org/abs/2411.07585",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… We investigate how a reinforcement learning agent can utilize financial indicators in specific market conditions and trends to enhance overall trading accuracy. By understanding the …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "本文研究强化学习智能体如何利用特定市场条件和趋势下的金融指标来提升整体交易准确性。通过理解市场动态，该框架旨在优化量化交易策略。",
    "fetch_date": "2025-12-25",
    "id": "20251225_c5574310"
  },
  {
    "title": "Deep reinforcement learning in quantitative algorithmic trading: A review",
    "url": "https://arxiv.org/abs/2106.00123",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… Deep Reinforcement Learning (DRL) agents proved to be to … reinforcement learning in the subdomain of AI in finance, more precisely, automated low-frequency quantitative stock trading…",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "深度强化学习在量化算法交易中的应用综述：该论文聚焦于深度强化学习（DRL）在金融人工智能子领域——特别是自动化低频量化股票交易中的实际应用。研究表明，DRL智能体在该领域展现出潜力，通过结合强化学习与深度学习技术，探索在实战交易中生成阿尔法（Alpha）的策略，具有较高的实践参考价值。",
    "fetch_date": "2025-12-25",
    "id": "20251225_307e048c"
  },
  {
    "title": "Quantitative trading on stock market based on deep reinforcement learning",
    "url": "https://ieeexplore.ieee.org/abstract/document/8851831/",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… intelligence, quantitative trading attracts … reinforcement learning in quantitative trading. A LSTM-based agent is proposed to learn the temporal pattern in data and automatically trades …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文提出了一种基于深度强化学习的股票市场量化交易方法，采用LSTM智能体学习数据中的时序模式，实现自动化交易。",
    "fetch_date": "2025-12-25",
    "id": "20251225_92f14b99"
  },
  {
    "title": "Deep Learning in Quantitative Trading",
    "url": "https://www.cambridge.org/core/elements/deep-learning-in-quantitative-trading/C39DE06D255470F6232BC97E2E5474E7",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… for developing deep learning algorithms for quantitative trading. This … deep learning algorithms to various financial problems. One of the most fundamental tasks in quantitative trading …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文探讨深度学习在量化交易中的应用，重点研究开发深度学习算法以解决金融问题，特别是量化交易中的核心任务。",
    "fetch_date": "2025-12-25",
    "id": "20251225_410d6f5e"
  },
  {
    "title": "Portfolio Optimization for Index Tracking with Constraints on Downside Risk and Carbon Footprint",
    "url": "https://arxiv.org/pdf/2512.21092v1",
    "source": "ArXiv",
    "date": "2025-12-24",
    "abstract": "Historically, financial risk management has mostly addressed risk factors that arise from the financial environment. Climate risks present a novel and significant challenge for companies and financial markets. Investors aiming for avoidance of firms with high carbon footprints require suitable risk measures and portfolio management strategies. This paper presents the construction of decarbonized indices for tracking the S \\& P-500 index of the U.S. stock market, as well as the Indian index NIFTY-50, employing two distinct methodologies and study their performances. These decarbonized indices optimize the portfolio weights by minimizing the mean-VaR and mean-ES and seek to reduce the risk of significant financial losses while still pursuing decarbonization goals. Investors can thereby find a balance between financial performance and environmental responsibilities. Ensuring transparency in the development of these indices will encourage the excluded and under-weighted asset companies to lower their carbon footprints through appropriate action plans. For long-term passive investors, these indices may present a more favourable option than green stocks.",
    "broker": "Cornell Univ",
    "score": 5,
    "summary": "本文提出了两种构建去碳化指数的方法，用于跟踪美国标普500指数和印度NIFTY-50指数。通过最小化均值-风险价值（mean-VaR）和均值-期望损失（mean-ES）来优化投资组合权重，旨在降低重大财务损失风险的同时实现去碳化目标。投资者可借此在财务绩效与环境责任间取得平衡，这些指数为长期被动投资者提供了比绿色股票更优的选择，并可能激励高碳排企业降低碳足迹。",
    "fetch_date": "2025-12-25",
    "id": "20251225_9ee0c108"
  },
  {
    "title": "Reinforcement learning in quantitative trading: A survey",
    "url": "https://www.techrxiv.org/doi/full/10.36227/techrxiv.19303853",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… two concepts on quantitative trading evolved with time along with the emergence of RL. To this end, we devote one section to discuss the literature of quantitative trading with the tools of …",
    "broker": "Google Scholar",
    "score": 5,
    "summary": "该论文是一篇关于强化学习在量化交易中应用的综述性研究，主要梳理了随着强化学习发展而演变的两个量化交易概念，并专门用一节讨论了使用相关工具的量化交易文献。作为综述，它提供了理论框架和文献梳理，但缺乏具体的实战策略、代码实现或可验证的Alpha生成方法，因此对直接实战交易的价值有限，更适合作为理论参考。",
    "fetch_date": "2025-12-25",
    "id": "20251225_c48f4542"
  },
  {
    "title": "Discrete-time asset price bubbles with short sales prohibitions under model uncertainty",
    "url": "https://arxiv.org/pdf/2512.21115v1",
    "source": "ArXiv",
    "date": "2025-12-24",
    "abstract": "In this study, we investigate asset price bubbles in a discrete-time, discrete-state market under model uncertainty and short sales prohibitions. Building on a new fundamental theorem of asset pricing and a superhedging duality in this setting, we introduce a notion of bubble based on a novel definition of the fundamental price, and analyze their types and characterization. We show that two distinct types of bubbles arise, depending on the maturity structure of the asset. For assets with bounded maturity and no dividend payments, the $G$-supermartingale property of prices provides a necessary and sufficient condition for the existence of bubbles. In contrast, when maturity is unbounded, the infi-supermartingale property yields a necessary condition, while the $G$-supermartingale property remains sufficient. Moreover, there is no bubble under a strengthened no dominance condition. As applications, we examine price bubbles for several standard contingent claims. We show that put-call parity generally fails for fundamental prices, whereas it holds for market prices under no dominance assumption. Furthermore, we establish bounds for the fundamental and market prices of American call options in terms of the corresponding European call prices, adjusted by the associated bubble components.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本研究在离散时间、离散状态市场下，结合模型不确定性和卖空禁令，探讨资产价格泡沫。基于该设定下的新基本资产定价定理和超对冲对偶性，我们引入了一种基于新定义的基本价格的泡沫概念，并分析了其类型和特征。研究表明，根据资产的期限结构，会出现两种不同类型的泡沫。对于有界期限且无股息支付的资产，价格的G-上鞅性质为泡沫存在提供了必要且充分条件。相比之下，当期限无界时，infi-上鞅性质产生必要条件，而G-上鞅性质仍为充分条件。此外，在强化的无支配条件下不存在泡沫。作为应用，我们检验了几种标准或有债权的价格泡沫。研究表明，基本价格下的看跌-看涨平价通常不成立，而在无支配假设下市场价格则成立。此外，我们建立了美式看涨期权的基本价格和市场价格的界限。",
    "fetch_date": "2025-12-25",
    "id": "20251225_d9f8f8a4"
  },
  {
    "title": "Implicit Numerical Scheme for the Hamilton-Jacobi-Bellman Quasi-Variational Inequality in the Optimal Market-Making Problem with Alpha Signal",
    "url": "https://arxiv.org/pdf/2512.20850v1",
    "source": "ArXiv",
    "date": "2025-12-24",
    "abstract": "We address the problem of combined stochastic and impulse control for a market maker operating in a limit order book. The problem is formulated as a Hamilton-Jacobi-Bellman quasi-variational inequality (HJBQVI). We propose an implicit time-discretization scheme coupled with a policy iteration algorithm. This approach removes time-step restrictions typical of explicit methods and ensures unconditional stability. Convergence to the unique viscosity solution is established by verifying monotonicity, stability, and consistency conditions and applying the comparison principle.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文针对限价订单簿中的做市商，研究了结合随机控制和脉冲控制的最优做市问题。该问题被表述为Hamilton-Jacobi-Bellman拟变分不等式（HJBQVI）。作者提出了一种隐式时间离散化方案，并结合策略迭代算法。该方法消除了显式方法典型的时间步长限制，确保了无条件稳定性。通过验证单调性、稳定性和一致性条件，并应用比较原理，建立了收敛于唯一黏性解的理论基础。",
    "fetch_date": "2025-12-25",
    "id": "20251225_aea7403d"
  },
  {
    "title": "Fixed-Income Pricing and the Replication of Liabilities",
    "url": "https://arxiv.org/pdf/2512.14662v2",
    "source": "ArXiv",
    "date": "2025-12-16",
    "abstract": "This paper develops a model-free framework for static fixed-income pricing and the replication of liability cash flows. We show that the absence of static arbitrage across a universe of fixed-income instruments is equivalent to the existence of a strictly positive discount curve that reproduces all observed market prices. We then study the replication and super-replication of liabilities and establish conditions ensuring the existence of least-cost super-replicating portfolios, including a rigorous interpretation of swap--repo replication within this static framework. The results provide a unified foundation for discount-curve construction and liability-driven investment, with direct relevance for economic capital assessment and regulatory practice.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文提出了一种无模型的静态固定收益定价框架及负债现金流复制方法。研究表明，固定收益工具间不存在静态套利等价于存在严格为正的贴现曲线能重现所有市场价格。进一步探讨了负债的复制与超复制，建立了确保最低成本超复制组合存在的条件，并对互换-回购复制进行了严谨解释。该结果为贴现曲线构建和负债驱动投资提供了统一理论基础，对经济资本评估和监管实践具有直接参考价值。",
    "fetch_date": "2025-12-25",
    "id": "20251225_63fda1dc"
  },
  {
    "title": "Interpretable Deep Learning for Stock Returns: A Consensus-Bottleneck Asset Pricing Model",
    "url": "https://arxiv.org/pdf/2512.16251v2",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "We introduce the Consensus-Bottleneck Asset Pricing Model (CB-APM), a partially interpretable neural network that replicates the reasoning processes of sell-side analysts by capturing how dispersed investor beliefs are compressed into asset prices through a consensus formation process. By modeling this \"bottleneck\" to summarize firm- and macro-level information, CB-APM not only predicts future risk premiums of U.S. equities but also links belief aggregation to expected returns in a structurally interpretable manner. The model improves long-horizon return forecasts and outperforms standard deep learning approaches in both predictive accuracy and explanatory power. Comprehensive portfolio analyses show that CB-APM's out-of-sample predictions translate into economically meaningful payoffs, with monotonic return differentials and stable long-short performance across regularization settings. Empirically, CB-APM leverages consensus as a regularizer to amplify long-horizon predictability and yields interpretable consensus-based components that clarify how information is priced in returns. Moreover, regression and Gibbons-Ross-Shanken (GRS)-based pricing diagnostics reveal that the learned consensus representations capture priced variation only partially spanned by traditional factor models, demonstrating that CB-APM uncovers belief-driven structure in expected returns beyond the canonical factor space. Overall, CB-APM provides an interpretable and empirically grounded framework for understanding belief-driven return dynamics.",
    "broker": "Cornell Univ",
    "score": 9,
    "summary": "我们提出了共识瓶颈资产定价模型（CB-APM），这是一种部分可解释的神经网络，通过捕捉分散的投资者信念如何通过共识形成过程压缩为资产价格，来复制卖方分析师推理过程。该模型通过建模这一“瓶颈”来汇总公司和宏观层面的信息，不仅预测美国股票的未来风险溢价，还在结构上以可解释的方式将信念聚合与预期回报联系起来。CB-APM改进了长期回报预测，在预测准确性和解释力方面均优于标准深度学习方法。全面的投资组合分析表明，CB-APM的样本外预测转化为具有经济意义的回报，具有单调的回报差异和跨正则化设置的稳定多空表现。实证上，CB-APM利用共识作为正则化器来增强长期可预测性，并产生基于共识的可解释组件，阐明信息如何在回报中定价。此外，回归和基于Gibbons-Ross-Shanken（GRS）的定价诊断揭示了所学内容。",
    "fetch_date": "2025-12-24",
    "id": "20251224_da05e7f2"
  },
  {
    "title": "Reinforcement learning for quantitative trading",
    "url": "https://dl.acm.org/doi/abs/10.1145/3582560",
    "source": "Scholar",
    "date": "2025-12-24",
    "abstract": "… we used are reinforcement learning, quantitative finance, algorithmic trading, portfolio … a brief overview of financial markets and quantitative trading. Then, we introduce the preliminaries …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文探讨了强化学习在量化交易中的应用，涵盖量化金融、算法交易和投资组合管理等领域。文章首先概述了金融市场和量化交易的基本概念，随后介绍了强化学习的理论基础及其在交易策略优化中的实际应用。",
    "fetch_date": "2025-12-24",
    "id": "20251224_3a476d40"
  },
  {
    "title": "Adaptive quantitative trading: An imitative deep reinforcement learning approach",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5587",
    "source": "Scholar",
    "date": "2025-12-24",
    "abstract": "… mathematical symbols then formally introduce the quantitative trading problem in detail. … always the goal of quantitative traders. This further proves that our trading agent can benefit from …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "《自适应量化交易：一种模仿深度强化学习方法》提出了一种基于深度强化学习的交易代理，能够从市场数据中学习并自适应调整交易策略。该方法通过模仿学习结合强化学习框架，旨在实现持续盈利这一量化交易的核心目标。论文表明该交易代理能够从历史数据中受益并优化交易决策，具有较高的实战应用潜力。",
    "fetch_date": "2025-12-24",
    "id": "20251224_766e09bf"
  },
  {
    "title": "Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems",
    "url": "https://arxiv.org/pdf/2512.18317v1",
    "source": "ArXiv",
    "date": "2025-12-20",
    "abstract": "This paper presents a trustworthy reinforcement learning approach for the control of industrial compressed air systems. We develop a framework that enables safe and energy-efficient operation under realistic boundary conditions and introduce a multi-level explainability pipeline combining input perturbation tests, gradient-based sensitivity analysis, and SHAP (SHapley Additive exPlanations) feature attribution. An empirical evaluation across multiple compressor configurations shows that the learned policy is physically plausible, anticipates future demand, and consistently respects system boundaries. Compared to the installed industrial controller, the proposed approach reduces unnecessary overpressure and achieves energy savings of approximately 4\\,\\% without relying on explicit physics models. The results further indicate that system pressure and forecast information dominate policy decisions, while compressor-level inputs play a secondary role. Overall, the combination of efficiency gains, predictive behavior, and transparent validation supports the trustworthy deployment of reinforcement learning in industrial energy systems.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文提出了一种可信赖的强化学习方法，用于工业压缩空气系统的控制。该框架能够在实际边界条件下实现安全、节能的运行，并引入了结合输入扰动测试、基于梯度的敏感性分析和SHAP（Shapley Additive exPlanations）特征归因的多层次可解释性管道。对多种压缩机配置的实证评估表明，学习到的策略在物理上是合理的，能够预测未来需求，并始终尊重系统边界。与已安装的工业控制器相比，所提出的方法减少了不必要的过压，在不依赖显式物理模型的情况下实现了约4%的节能。结果进一步表明，系统压力和预测信息主导了策略决策，而压缩机级别的输入则起次要作用。总体而言，效率提升、预测行为和透明验证的结合支持了强化学习在工业能源系统中的可信赖部署。",
    "fetch_date": "2025-12-24",
    "id": "20251224_4eec8973"
  },
  {
    "title": "Asymptotic and finite-sample distributions of one- and two-sample empirical relative entropy, with application to change-point detection",
    "url": "https://arxiv.org/pdf/2512.16411v1",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "Relative entropy, as a divergence metric between two distributions, can be used for offline change-point detection and extends classical methods that mainly rely on moment-based discrepancies. To build a statistical test suitable for this context, we study the distribution of empirical relative entropy and derive several types of approximations: concentration inequalities for finite samples, asymptotic distributions, and Berry-Esseen bounds in a pre-asymptotic regime. For the latter, we introduce a new approach to obtain Berry-Esseen inequalities for nonlinear functions of sum statistics under some convexity assumptions. Our theoretical contributions cover both one- and two-sample empirical relative entropies. We then detail a change-point detection procedure built on relative entropy and compare it, through extensive simulations, with classical methods based on moments or on information criteria. Finally, we illustrate its practical relevance on two real datasets involving temperature series and volatility of stock indices.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文研究了经验相对熵的分布，推导了有限样本的集中不等式、渐近分布以及前渐近状态下的Berry-Esseen界，并提出了一种基于相对熵的变点检测方法。通过模拟和真实数据（包括股票指数波动率）验证了该方法相对于基于矩或信息准则的传统方法的实用性。",
    "fetch_date": "2025-12-24",
    "id": "20251224_c7720f56"
  },
  {
    "title": "Design of a Decentralized Fixed-Income Lending Automated Market Maker Protocol Supporting Arbitrary Maturities",
    "url": "https://arxiv.org/pdf/2512.16080v1",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "In decentralized finance (DeFi), designing fixed-income lending automated market makers (AMMs) is extremely challenging due to time-related complexities. Moreover, existing protocols only support single-maturity lending. Building upon the BondMM protocol, this paper argues that its mathematical invariants are sufficiently elegant to be generalized to arbitrary maturities. This paper thus propose an improved design, BondMM-A, which supports lending activities of any maturity. By integrating fixed-income instruments of varying maturities into a single smart contract, BondMM-A offers users and liquidity providers (LPs) greater operational freedom and capital efficiency. Experimental results show that BondMM-A performs excellently in terms of interest rate stability and financial robustness.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "在去中心化金融（DeFi）中，由于时间相关的复杂性，设计固定收益借贷自动做市商（AMM）极具挑战性。现有协议仅支持单一期限借贷。本文基于BondMM协议，论证其数学不变量足够优雅，可推广至任意期限。因此，本文提出改进设计BondMM-A，支持任何期限的借贷活动。通过将不同期限的固定收益工具整合到单一智能合约中，BondMM-A为用户和流动性提供者（LPs）提供更大的操作自由和资本效率。实验结果表明，BondMM-A在利率稳定性和金融稳健性方面表现优异。",
    "fetch_date": "2025-12-24",
    "id": "20251224_c04304c9"
  },
  {
    "title": "Multi-Objective Bayesian Optimization of Deep Reinforcement Learning for Environmental, Social, and Governance (ESG) Financial Portfolio Management",
    "url": "https://arxiv.org/pdf/2512.14992v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "DRL agents circumvent the issue of classic models in the sense that they do not make assumptions like the financial returns being normally distributed and are able to deal with any information like the ESG score if they are configured to gain a reward that makes an objective better. However, the performance of DRL agents has high variability and it is very sensible to the value of their hyperparameters. Bayesian optimization is a class of methods that are suited to the optimization of black-box functions, that is, functions whose analytical expression is unknown, are noisy and expensive to evaluate. The hyperparameter tuning problem of DRL algorithms perfectly suits this scenario. As training an agent just for one objective is a very expensive period, requiring millions of timesteps, instead of optimizing an objective being a mixture of a risk-performance metric and an ESG metric, we choose to separate the objective and solve the multi-objective scenario to obtain an optimal Pareto set of portfolios representing the best tradeoff between the Sharpe ratio and the ESG mean score of the portfolio and leaving to the investor the choice of the final portfolio. We conducted our experiments using environments encoded within the OpenAI Gym, adapted from the FinRL platform. The experiments are carried out in the Dow Jones Industrial Average (DJIA) and the NASDAQ markets in terms of the Sharpe ratio achieved by the agent and the mean ESG score of the portfolio. We compare the performance of the obtained Pareto sets in hypervolume terms illustrating how portfolios are the best trade-off between the Sharpe ratio and mean ESG score. Also, we show the usefulness of our proposed methodology by comparing the obtained hypervolume with one achieved by a Random Search methodology on the DRL hyperparameter space.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文提出了一种用于环境、社会和治理（ESG）金融投资组合管理的多目标贝叶斯优化深度强化学习方法。深度强化学习（DRL）代理无需假设金融收益服从正态分布，并能处理ESG评分等信息，但其性能对超参数高度敏感。贝叶斯优化适用于优化黑盒函数，DRL的超参数调优正符合此场景。由于单目标训练成本高昂（需数百万时间步），作者将目标分离，通过多目标优化获得代表夏普比率与投资组合ESG平均评分之间最佳权衡的帕累托最优投资组合集，最终由投资者选择具体组合。",
    "fetch_date": "2025-12-24",
    "id": "20251224_e237fd82"
  },
  {
    "title": "Systemic Risk Radar: A Multi-Layer Graph Framework for Early Market Crash Warning",
    "url": "https://arxiv.org/pdf/2512.17185v1",
    "source": "ArXiv",
    "date": "2025-12-19",
    "abstract": "Financial crises emerge when structural vulnerabilities accumulate across sectors, markets, and investor behavior. Predicting these systemic transitions is challenging because they arise from evolving interactions between market participants, not isolated price movements alone. We present Systemic Risk Radar (SRR), a framework that models financial markets as multi-layer graphs to detect early signs of systemic fragility and crash-regime transitions.\n  We evaluate SRR across three major crises: the Dot-com crash, the Global Financial Crisis, and the COVID-19 shock. Our experiments compare snapshot GNNs, a simplified temporal GNN prototype, and standard baselines (logistic regression and Random Forest). Results show that structural network information provides useful early-warning signals compared to feature-based models alone.\n  This correlation-based instantiation of SRR demonstrates that graph-derived features capture meaningful changes in market structure during stress events. The findings motivate extending SRR with additional graph layers (sector/factor exposure, sentiment) and more expressive temporal architectures (LSTM/GRU or Transformer encoders) to better handle diverse crisis types.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "《系统性风险雷达：用于早期市场崩盘预警的多层图框架》提出了一种将金融市场建模为多层图以检测系统性脆弱性和崩盘状态转换早期迹象的框架。该研究评估了SRR在互联网泡沫、全球金融危机和COVID-19冲击三个重大危机中的表现，实验表明结构网络信息相比纯特征模型能提供更有用的早期预警信号。虽然该框架展示了图衍生特征在压力事件期间捕捉市场结构有意义变化的能力，但当前实现主要基于相关性分析，属于理论验证阶段。论文建议通过添加更多图层（行业/因子暴露、情绪）和更强大的时序架构（LSTM/GRU或Transformer编码器）来扩展SRR，这为实战交易系统开发提供了有价值的理论框架和方向指引。",
    "fetch_date": "2025-12-24",
    "id": "20251224_7b111b14"
  },
  {
    "title": "An Efficient Machine Learning Framework for Option Pricing via Fourier Transform",
    "url": "https://arxiv.org/pdf/2512.16115v1",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "The increasing need for rapid recalibration of option pricing models in dynamic markets places stringent computational demands on data generation and valuation algorithms. In this work, we propose a hybrid algorithmic framework that integrates the smooth offset algorithm (SOA) with supervised machine learning models for the fast pricing of multiple path-independent options under exponential Lévy dynamics. Building upon the SOA-generated dataset, we train neural networks, random forests, and gradient boosted decision trees to construct surrogate pricing operators. Extensive numerical experiments demonstrate that, once trained, these surrogates achieve order-of-magnitude acceleration over direct SOA evaluation. Importantly, the proposed framework overcomes key numerical limitations inherent to fast Fourier transform-based methods, including the consistency of input data and the instability in deep out-of-the-money option pricing.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "动态市场中期权定价模型快速重新校准的需求日益增长，这对数据生成和估值算法提出了严格的计算要求。本文提出了一种混合算法框架，将平滑偏移算法（SOA）与监督机器学习模型相结合，用于在指数Lévy动态下快速定价多种路径无关期权。基于SOA生成的数据集，我们训练神经网络、随机森林和梯度提升决策树来构建替代定价算子。大量数值实验表明，一旦训练完成，这些替代模型相比直接SOA评估实现了数量级的加速。重要的是，所提出的框架克服了基于快速傅里叶变换方法固有的关键数值限制，包括输入数据的一致性和深度虚值期权定价的不稳定性。",
    "fetch_date": "2025-12-24",
    "id": "20251224_21c43b5a"
  },
  {
    "title": "SigMA: Path Signatures and Multi-head Attention for Learning Parameters in fBm-driven SDEs",
    "url": "https://arxiv.org/pdf/2512.15088v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "Stochastic differential equations (SDEs) driven by fractional Brownian motion (fBm) are increasingly used to model systems with rough dynamics and long-range dependence, such as those arising in quantitative finance and reliability engineering. However, these processes are non-Markovian and lack a semimartingale structure, rendering many classical parameter estimation techniques inapplicable or computationally intractable beyond very specific cases. This work investigates two central questions: (i) whether integrating path signatures into deep learning architectures can improve the trade-off between estimation accuracy and model complexity, and (ii) what constitutes an effective architecture for leveraging signatures as feature maps. We introduce SigMA (Signature Multi-head Attention), a neural architecture that integrates path signatures with multi-head self-attention, supported by a convolutional preprocessing layer and a multilayer perceptron for effective feature encoding. SigMA learns model parameters from synthetically generated paths of fBm-driven SDEs, including fractional Brownian motion, fractional Ornstein-Uhlenbeck, and rough Heston models, with a particular focus on estimating the Hurst parameter and on joint multi-parameter inference, and it generalizes robustly to unseen trajectories. Extensive experiments on synthetic data and two real-world datasets (i.e., equity-index realized volatility and Li-ion battery degradation) show that SigMA consistently outperforms CNN, LSTM, vanilla Transformer, and Deep Signature baselines in accuracy, robustness, and model compactness. These results demonstrate that combining signature transforms with attention-based architectures provides an effective and scalable framework for parameter inference in stochastic systems with rough or persistent temporal structure.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "该论文提出SigMA（Signature Multi-head Attention）神经网络架构，将路径签名与多头自注意力机制结合，用于学习分数布朗运动驱动的随机微分方程参数。该方法针对具有粗糙动态和长程依赖的系统建模，如量化金融中的分数布朗运动、分数Ornstein-Uhlenbeck和粗糙Heston模型。研究聚焦于通过合成生成路径进行参数估计，探讨路径签名在深度学习架构中如何平衡估计精度与模型复杂度。",
    "fetch_date": "2025-12-24",
    "id": "20251224_a46aba2c"
  },
  {
    "title": "Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes",
    "url": "https://arxiv.org/pdf/2512.14991v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "We study reinforcement learning for controlled diffusion processes with unbounded continuous state spaces, bounded continuous actions, and polynomially growing rewards: settings that arise naturally in finance, economics, and operations research. To overcome the challenges of continuous and high-dimensional domains, we introduce a model-based algorithm that adaptively partitions the joint state-action space. The algorithm maintains estimators of drift, volatility, and rewards within each partition, refining the discretization whenever estimation bias exceeds statistical confidence. This adaptive scheme balances exploration and approximation, enabling efficient learning in unbounded domains. Our analysis establishes regret bounds that depend on the problem horizon, state dimension, reward growth order, and a newly defined notion of zooming dimension tailored to unbounded diffusion processes. The bounds recover existing results for bounded settings as a special case, while extending theoretical guarantees to a broader class of diffusion-type problems. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "本文研究针对具有无界连续状态空间、有界连续动作和多项式增长奖励的受控扩散过程的强化学习——这些设定自然出现在金融、经济和运筹学中。为克服连续高维领域的挑战，我们提出一种基于模型的算法，自适应地划分联合状态-动作空间。该算法在每个分区内维护漂移、波动率和奖励的估计器，并在估计偏差超过统计置信度时细化离散化。这种自适应方案平衡了探索与近似，使得在无界域中高效学习成为可能。我们的分析建立了遗憾界，其依赖于问题时域、状态维度、奖励增长阶数以及为无界扩散过程定制的新定义的“缩放维度”概念。这些界限将现有有界设定结果作为特例恢复，同时将理论保证扩展到更广泛的扩散类问题。最后，我们通过数值实验验证了方法的有效性，包括在高维问题中的应用。",
    "fetch_date": "2025-12-24",
    "id": "20251224_140ee511"
  },
  {
    "title": "Modelling financial time series with $φ^{4}$ quantum field theory",
    "url": "https://arxiv.org/pdf/2512.17225v1",
    "source": "ArXiv",
    "date": "2025-12-19",
    "abstract": "We use a $φ^{4}$ quantum field theory with inhomogeneous couplings and explicit symmetry-breaking to model an ensemble of financial time series from the S$\\&$P 500 index. The continuum nature of the $φ^4$ theory avoids the inaccuracies that occur in Ising-based models which require a discretization of the time series. We demonstrate this using the example of the 2008 global financial crisis. The $φ^{4}$ quantum field theory is expressive enough to reproduce the higher-order statistics such as the market kurtosis, which can serve as an indicator of possible market shocks. Accurate reproduction of high kurtosis is absent in binarized models. Therefore Ising models, despite being widely employed in econophysics, are incapable of fully representing empirical financial data, a limitation not present in the generalization of the $φ^{4}$ scalar field theory. We then investigate the scaling properties of the $φ^{4}$ machine learning algorithm and extract exponents which govern the behavior of the learned couplings (or weights and biases in ML language) in relation to the number of stocks in the model. Finally, we use our model to forecast the price changes of the AAPL, MSFT, and NVDA stocks. We conclude by discussing how the $φ^{4}$ scalar field theory could be used to build investment strategies and the possible intuitions that the QFT operations of dimensional compactification and renormalization can provide for financial modelling.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文使用具有非均匀耦合和显式对称性破缺的φ⁴量子场论来建模标普500指数中的金融时间序列集合。与需要离散化时间序列的伊辛模型相比，φ⁴理论的连续性质避免了不准确性，并能重现高阶统计量（如市场峰度），可作为市场冲击的指标。论文还研究了φ⁴机器学习算法的标度特性，并提取了控制学习耦合（或ML中的权重和偏置）与模型中股票数量关系的指数。最后，使用该模型预测了AAPL、MSFT和NVDA股票的价格变化。",
    "fetch_date": "2025-12-24",
    "id": "20251224_1cb49c57"
  },
  {
    "title": "Global universal approximation with Brownian signatures",
    "url": "https://arxiv.org/pdf/2512.16396v1",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "We establish $L^p$-type universal approximation theorems for general and non-anticipative functionals on suitable rough path spaces, showing that linear functionals acting on signatures of time-extended rough paths are dense with respect to an $L^p$-distance. To that end, we derive global universal approximation theorems for weighted rough path spaces. We demonstrate that these $L^p$-type universal approximation theorems apply in particular to Brownian motion. As a consequence, linear functionals on the signature of the time-extended Brownian motion can approximate any $p$-integrable stochastic process adapted to the Brownian filtration, including solutions to stochastic differential equations.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文在加权粗糙路径空间上建立了L^p型全局通用逼近定理，证明了对时间扩展粗糙路径的签名进行线性泛函作用在L^p距离意义下是稠密的。特别地，这些定理适用于布朗运动，因此布朗运动时间扩展签名的线性泛函可以逼近任何适应于布朗滤波的p可积随机过程，包括随机微分方程的解。",
    "fetch_date": "2025-12-24",
    "id": "20251224_94b3ca35"
  },
  {
    "title": "Adaptive Weighted Genetic Algorithm-Optimized SVR for Robust Long-Term Forecasting of Global Stock Indices for investment decisions",
    "url": "https://arxiv.org/pdf/2512.15113v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "Long-term price forecasting remains a formidable challenge due to the inherent uncertainty over the long term, despite some success in short-term predictions. Nonetheless, accurate long-term forecasts are essential for high-net-worth individuals, institutional investors, and traders. The proposed improved genetic algorithm-optimized support vector regression (IGA-SVR) model is specifically designed for long-term price prediction of global indices. The performance of the IGA-SVR model is rigorously evaluated and compared against the state-of-the-art baseline models, the Long Short-Term Memory (LSTM), and the forward-validating genetic algorithm optimized support vector regression (OGA-SVR). Extensive testing was conducted on the five global indices, namely Nifty, Dow Jones Industrial Average (DJI), DAX Performance Index (DAX), Nikkei 225 (N225), and Shanghai Stock Exchange Composite Index (SSE) from 2021 to 2024 of daily price prediction up to a year. Overall, the proposed IGA-SVR model achieved a reduction in MAPE by 19.87% compared to LSTM and 50.03% compared to OGA-SVR, demonstrating its superior performance in long-term daily price forecasting of global indices. Further, the execution time for LSTM was approximately 20 times higher than that of IGA-SVR, highlighting the high accuracy and computational efficiency of the proposed model. The genetic algorithm selects the optimal hyperparameters of SVR by minimizing the arithmetic mean of the Mean Absolute Percentage Error (MAPE) calculated over the full training dataset and the most recent five years of training data. This purposefully designed training methodology adjusts for recent trends while retaining long-term trend information, thereby offering enhanced generalization compared to the LSTM and rolling-forward validation approach employed by OGA-SVR, which forgets long-term trends and suffers from recency bias.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文提出了一种改进的遗传算法优化支持向量回归（IGA-SVR）模型，专门用于全球股票指数的长期价格预测。在2021年至2024年期间，对Nifty、道琼斯工业平均指数（DJI）、DAX绩效指数（DAX）、日经225指数（N225）和上证综合指数（SSE）等五个全球指数进行了长达一年的每日价格预测测试。结果表明，与LSTM和OGA-SVR相比，IGA-SVR模型在平均绝对百分比误差（MAPE）上分别降低了19.87%和50.03%，显示出其在长期预测中的优越性能。",
    "fetch_date": "2025-12-24",
    "id": "20251224_b3187dce"
  },
  {
    "title": "Arbitrage-Free Pricing with Diffusion-Dependent Jumps",
    "url": "https://arxiv.org/pdf/2512.15071v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "Standard jump-diffusion models assume independence between jumps and diffusion components. We develop a multi-type jump-diffusion model where jump occurrence and magnitude depend on contemporaneous diffusion movements. Unlike previous one-sided models that create arbitrage opportunities, our framework includes upward and downward jumps triggered by both large upward and large downward diffusion increments. We derive the explicit no-arbitrage condition linking the physical drift to model parameters and market risk premia by constructing an Equivalent Martingale Measure using Girsanov's theorem and a normalized Esscher transform. This condition provides a rigorous foundation for arbitrage-free pricing in models with diffusion-dependent jumps.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "标准跳跃扩散模型假设跳跃与扩散成分相互独立。本文开发了一种多类型跳跃扩散模型，其中跳跃的发生和幅度取决于同期的扩散运动。与以往可能产生套利机会的单边模型不同，我们的框架包含由大幅向上和向下扩散增量触发的向上和向下跳跃。通过使用Girsanov定理和归一化Esscher变换构建等价鞅测度，我们推导出将物理漂移与模型参数及市场风险溢价联系起来的明确无套利条件。该条件为具有扩散依赖跳跃的模型中的无套利定价提供了严格基础。",
    "fetch_date": "2025-12-24",
    "id": "20251224_33dbfdbc"
  },
  {
    "title": "Optimal Signal Extraction from Order Flow: A Matched Filter Perspective on Normalization and Market Microstructure",
    "url": "https://arxiv.org/pdf/2512.18648v1",
    "source": "ArXiv",
    "date": "2025-12-21",
    "abstract": "We demonstrate that the choice of normalization for order flow intensity is fundamental to signal extraction in finance, not merely a technical detail. Through theoretical modeling, Monte Carlo simulation, and empirical validation using Korean market data, we prove that market capitalization normalization acts as a ``matched filter'' for informed trading signals, achieving 1.32--1.97$\\times$ higher correlation with future returns compared to traditional trading value normalization. The key insight is that informed traders scale positions by firm value (market capitalization), while noise traders respond to daily liquidity (trading volume), creating heteroskedastic corruption when normalizing by trading volume. By reframing the normalization problem using signal processing theory, we show that dividing order flow by market capitalization preserves the information signal while traditional volume normalization multiplies the signal by inverse turnover -- a highly volatile quantity. Our theoretical predictions are robust across parameter specifications and validated by empirical evidence showing 482\\% improvement in explanatory power. These findings have immediate implications for high-frequency trading algorithms, risk factor construction, and information-based trading strategies.",
    "broker": "Cornell Univ",
    "score": 9,
    "summary": "本文论证了订单流强度归一化方法的选择对信号提取至关重要，而不仅仅是技术细节。通过理论建模、蒙特卡洛模拟和韩国市场数据的实证验证，证明市值归一化可作为知情交易信号的“匹配滤波器”，相比传统的交易额归一化，与未来收益的相关性提高1.32-1.97倍。核心观点是：知情交易者按公司价值（市值）调整头寸，而噪声交易者则响应日流动性（交易量），使用交易量归一化会导致异方差干扰。通过信号处理理论重新构建归一化问题，发现除以市值能保留信息信号，而传统的交易量归一化会将信号乘以逆换手率——一个高度波动的变量。理论预测在不同参数设定下均稳健，实证证据显示解释力提升482%。这些发现对高频交易、算法交易和风险模型具有直接应用价值。",
    "fetch_date": "2025-12-24",
    "id": "20251224_eb1783a9"
  },
  {
    "title": "Switching between states and the COVID-19 turbulence",
    "url": "https://arxiv.org/pdf/2512.20477v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "In Aarab (2020), I examine U.S. stock return predictability across economic regimes and document evidence of time-varying expected returns across market states in the long run. The analysis introduces a state-switching specification in which the market state is proxied by the slope of the yield curve, and proposes an Aligned Economic Index built from the popular predictors of Welch and Goyal (2008) (augmented with bond and equity premium measures). The Aligned Economic Index under the state-switching model exhibits statistically and economically meaningful in-sample ($R^2 = 5.9\\%$) and out-of-sample ($R^2_{\\text{oos}} = 4.12\\%$) predictive power across both recessions and expansions, while outperforming a range of widely used predictors. In this work, I examine the added value for professional practitioners by computing the economic gains for a mean-variance investor and find substantial added benefit of using the new index under the state switching model across all market states. The Aligned Economic Index can thus be implemented on a consistent real-time basis. These findings are crucial for both academics and practitioners as expansions are much longer-lived than recessions. Finally, I extend the empirical exercises by incorporating data through September 2020 and document sizable gains from using the Aligned Economic Index, relative to more traditional approaches, during the COVID-19 market turbulence.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文通过引入状态切换模型（以收益率曲线斜率作为市场状态代理变量）和构建对齐经济指数（基于Welch和Goyal（2008）的经典预测因子，并加入债券和股权溢价指标），实证显示该指数在样本内（R²=5.9%）和样本外（R²oos=4.12%）均对美股收益具有统计及经济意义的预测能力，且优于多种常用预测因子。研究进一步通过均值-方差投资者模型验证了该模型在所有市场状态下均能带来显著经济收益，并强调该指数可实时应用于实践。这些发现对从业者尤为重要，因为经济扩张期远长于衰退期。",
    "fetch_date": "2025-12-24",
    "id": "20251224_a39154aa"
  },
  {
    "title": "The Aligned Economic Index & The State Switching Model",
    "url": "https://arxiv.org/pdf/2512.20460v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "A growing empirical literature suggests that equity-premium predictability is state dependent, with much of the forecasting power concentrated around recessionary periods \\parencite{Henkel2011,DanglHalling2012,Devpura2018}. I study U.S. stock return predictability across economic regimes and document strong evidence of time-varying expected returns across both expansionary and contractionary states. I contribute in two ways. First, I introduce a state-switching predictive regression in which the market state is defined in real time using the slope of the yield curve. Relative to the standard one-state predictive regression, the state-switching specification increases both in-sample and out-of-sample performance for the set of popular predictors considered by \\textcite{WelchGoyal2008}, improving the out-of-sample performance of most predictors in economically meaningful ways. Second, I propose a new aggregate predictor, the Aligned Economic Index, constructed via partial least squares (PLS). Under the state-switching model, the Aligned Economic Index exhibits statistically and economically significant predictive power in sample and out of sample, and it outperforms widely used benchmark predictors and alternative predictor-combination methods.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文研究了美国股票收益在不同经济状态下的可预测性，提出了两个对实战交易有价值的贡献：一是引入基于收益率曲线斜率实时定义市场状态的状态切换预测回归模型，相比传统单状态模型显著提高了样本内和样本外预测性能；二是通过偏最小二乘法构建了新的聚合预测指标——对齐经济指数，在状态切换模型下展现出统计和经济意义上显著的样本内外预测能力。论文聚焦于经济状态依赖的股票溢价预测，其状态切换模型和对齐经济指数可直接应用于实战中的择时和风险管理策略。",
    "fetch_date": "2025-12-24",
    "id": "20251224_23ae3263"
  },
  {
    "title": "GIFfluence: A Visual Approach to Investor Sentiment and the Stock Market",
    "url": "https://arxiv.org/pdf/2512.20027v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "We study dynamic visual representations as a proxy for investor sentiment about the stock market. Our sentiment index, GIFsentiment, is constructed from millions of posts in the Graphics Interchange Format (GIF) on a leading investment social media platform. GIFsentiment correlates with seasonal mood variations and the severity of COVID lockdowns. It is positively associated with contemporaneous market returns and negatively predicts returns for up to four weeks, even after controlling for other sentiment and attention measures. These effects are stronger among portfolios that are more susceptible to mispricing. GIFsentiment positively predicts trading volume, market volatility, and flows toward equity funds and away from debt funds. Our evidence suggests that GIFsentiment is a proxy for misperceptions that are later corrected.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文提出了一种基于投资社交媒体平台GIF帖子的投资者情绪指标GIFsentiment。研究发现：1）该指标与季节性情绪波动和疫情封锁严重程度相关；2）与同期市场收益正相关，并能负向预测未来四周收益（控制其他情绪指标后仍显著）；3）对易受错误定价影响的投资组合预测效果更强；4）能正向预测交易量、市场波动率以及资金从债券基金流向股票基金。证据表明GIFsentiment可作为市场错误认知的代理指标，这些认知后续会被修正。",
    "fetch_date": "2025-12-24",
    "id": "20251224_78339dde"
  },
  {
    "title": "Covariance-Aware Simplex Projection for Cardinality-Constrained Portfolio Optimization",
    "url": "https://arxiv.org/pdf/2512.19986v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "Metaheuristic algorithms for cardinality-constrained portfolio optimization require repair operators to map infeasible candidates onto the feasible region. Standard Euclidean projection treats assets as independent and can ignore the covariance structure that governs portfolio risk, potentially producing less diversified portfolios. This paper introduces Covariance-Aware Simplex Projection (CASP), a two-stage repair operator that (i) selects a target number of assets using volatility-normalized scores and (ii) projects the candidate weights using a covariance-aware geometry aligned with tracking-error risk. This provides a portfolio-theoretic foundation for using a covariance-induced distance in repair operators. On S&P 500 data (2020-2024), CASP-Basic delivers materially lower portfolio variance than standard Euclidean repair without relying on return estimates, with improvements that are robust across assets and statistically significant. Ablation results indicate that volatility-normalized selection drives most of the variance reduction, while the covariance-aware projection provides an additional, consistent improvement. We further show that optional return-aware extensions can improve Sharpe ratios, and out-of-sample tests confirm that gains transfer to realized performance. CASP integrates as a drop-in replacement for Euclidean projection in metaheuristic portfolio optimizers.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文提出了一种用于基数约束投资组合优化的协方差感知单纯形投影方法。针对元启发式算法中修复算子将不可行候选解映射到可行区域时忽略协方差结构的问题，该方法采用两阶段修复：首先基于波动率归一化评分选择目标资产数量，然后使用与跟踪误差风险对齐的协方差感知几何进行权重投影。在S&P 500数据上的实证表明，该方法在不依赖收益预测的情况下显著降低了投资组合方差，且改进具有统计显著性。消融实验显示波动率归一化选择贡献了主要方差降低，而协方差感知投影提供了额外的稳定改进。",
    "fetch_date": "2025-12-24",
    "id": "20251224_432db6dc"
  },
  {
    "title": "Needles in a haystack: using forensic network science to uncover insider trading",
    "url": "https://arxiv.org/pdf/2512.18918v1",
    "source": "ArXiv",
    "date": "2025-12-21",
    "abstract": "Although the automation and digitisation of anti-financial crime investigation has made significant progress in recent years, detecting insider trading remains a unique challenge, partly due to the limited availability of labelled data. To address this challenge, we propose using a data-driven networks approach that flags groups of corporate insiders who report coordinated transactions that are indicative of insider trading. Specifically, we leverage data on 2.9 million trades reported to the U.S. Securities and Exchange Commission (SEC) by company insiders (C-suite executives, board members and major shareholders) between 2014 and 2024. Our proposed algorithm constructs weighted edges between insiders based on the temporal similarity of their trades over the 10-year timeframe. Within this network we then uncover trends that indicate insider trading by focusing on central nodes and anomalous subgraphs. To highlight the validity of our approach we evaluate our findings with reference to two null models, generated by running our algorithm on synthetic empirically calibrated and shuffled datasets. The results indicate that our approach can be used to detect pairs or clusters of insiders whose behaviour suggests insider trading and/or market manipulation.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文提出了一种利用法证网络科学检测内幕交易的数据驱动网络方法。通过分析2014-2024年间美国证券交易委员会（SEC）收到的290万笔公司内部人（高管、董事会成员和大股东）交易报告，该算法基于交易时间相似性构建内部人之间的加权边网络，并通过识别中心节点和异常子图来揭示内幕交易模式。研究使用合成经验校准和随机数据集生成的零模型验证了方法的有效性，表明该方法能有效检测协同交易的内幕交易对或集群。",
    "fetch_date": "2025-12-24",
    "id": "20251224_944d270d"
  },
  {
    "title": "Quantitative Financial Modeling for Sri Lankan Markets: Approach Combining NLP, Clustering and Time-Series Forecasting",
    "url": "https://arxiv.org/pdf/2512.20216v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "This research introduces a novel quantitative methodology tailored for quantitative finance applications, enabling banks, stockbrokers, and investors to predict economic regimes and market signals in emerging markets, specifically Sri Lankan stock indices (S&P SL20 and ASPI) by integrating Environmental, Social, and Governance (ESG) sentiment analysis with macroeconomic indicators and advanced time-series forecasting. Designed to leverage quantitative techniques for enhanced risk assessment, portfolio optimization, and trading strategies in volatile environments, the architecture employs FinBERT, a transformer-based NLP model, to extract sentiment from ESG texts, followed by unsupervised clustering (UMAP/HDBSCAN) to identify 5 latent ESG regimes, validated via PCA. These regimes are mapped to economic conditions using a dense neural network and gradient boosting classifier, achieving 84.04% training and 82.0% validation accuracy. Concurrently, time-series models (SRNN, MLP, LSTM, GRU) forecast daily closing prices, with GRU attaining an R-squared of 0.801 and LSTM delivering 52.78% directional accuracy on intraday data. A strong correlation between S&P SL20 and S&P 500, observed through moving average and volatility trend plots, further bolsters forecasting precision. A rule-based fusion logic merges ESG and time-series outputs for final market signals. By addressing literature gaps that overlook emerging markets and holistic integration, this quant-driven framework combines global correlations and local sentiment analysis to offer scalable, accurate tools for quantitative finance professionals navigating complex markets like Sri Lanka.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "该研究为斯里兰卡市场（S&P SL20和ASPI指数）提出了一种新颖的量化金融建模方法，通过整合ESG情感分析（使用FinBERT模型）、宏观经济指标和先进的时间序列预测技术（包括SRNN、MLP、LSTM、GRU），旨在预测经济状态和市场信号。该方法采用无监督聚类（UMAP/HDBSCAN）识别出5个潜在的ESG状态，并通过密集神经网络和梯度提升分类器将其映射到经济条件，训练和验证准确率分别达到84.04%和82.0%。在时间序列预测方面，GRU模型的R平方为0.801，LSTM在日内数据上的方向准确性为52.78%。研究还观察到S&P SL20与S&P 500之间存在强相关性。该框架旨在增强风险评估、投资组合优化和交易策略，适用于波动环境中的新兴市场。",
    "fetch_date": "2025-12-24",
    "id": "20251224_6cec85b9"
  },
  {
    "title": "Pricing of wrapped Bitcoin and Ethereum on-chain options",
    "url": "https://arxiv.org/pdf/2512.20190v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "This paper measures price differences between Hegic option quotes on Arbitrum and a model-based benchmark built on Black--Scholes model with regime-sensitive volatility estimated via a two-regime MS-AR-(GJR)-GARCH model. Using option-level feasible GLS, we find benchmark prices exceed Hegic quotes on average, especially for call options. The price spread rises with order size, strike, maturity, and estimated volatility, and falls with trading volume. By underlying, wrapped Bitcoin options show larger and more persistent spreads, while Ethereum options are closer to the benchmark. The framework offers a data-driven analysis for monitoring and calibrating on-chain option pricing logic.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "该论文通过对比Hegic在Arbitrum上的期权报价与基于两区制MS-AR-(GJR)-GARCH模型估计波动率的Black-Scholes基准模型，发现基准价格普遍高于Hegic报价（尤其是看涨期权）。价差随订单规模、行权价、期限和估计波动率增加而扩大，随交易量增加而缩小。其中，包装比特币期权价差更大且更持久，以太坊期权则更接近基准。该框架为监控和校准链上期权定价逻辑提供了数据驱动的分析方法。",
    "fetch_date": "2025-12-24",
    "id": "20251224_6243b8b8"
  },
  {
    "title": "Equilibrium Liquidity and Risk Offsetting in Decentralised Markets",
    "url": "https://arxiv.org/pdf/2512.19838v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "We develop an economic model of decentralised exchanges (DEXs) in which risk-averse liquidity providers (LPs) manage risk in a centralised exchange (CEX) based on preferences, information, and trading costs. Rational, risk-averse LPs anticipate the frictions associated with replication and manage risk primarily by reducing the reserves supplied to the DEX. Greater aversion reduces the equilibrium viability of liquidity provision, resulting in thinner markets and lower trading volumes. Greater uninformed demand supports deeper liquidity, whereas higher fundamental price volatility erodes it. Finally, while moderate anticipated price changes can improve LP performance, larger changes require more intensive trading in the CEX, generate higher replication costs, and induce LPs to reduce liquidity supply.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文构建了一个去中心化交易所（DEX）的经济模型，研究风险厌恶的流动性提供者（LPs）如何基于偏好、信息与交易成本，在中心化交易所（CEX）管理风险。理性且风险厌恶的LPs会预判与复制相关的摩擦，主要通过减少向DEX提供的储备来管理风险。更高的风险厌恶会降低流动性提供的均衡可行性，导致市场更薄、交易量更低。更大的非知情需求支持更深的流动性，而更高的基础价格波动则会削弱流动性。最后，虽然适度的预期价格变动可能改善LP表现，但更大的变动需要在CEX进行更密集的交易，产生更高的复制成本，并促使LPs减少流动性供给。",
    "fetch_date": "2025-12-24",
    "id": "20251224_27c66c3f"
  },
  {
    "title": "How to choose my stochastic volatility parameters? A review",
    "url": "https://arxiv.org/pdf/2512.19821v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "Based on the existing literature, this article presents the different ways of choosing the parameters of stochastic volatility models in general, in the context of pricing financial derivative contracts. This includes the use of stochastic volatility inside stochastic local volatility models.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "基于现有文献，本文综述了在金融衍生品定价背景下，选择随机波动率模型参数的各种方法，包括在随机局部波动率模型中使用随机波动率。",
    "fetch_date": "2025-12-24",
    "id": "20251224_faddc8fe"
  },
  {
    "title": "Counterexamples for FX Options Interpolations -- Part II",
    "url": "https://arxiv.org/pdf/2512.19625v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "This follow-up article analyzes the impact of foreign exchange option interpolation on the vanilla option implied volatilities. In particular different exact interpolations of broker quotes may lead to different implied volatilities at the 10$Δ$ and 25$Δ$ Puts and Calls.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "这篇后续文章分析了外汇期权插值对普通期权隐含波动率的影响。具体而言，经纪商报价的不同精确插值方法可能导致10Δ和25Δ看跌期权与看涨期权的隐含波动率出现差异。",
    "fetch_date": "2025-12-24",
    "id": "20251224_bee73e28"
  },
  {
    "title": "Counterexamples for FX Options Interpolations -- Part I",
    "url": "https://arxiv.org/pdf/2512.19621v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "This article provides a list of counterexamples, where some of the popular fx option interpolations break down. Interpolation of FX option prices (or equivalently volatilities), is key to risk-manage not only vanilla FX option books, but also more exotic derivatives which are typically valued with local volatility or local stochastic volatilility models.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文列举了外汇期权插值方法失效的反例，指出插值对于风险管理至关重要，不仅涉及普通外汇期权，也影响使用局部波动率或局部随机波动率模型定价的奇异衍生品。",
    "fetch_date": "2025-12-24",
    "id": "20251224_43d5d092"
  },
  {
    "title": "Heston vol-of-vol and the VVIX",
    "url": "https://arxiv.org/pdf/2512.19611v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "The Heston stochastic volatility model is arguably, the most popular stochastic volatility model used to price and risk manage exotic derivatives. In spite of this, it is not necessarily easy to calibrate to the market and obtain stable exotic option prices with this model. This paper focuses on the vol-of-vol parameter and its relation with the volatility of volatility index (VVIX) level. Four different approaches to estimate the VVIX in the Heston model are presented: two based on the known transition density of the variance, one analytical approximation, and one based on the Heston PDE which computes the value directly out of the underlying SPX500. Finally we explore their use to improve calibration stability.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文聚焦于Heston随机波动率模型中的波动率波动率参数及其与波动率波动率指数（VVIX）水平的关系。提出了四种在Heston模型中估计VVIX的方法：两种基于已知的方差转移密度，一种解析近似方法，以及一种基于Heston偏微分方程直接从标普500指数计算的方法。最后探讨了这些方法在提高模型校准稳定性方面的应用。",
    "fetch_date": "2025-12-24",
    "id": "20251224_dad4d8e3"
  },
  {
    "title": "Learning General Policies with Policy Gradient Methods",
    "url": "https://arxiv.org/pdf/2512.19366v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "While reinforcement learning methods have delivered remarkable results in a number of settings, generalization, i.e., the ability to produce policies that generalize in a reliable and systematic way, has remained a challenge. The problem of generalization has been addressed formally in classical planning where provable correct policies that generalize over all instances of a given domain have been learned using combinatorial methods. The aim of this work is to bring these two research threads together to illuminate the conditions under which (deep) reinforcement learning approaches, and in particular, policy optimization methods, can be used to learn policies that generalize like combinatorial methods do. We draw on lessons learned from previous combinatorial and deep learning approaches, and extend them in a convenient way. From the former, we model policies as state transition classifiers, as (ground) actions are not general and change from instance to instance. From the latter, we use graph neural networks (GNNs) adapted to deal with relational structures for representing value functions over planning states, and in our case, policies. With these ingredients in place, we find that actor-critic methods can be used to learn policies that generalize almost as well as those obtained using combinatorial approaches while avoiding the scalability bottleneck and the use of feature pools. Moreover, the limitations of the DRL methods on the benchmarks considered have little to do with deep learning or reinforcement learning algorithms, and result from the well-understood expressive limitations of GNNs, and the tradeoff between optimality and generalization (general policies cannot be optimal in some domains). Both of these limitations are addressed without changing the basic DRL methods by adding derived predicates and an alternative cost structure to optimize.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文探讨了强化学习方法（特别是策略梯度方法）在何种条件下能学习到具有泛化能力的策略，类似于组合方法在经典规划中所实现的。作者结合了组合方法与深度学习的思路，将策略建模为状态转移分类器（因为具体动作会随问题实例变化），并使用图神经网络（GNNs）来处理关系结构以表示规划状态的价值函数和策略。研究旨在弥合强化学习与可证明泛化的组合方法之间的差距，但重点在于理论框架与条件分析，而非直接应用于实战交易场景。",
    "fetch_date": "2025-12-24",
    "id": "20251224_5412cd38"
  },
  {
    "title": "Institutional Backing and Crypto Volatility: A Hybrid Framework for DeFi Stabilization",
    "url": "https://arxiv.org/pdf/2512.19251v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "Decentralized finance (DeFi) lacks centralized oversight, often resulting in heightened volatility. In contrast, centralized finance (CeFi) offers a more stable environment with institutional safeguards. Institutional backing can play a stabilizing role in a hybrid structure (HyFi), enhancing transparency, governance, and market discipline. This study investigates whether HyFi-like cryptocurrencies, those backed by institutions, exhibit lower price risk than fully decentralized counterparts. Using daily data for 18 major cryptocurrencies from January 2020 to November 2024, we estimate panel EGLS models with fixed, random, and dynamic specifications. Results show that HyFi-like assets consistently experience lower price risk, with this effect intensifying during periods of elevated market volatility. The negative interaction between HyFi status and market-wide volatility confirms their stabilizing role. Conversely, greater decentralization is strongly associated with increased volatility, particularly during periods of market stress. Robustness checks using quantile regressions and pre-/post-Terra Luna subsamples reinforce these findings, with stronger effects observed in high-volatility quantiles and post-crisis conditions. These results highlight the importance of institutional architecture in enhancing the resilience of digital asset markets.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文探讨了去中心化金融（DeFi）因缺乏中心化监管而波动性较高，而中心化金融（CeFi）通过机构保障提供更稳定环境。研究发现，在混合结构（HyFi）中，机构支持能通过增强透明度、治理和市场纪律发挥稳定作用。基于2020年1月至2024年11月18种主要加密货币的日度数据，面板EGLS模型显示，具有机构支持的HyFi类资产价格风险较低，且在市场波动加剧时期稳定作用更明显。相反，去中心化程度越高，波动性越强，尤其在市场压力时期。分位数回归及Terra Luna事件前后子样本的稳健性检验支持了这些结论。",
    "fetch_date": "2025-12-24",
    "id": "20251224_36795ecf"
  }
]