[
  {
    "title": "The Red Queen's Trap: Limits of Deep Evolution in High-Frequency Trading",
    "url": "https://arxiv.org/pdf/2512.15732v1",
    "source": "ArXiv",
    "date": "2025-12-05",
    "abstract": "The integration of Deep Reinforcement Learning (DRL) and Evolutionary Computation (EC) is frequently hypothesized to be the \"Holy Grail\" of algorithmic trading, promising systems that adapt autonomously to non-stationary market regimes. This paper presents a rigorous post-mortem analysis of \"Galaxy Empire,\" a hybrid framework coupling LSTM/Transformer-based perception with a genetic \"Time-is-Life\" survival mechanism. Deploying a population of 500 autonomous agents in a high-frequency cryptocurrency environment, we observed a catastrophic divergence between training metrics (Validation APY $>300\\%$) and live performance (Capital Decay $>70\\%$). We deconstruct this failure through a multi-disciplinary lens, identifying three critical failure modes: the overfitting of \\textit{Aleatoric Uncertainty} in low-entropy time-series, the \\textit{Survivor Bias} inherent in evolutionary selection under high variance, and the mathematical impossibility of overcoming microstructure friction without order-flow data. Our findings provide empirical evidence that increasing model complexity in the absence of information asymmetry exacerbates systemic fragility.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "《红皇后的陷阱：高频交易中深度进化的局限》对实战交易具有重要警示价值。该论文对名为“银河帝国”的混合框架（结合LSTM/Transformer感知与遗传“时间即生命”生存机制）进行了严谨的事后分析。在加密货币高频环境中部署500个自主代理后，观察到训练指标（验证年化收益率>300%）与实际表现（资本衰减>70%）之间的灾难性背离。研究通过多学科视角解构了失败原因，识别出三个关键失效模式：低熵时间序列中偶然不确定性的过拟合、高方差下进化选择固有的幸存者偏差，以及缺乏订单流数据时无法克服微观结构摩擦的数学不可能性。研究结果为模型复杂性增加在缺乏信息不对称时加剧系统脆弱性提供了实证证据。",
    "fetch_date": "2025-12-29",
    "id": "20251229_f1a0b406"
  },
  {
    "title": "Predicting Price Movements in High-Frequency Financial Data with Spiking Neural Networks",
    "url": "https://arxiv.org/pdf/2512.05868v1",
    "source": "ArXiv",
    "date": "2025-12-05",
    "abstract": "Modern high-frequency trading (HFT) environments are characterized by sudden price spikes that present both risk and opportunity, but conventional financial models often fail to capture the required fine temporal structure. Spiking Neural Networks (SNNs) offer a biologically inspired framework well-suited to these challenges due to their natural ability to process discrete events and preserve millisecond-scale timing. This work investigates the application of SNNs to high-frequency price-spike forecasting, enhancing performance via robust hyperparameter tuning with Bayesian Optimization (BO). This work converts high-frequency stock data into spike trains and evaluates three architectures: an established unsupervised STDP-trained SNN, a novel SNN with explicit inhibitory competition, and a supervised backpropagation network. BO was driven by a novel objective, Penalized Spike Accuracy (PSA), designed to ensure a network's predicted price spike rate aligns with the empirical rate of price events. Simulated trading demonstrated that models optimized with PSA consistently outperformed their Spike Accuracy (SA)-tuned counterparts and baselines. Specifically, the extended SNN model with PSA achieved the highest cumulative return (76.8%) in simple backtesting, significantly surpassing the supervised alternative (42.54% return). These results validate the potential of spiking networks, when robustly tuned with task-specific objectives, for effective price spike forecasting in HFT.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "该论文《利用脉冲神经网络预测高频金融数据中的价格变动》针对高频交易环境中传统模型难以捕捉的毫秒级价格尖峰问题，提出了一种生物启发的解决方案。研究将高频股票数据转换为脉冲序列，并评估了三种架构：基于无监督STDP训练的经典脉冲神经网络、具有显式抑制竞争的新型脉冲神经网络，以及监督式反向传播网络。通过贝叶斯优化结合新颖的惩罚性脉冲准确率目标函数进行超参数调优，确保模型预测的价格尖峰率与实证事件率一致。模拟交易显示，经PSA优化的模型在性能上持续优于仅使用脉冲准确率调优的对比模型及基线方法。",
    "fetch_date": "2025-12-29",
    "id": "20251229_8824f09c"
  },
  {
    "title": "A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning",
    "url": "https://arxiv.org/pdf/2512.05753v1",
    "source": "ArXiv",
    "date": "2025-12-05",
    "abstract": "The fast deployment of cognitive radar to counter jamming remains a critical challenge in modern warfare, where more efficient deployment leads to quicker detection of targets. Existing methods are primarily based on evolutionary algorithms, which are time-consuming and prone to falling into local optima. We tackle these drawbacks via the efficient inference of neural networks and propose a brand new framework: Fast Anti-Jamming Radar Deployment Algorithm (FARDA). We first model the radar deployment problem as an end-to-end task and design deep reinforcement learning algorithms to solve it, where we develop integrated neural modules to perceive heatmap information and a brand new reward format. Empirical results demonstrate that our method achieves coverage comparable to evolutionary algorithms while deploying radars approximately 7,000 times faster. Further ablation experiments confirm the necessity of each component of FARDA.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "针对现代战争中认知雷达快速部署以对抗干扰的关键挑战，本文提出了一种基于深度强化学习的快速抗干扰雷达部署算法（FARDA）。现有方法主要基于进化算法，耗时且易陷入局部最优。FARDA通过神经网络高效推理，将雷达部署建模为端到端任务，设计了集成神经模块感知热图信息和新奖励格式的深度强化学习算法。实证结果表明，该方法在达到与进化算法相当覆盖范围的同时，部署速度提升约7000倍。消融实验验证了FARDA各组件的必要性。",
    "fetch_date": "2025-12-29",
    "id": "20251229_5a33edc9"
  },
  {
    "title": "Deep Reinforcement Learning Optimization for Uncertain Nonlinear Systems via Event-Triggered Robust Adaptive Dynamic Programming",
    "url": "https://arxiv.org/pdf/2512.15735v3",
    "source": "ArXiv",
    "date": "2025-12-05",
    "abstract": "This work proposes a unified control architecture that couples a Reinforcement Learning (RL)-driven controller with a disturbance-rejection Extended State Observer (ESO), complemented by an Event-Triggered Mechanism (ETM) to limit unnecessary computations. The ESO is utilized to estimate the system states and the lumped disturbance in real time, forming the foundation for effective disturbance compensation. To obtain near-optimal behavior without an accurate system description, a value-iteration-based Adaptive Dynamic Programming (ADP) method is adopted for policy approximation. The inclusion of the ETM ensures that parameter updates of the learning module are executed only when the state deviation surpasses a predefined bound, thereby preventing excessive learning activity and substantially reducing computational load. A Lyapunov-oriented analysis is used to characterize the stability properties of the resulting closed-loop system. Numerical experiments further confirm that the developed approach maintains strong control performance and disturbance tolerance, while achieving a significant reduction in sampling and processing effort compared with standard time-triggered ADP schemes.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文提出了一种将强化学习（RL）控制器与抗扰扩展状态观测器（ESO）相结合的统一控制架构，并辅以事件触发机制（ETM）以减少不必要的计算。ESO用于实时估计系统状态和集总扰动，为有效扰动补偿奠定基础。为在缺乏精确系统描述的情况下获得近似最优行为，采用基于值迭代的自适应动态规划（ADP）方法进行策略逼近。ETM的引入确保学习模块的参数更新仅在状态偏差超过预设界限时执行，从而避免过度学习活动并显著降低计算负荷。通过李雅普诺夫导向分析表征了闭环系统的稳定性。数值实验进一步证实，与标准时间触发ADP方案相比，该方法在保持强大控制性能和扰动容忍度的同时，显著减少了采样和处理工作量。",
    "fetch_date": "2025-12-29",
    "id": "20251229_f5507cc4"
  },
  {
    "title": "A Unified AI System For Data Quality Control and DataOps Management in Regulated Environments",
    "url": "https://arxiv.org/pdf/2512.05559v1",
    "source": "ArXiv",
    "date": "2025-12-05",
    "abstract": "In regulated domains such as finance, the integrity and governance of data pipelines are critical - yet existing systems treat data quality control (QC) as an isolated preprocessing step rather than a first-class system component. We present a unified AI-driven Data QC and DataOps Management framework that embeds rule-based, statistical, and AI-based QC methods into a continuous, governed layer spanning ingestion, model pipelines, and downstream applications. Our architecture integrates open-source tools with custom modules for profiling, audit logging, breach handling, configuration-driven policies, and dynamic remediation. We demonstrate deployment in a production-grade financial setup: handling streaming and tabular data across multiple asset classes and transaction streams, with configurable thresholds, cloud-native storage interfaces, and automated alerts. We show empirical gains in anomaly detection recall, reduction of manual remediation effort, and improved auditability and traceability in high-throughput data workflows. By treating QC as a system concern rather than an afterthought, our framework provides a foundation for trustworthy, scalable, and compliant AI pipelines in regulated environments.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "在金融等受监管领域，数据管道的完整性和治理至关重要。本文提出了一种统一的AI驱动数据质量控制和DataOps管理框架，将基于规则、统计和AI的质量控制方法嵌入到一个跨越数据摄取、模型管道和下游应用的连续治理层中。该架构整合了开源工具与定制模块，用于数据剖析、审计日志记录、违规处理、配置驱动策略和动态修复。在金融生产环境中部署的演示表明，该框架能够处理多资产类别和交易流中的流数据和表格数据，具有可配置阈值、云原生存储接口和自动警报功能。实证结果显示，在高吞吐量数据工作流中，异常检测召回率得到提升，手动修复工作量减少，审计性和可追溯性得到改善。通过将质量控制视为系统核心而非事后补救，该框架为可信、可扩展且合规的AI管道提供了基础。",
    "fetch_date": "2025-12-29",
    "id": "20251229_144f113c"
  },
  {
    "title": "Differential ML with a Difference",
    "url": "https://arxiv.org/pdf/2512.05301v1",
    "source": "ArXiv",
    "date": "2025-12-04",
    "abstract": "Differential ML (Huge and Savine 2020) is a technique for training neural networks to provide fast approximations to complex simulation-based models for derivatives pricing and risk management. It uses price sensitivities calculated through pathwise adjoint differentiation to reduce pricing and hedging errors. However, for options with discontinuous payoffs, such as digital or barrier options, the pathwise sensitivities are biased, and incorporating them into the loss function can magnify errors. We consider alternative methods for estimating sensitivities and find that they can substantially reduce test errors in prices and in their sensitivities. Using differential labels calculated through the likelihood ratio method expands the scope of Differential ML to discontinuous payoffs. A hybrid method incorporates gamma estimates as well as delta estimates, providing further regularization.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "差分机器学习（Differential ML）是一种训练神经网络快速近似复杂模拟模型的技术，用于衍生品定价和风险管理。该方法利用通过路径伴随微分计算的价格敏感性来减少定价和对冲误差。然而，对于具有不连续收益的期权（如数字或障碍期权），路径敏感性存在偏差，将其纳入损失函数可能放大误差。研究探讨了替代敏感性估计方法，发现这些方法能显著降低价格及其敏感性的测试误差。使用似然比法计算的差分标签将差分机器学习扩展到不连续收益领域。混合方法结合了伽马估计和德尔塔估计，提供了进一步的规范化。",
    "fetch_date": "2025-12-29",
    "id": "20251229_c043a012"
  },
  {
    "title": "Continuous-time reinforcement learning for optimal switching over multiple regimes",
    "url": "https://arxiv.org/pdf/2512.04697v2",
    "source": "ArXiv",
    "date": "2025-12-04",
    "abstract": "This paper studies the continuous-time reinforcement learning (RL) for optimal switching problems across multiple regimes. We consider a type of exploratory formulation under entropy regularization where the agent randomizes both the timing of switches and the selection of regimes through the generator matrix of an associated continuous-time finite-state Markov chain. We establish the well-posedness of the associated system of Hamilton-Jacobi-Bellman (HJB) equations and provide a characterization of the optimal policy. The policy improvement and the convergence of the policy iterations are rigorously established by analyzing the system of equations. We also show the convergence of the value function in the exploratory formulation towards the value function in the classical formulation as the temperature parameter vanishes. Finally, a reinforcement learning algorithm is devised and implemented by invoking the policy evaluation based on the martingale characterization. Our numerical examples with the aid of neural networks illustrate the effectiveness of the proposed RL algorithm.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文研究了多体制下最优切换问题的连续时间强化学习。在熵正则化的探索性框架下，代理通过关联连续时间有限状态马尔可夫链的生成矩阵，随机化切换时机和体制选择。我们建立了相关哈密顿-雅可比-贝尔曼方程组的适定性，并给出了最优策略的表征。通过分析方程组，严格证明了策略改进和策略迭代的收敛性。当温度参数趋近于零时，我们还展示了探索性框架下的价值函数向经典框架价值函数的收敛。最后，基于鞅表征的策略评估，设计并实现了一种强化学习算法。借助神经网络的数值算例说明了所提RL算法的有效性。",
    "fetch_date": "2025-12-29",
    "id": "20251229_126a24ad"
  },
  {
    "title": "Convolution-FFT for option pricing in the Heston model",
    "url": "https://arxiv.org/pdf/2512.05326v1",
    "source": "ArXiv",
    "date": "2025-12-05",
    "abstract": "We propose a convolution-FFT method for pricing European options under the Heston model that leverages a continuously differentiable representation of the joint characteristic function. Unlike existing Fourier-based methods that rely on branch-cut adjustments or empirically tuned damping parameters, our approach yields a stable integrand even under large frequency oscillations. Crucially, we derive fully analytical error bounds that quantify both truncation error and discretization error in terms of model parameters and grid settings. To the best of our knowledge, this is the first work to provide such explicit, closed-form error estimates for an FFT-based convolution method specialized to the Heston model. Numerical experiments confirm the theoretical rates and illustrate robust, high-accuracy option pricing at modest computational cost.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "本文提出了一种用于Heston模型下欧式期权定价的卷积-FFT方法，该方法利用联合特征函数的连续可微表示。与现有依赖分支切割调整或经验调优阻尼参数的傅里叶方法不同，本方法即使在大频率振荡下也能产生稳定的被积函数。关键贡献在于推导了完全解析的误差界，以模型参数和网格设置量化截断误差和离散化误差。据我们所知，这是首个为专门针对Heston模型的基于FFT的卷积方法提供此类显式闭式误差估计的工作。数值实验验证了理论收敛速度，并展示了以适中计算成本实现稳健、高精度的期权定价。",
    "fetch_date": "2025-12-29",
    "id": "20251229_111d7440"
  },
  {
    "title": "Market Reactions to Material Cybersecurity Incident Disclosures",
    "url": "https://arxiv.org/pdf/2512.06144v1",
    "source": "ArXiv",
    "date": "2025-12-05",
    "abstract": "This study examines short-term market responses to material cybersecurity incidents disclosed under Item 1.05 of Form 8-K. Drawing on a sample of disclosures made between 2023 and 2025, daily stock price movements were evaluated over a standardized event window surrounding each filing. On average, companies experienced negative price reactions following the disclosure of a material cybersecurity incident. Comparisons across company characteristics indicate that smaller companies tended to incur more pronounced declines, while differences by sector and beta were not evident. These findings offer empirical insight into how public markets interpret cybersecurity risks when they are formally reported and suggest that firm size may influence the degree of sensitivity to such events.",
    "broker": "Cornell Univ",
    "score": 5,
    "summary": "本研究考察了根据8-K表格第1.05项披露的重大网络安全事件引发的短期市场反应。基于2023年至2025年间的披露样本，评估了每份申报文件周围标准化事件窗口内的每日股价变动。平均而言，公司在披露重大网络安全事件后经历了负面价格反应。跨公司特征的比较表明，规模较小的公司往往遭受更明显的股价下跌，而按行业和贝塔值的差异并不明显。这些发现为公开市场如何解释正式报告的网络安全风险提供了实证见解，并表明公司规模可能影响对此类事件的敏感程度。",
    "fetch_date": "2025-12-29",
    "id": "20251229_da2b1b43"
  },
  {
    "title": "Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem",
    "url": "https://arxiv.org/pdf/2512.05946v1",
    "source": "ArXiv",
    "date": "2025-12-05",
    "abstract": "Resource allocation remains NP-hard due to combinatorial complexity. While deep reinforcement learning (DRL) methods, such as the Rainbow Deep Q-Network (DQN), improve scalability through prioritized replay and distributional heads, classical function approximators limit their representational power. We introduce Variational Quantum Rainbow DQN (VQR-DQN), which integrates ring-topology variational quantum circuits with Rainbow DQN to leverage quantum superposition and entanglement. We frame the human resource allocation problem (HRAP) as a Markov decision process (MDP) with combinatorial action spaces based on officer capabilities, event schedules, and transition times. On four HRAP benchmarks, VQR-DQN achieves 26.8% normalized makespan reduction versus random baselines and outperforms Double DQN and classical Rainbow DQN by 4.9-13.4%. These gains align with theoretical connections between circuit expressibility, entanglement, and policy quality, demonstrating the potential of quantum-enhanced DRL for large-scale resource allocation. Our implementation is available at: https://github.com/Analytics-Everywhere-Lab/qtrl/.",
    "broker": "Cornell Univ",
    "score": 5,
    "summary": "资源分配问题因其组合复杂性而保持NP难。虽然深度强化学习方法（如Rainbow DQN）通过优先回放和分布头提高了可扩展性，但经典函数逼近器限制了其表示能力。本文提出变分量子Rainbow DQN（VQR-DQN），将环形拓扑变分量子电路与Rainbow DQN集成，以利用量子叠加和纠缠。我们将人力资源分配问题（HRAP）建模为基于官员能力、事件时间表和转移时间的组合动作空间的马尔可夫决策过程（MDP）。在四个HRAP基准测试中，VQR-DQN相比随机基线实现了26.8%的归一化完工时间减少，并优于Double DQN和经典Rainbow DQN 4.9-13.4%。这些收益与电路表达能力、纠缠和策略质量之间的理论联系一致，展示了量子增强DRL在大规模资源分配中的潜力。",
    "fetch_date": "2025-12-29",
    "id": "20251229_4b5ad711"
  },
  {
    "title": "FedSight AI: Multi-Agent System Architecture for Federal Funds Target Rate Prediction",
    "url": "https://arxiv.org/pdf/2512.15728v1",
    "source": "ArXiv",
    "date": "2025-12-05",
    "abstract": "The Federal Open Market Committee (FOMC) sets the federal funds rate, shaping monetary policy and the broader economy. We introduce \\emph{FedSight AI}, a multi-agent framework that uses large language models (LLMs) to simulate FOMC deliberations and predict policy outcomes. Member agents analyze structured indicators and unstructured inputs such as the Beige Book, debate options, and vote, replicating committee reasoning. A Chain-of-Draft (CoD) extension further improves efficiency and accuracy by enforcing concise multistage reasoning. Evaluated at 2023-2024 meetings, FedSight CoD achieved accuracy of 93.75\\% and stability of 93.33\\%, outperforming baselines including MiniFed and Ordinal Random Forest (RF), while offering transparent reasoning aligned with real FOMC communications.",
    "broker": "Cornell Univ",
    "score": 5,
    "summary": "本文介绍了FedSight AI，这是一个利用大型语言模型（LLMs）模拟联邦公开市场委员会（FOMC）审议过程以预测联邦基金目标利率的多智能体系统架构。该系统通过智能体分析结构化指标（如经济数据）和非结构化输入（如褐皮书），进行辩论和投票，模拟委员会决策逻辑。其Chain-of-Draft（CoD）扩展通过强制简洁的多阶段推理，进一步提升了效率和准确性。在2023-2024年会议评估中，FedSight CoD实现了93.75%的准确率和93.33%的稳定性，优于包括MiniFed和Ordinal Random Forest（RF）在内的基线模型，同时提供了与真实FOMC沟通一致的透明推理。",
    "fetch_date": "2025-12-29",
    "id": "20251229_dc3f93f2"
  },
  {
    "title": "Standard and stressed value at risk forecasting using dynamic Bayesian networks",
    "url": "https://arxiv.org/pdf/2512.05661v1",
    "source": "ArXiv",
    "date": "2025-12-05",
    "abstract": "This study introduces a dynamic Bayesian network (DBN) framework for forecasting value at risk (VaR) and stressed VaR (SVaR) and compares its performance to several commonly applied models. Using daily S&P 500 index returns from 1991 to 2020, we produce 10-day 99% VaR and SVaR forecasts using a rolling period and historical returns for the traditional models, while three DBNs use both historical and forecasted returns. We evaluate the models' forecasting accuracy using standard backtests and forecasting error measures. Results show that autoregressive models deliver the most accurate VaR forecasts, while the DBNs achieve comparable performance to the historical simulation model, despite incorporating forward-looking return forecasts. For SVaR, all models produce highly conservative forecasts, with minimal breaches and limited differentiation in accuracy. While DBNs do not outperform traditional models, they demonstrate feasibility as a forward-looking approach to provide a foundation for future research on integrating causal inference into financial risk forecasting.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本研究引入动态贝叶斯网络（DBN）框架来预测风险价值（VaR）和压力风险价值（SVaR），并与几种常用模型进行性能比较。使用1991年至2020年标普500指数的日收益率数据，通过滚动周期和历史收益率生成10天99%的VaR和SVaR预测，而三个DBN模型同时使用历史收益率和预测收益率。通过标准回测和预测误差指标评估模型预测准确性。结果显示，自回归模型提供最准确的VaR预测，而DBN模型尽管包含前瞻性收益率预测，其表现与历史模拟模型相当。对于SVaR，所有模型均产生高度保守的预测，违约次数极少且准确性差异有限。虽然DBN未超越传统模型，但其作为前瞻性方法的可行性为未来将因果推断整合到金融风险预测的研究奠定了基础。",
    "fetch_date": "2025-12-29",
    "id": "20251229_f41d7e01"
  },
  {
    "title": "Risk aversion of insider and dynamic asymmetric information",
    "url": "https://arxiv.org/pdf/2512.05011v1",
    "source": "ArXiv",
    "date": "2025-12-04",
    "abstract": "This paper studies a Kyle-Back model with a risk-averse insider possessing exponential utility and a dynamic stochastic signal about the asset's terminal fundamental value. While the existing literature considers either risk-neutral insiders with dynamic signals or risk-averse insiders with static signals, we establish equilibrium when both features are present. Our approach imposes no restrictions on the magnitude of the risk aversion parameter, extending beyond previous work that requires sufficiently small risk aversion. We employ a weak conditioning methodology to construct a Schrödinger bridge between the insider's signal and the asset price process, an approach that naturally accommodates stochastic signal evolution and removes risk aversion constraints.\n  We derive necessary conditions for equilibrium, showing that the optimal insider strategy must be continuous with bounded variation. Under these conditions, we characterize the market-maker pricing rule and insider strategy that achieve equilibrium. We obtain explicit closed-form solutions for important cases including deterministic and quadratic signal volatilities, demonstrating the tractability of our framework.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文研究了一个Kyle-Back模型，其中内幕交易者具有风险厌恶特征（采用指数效用函数）并拥有关于资产最终基础价值的动态随机信号。现有文献通常只考虑风险中性内幕交易者配动态信号，或风险厌恶内幕交易者配静态信号，而本文在两者同时存在的情况下建立了均衡。我们的方法不对风险厌恶参数的大小施加限制，超越了先前要求风险厌恶足够小的工作。我们采用弱条件方法在内幕交易者信号与资产价格过程之间构建了一个薛定谔桥，这种方法自然地适应了随机信号的演化并消除了风险厌恶约束。我们推导了均衡的必要条件，表明最优内幕交易策略必须是连续且有界变差的。在这些条件下，我们描述了实现均衡的做市商定价规则和内幕交易策略。我们针对包括确定性和二次信号波动率在内的重要案例获得了显式闭式解，证明了我们框架的可处理性。",
    "fetch_date": "2025-12-29",
    "id": "20251229_5800e438"
  },
  {
    "title": "Coordinated Mean-Field Control for Systemic Risk",
    "url": "https://arxiv.org/pdf/2512.04704v1",
    "source": "ArXiv",
    "date": "2025-12-04",
    "abstract": "We develop a robust linear-quadratic mean-field control framework for systemic risk under model uncertainty, in which a central bank jointly optimizes interest rate policy and supervisory monitoring intensity against adversarial distortions. Our model features multiple policy instruments with interactive dynamics, implemented via a variance weight that depends on the policy rate, generating coupling effects absent in single-instrument models. We establish viscosity solutions for the associated HJB--Isaacs equation, prove uniqueness via comparison principles, and provide verification theorems. The linear-quadratic structure yields explicit feedback controls derived from a coupled Riccati system, preserving analytical tractability despite adversarial uncertainty. Simulations reveal distinct loss-of-control regimes driven by robustness-breakdown and control saturation, alongside a pronounced asymmetry in sensitivity between the mean and variance channels. These findings demonstrate the importance of instrument complementarity in systemic risk modeling and control.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文开发了一个稳健的线性二次平均场控制框架，用于在模型不确定性下处理系统性风险。中央银行通过联合优化利率政策和监管监控强度来对抗对抗性扭曲。模型具有多个政策工具的动态交互，通过依赖于政策利率的方差权重实现，产生了单工具模型中不存在的耦合效应。作者建立了相关HJB-Isaacs方程的粘性解，通过比较原理证明了唯一性，并提供了验证定理。线性二次结构产生了从耦合Riccati系统导出的显式反馈控制，尽管存在对抗性不确定性，但仍保持了分析的可处理性。模拟揭示了由稳健性崩溃和控制饱和驱动的不同失控机制，以及均值通道和方差通道之间显著的敏感性不对称。这些发现证明了在系统性风险建模和控制中工具互补性的重要性。",
    "fetch_date": "2025-12-29",
    "id": "20251229_05510e0b"
  },
  {
    "title": "Semi Centralized Training Decentralized Execution Architecture for Multi Agent Deep Reinforcement Learning in Traffic Signal Control",
    "url": "https://arxiv.org/pdf/2512.04653v1",
    "source": "ArXiv",
    "date": "2025-12-04",
    "abstract": "Multi-agent reinforcement learning (MARL) has emerged as a promising paradigm for adaptive traffic signal control (ATSC) of multiple intersections. Existing approaches typically follow either a fully centralized or a fully decentralized design. Fully centralized approaches suffer from the curse of dimensionality, and reliance on a single learning server, whereas purely decentralized approaches operate under severe partial observability and lack explicit coordination resulting in suboptimal performance. These limitations motivate region-based MARL, where the network is partitioned into smaller, tightly coupled intersections that form regions, and training is organized around these regions. This paper introduces a Semi-Centralized Training, Decentralized Execution (SEMI-CTDE) architecture for multi intersection ATSC. Within each region, SEMI-CTDE performs centralized training with regional parameter sharing and employs composite state and reward formulations that jointly encode local and regional information. The architecture is highly transferable across different policy backbones and state-reward instantiations. Building on this architecture, we implement two models with distinct design objectives. A multi-perspective experimental analysis of the two implemented SEMI-CTDE-based models covering ablations of the architecture's core elements including rule based and fully decentralized baselines shows that they achieve consistently superior performance and remain effective across a wide range of traffic densities and distributions.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文提出了一种用于多交叉口自适应交通信号控制的半集中训练去中心化执行架构，通过区域划分、参数共享和复合状态奖励设计来解决完全集中式方法的维度灾难和完全分布式方法的局部可观测性问题。虽然架构具有可迁移性并实现了两个具体模型，但其针对交通信号控制这一特定领域，与量化交易的实战应用关联较弱。",
    "fetch_date": "2025-12-29",
    "id": "20251229_6d6beb51"
  },
  {
    "title": "DeepSVM: Learning Stochastic Volatility Models with Physics-Informed Deep Operator Networks",
    "url": "https://arxiv.org/pdf/2512.07162v1",
    "source": "ArXiv",
    "date": "2025-12-08",
    "abstract": "Real-time calibration of stochastic volatility models (SVMs) is computationally bottlenecked by the need to repeatedly solve coupled partial differential equations (PDEs). In this work, we propose DeepSVM, a physics-informed Deep Operator Network (PI-DeepONet) designed to learn the solution operator of the Heston model across its entire parameter space. Unlike standard data-driven deep learning (DL) approaches, DeepSVM requires no labelled training data. Rather, we employ a hard-constrained ansatz that enforces terminal payoffs and static no-arbitrage conditions by design. Furthermore, we use Residual-based Adaptive Refinement (RAR) to stabilize training in difficult regions subject to high gradients. Overall, DeepSVM achieves a final training loss of $10^{-5}$ and predicts highly accurate option prices across a range of typical market dynamics. While pricing accuracy is high, we find that the model's derivatives (Greeks) exhibit noise in the at-the-money (ATM) regime, highlighting the specific need for higher-order regularization in physics-informed operator learning.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "DeepSVM：一种基于物理信息深度算子网络学习随机波动率模型的方法。实时校准随机波动率模型（SVMs）的计算瓶颈在于需要反复求解耦合偏微分方程（PDEs）。本文提出的DeepSVM无需标记训练数据，通过硬约束假设强制满足终端收益和静态无套利条件，并采用残差自适应细化（RAR）稳定高梯度区域的训练。该模型在典型市场动态范围内实现了高度准确的期权定价，但发现其衍生品（Greeks）在平价（ATM）区域存在噪声，凸显了物理信息算子学习中高阶正则化的需求。",
    "fetch_date": "2025-12-28",
    "id": "20251228_b22309f0"
  },
  {
    "title": "Learning to Hedge Swaptions",
    "url": "https://arxiv.org/pdf/2512.06639v1",
    "source": "ArXiv",
    "date": "2025-12-07",
    "abstract": "This paper investigates the deep hedging framework, based on reinforcement learning (RL), for the dynamic hedging of swaptions, contrasting its performance with traditional sensitivity-based rho-hedging. We design agents under three distinct objective functions (mean squared error, downside risk, and Conditional Value-at-Risk) to capture alternative risk preferences and evaluate how these objectives shape hedging styles. Relying on a three-factor arbitrage-free dynamic Nelson-Siegel model for our simulation experiments, our findings show that near-optimal hedging effectiveness is achieved when using two swaps as hedging instruments. Deep hedging strategies dynamically adapt the hedging portfolio's exposure to risk factors across states of the market. In our experiments, their out-performance over rho-hedging strategies persists even in the presence some of model misspecification. These results highlight RL's potential to deliver more efficient and resilient swaption hedging strategies.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "本文研究了基于强化学习的深度对冲框架在掉期期权动态对冲中的应用，并与传统的基于敏感性的Rho对冲方法进行了性能对比。研究设计了三种不同目标函数（均方误差、下行风险、条件风险价值）的智能体以捕捉不同的风险偏好，并评估这些目标如何塑造对冲风格。基于三因子无套利动态Nelson-Siegel模型进行模拟实验，结果表明使用两种互换作为对冲工具时能实现接近最优的对冲效果。深度对冲策略能根据市场状态动态调整对冲组合对风险因子的敞口。实验显示，即使在模型存在一定误设的情况下，其表现仍持续优于Rho对冲策略。这些结果突显了强化学习在提供更高效、更具韧性的掉期期权对冲策略方面的潜力。",
    "fetch_date": "2025-12-28",
    "id": "20251228_80dea847"
  },
  {
    "title": "Unveiling Hedge Funds: Topic Modeling and Sentiment Correlation with Fund Performance",
    "url": "https://arxiv.org/pdf/2512.06620v1",
    "source": "ArXiv",
    "date": "2025-12-07",
    "abstract": "The hedge fund industry presents significant challenges for investors due to its opacity and limited disclosure requirements. This pioneering study introduces two major innovations in financial text analysis. First, we apply topic modeling to hedge fund documents-an unexplored domain for automated text analysis-using a unique dataset of over 35,000 documents from 1,125 hedge fund managers. We compared three state-of-the-art methods: Latent Dirichlet Allocation (LDA), Top2Vec, and BERTopic. Our findings reveal that LDA with 20 topics produces the most interpretable results for human users and demonstrates higher robustness in topic assignments when the number of topics varies, while Top2Vec shows superior classification performance. Second, we establish a novel quantitative framework linking document sentiment to fund performance, transforming qualitative information traditionally requiring expert interpretation into systematic investment signals. In sentiment analysis, contrary to expectations, the general-purpose DistilBERT outperforms the finance-specific FinBERT in generating sentiment scores, demonstrating superior adaptability to diverse linguistic patterns found in hedge fund documents that extend beyond specialized financial news text. Furthermore, sentiment scores derived using DistilBERT in combination with Top2Vec show stronger correlations with subsequent fund performance compared to other model combinations. These results demonstrate that automated topic modeling and sentiment analysis can effectively process hedge fund documents, providing investors with new data-driven decision support tools.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "本研究在金融文本分析领域引入两大创新：首先，将主题建模应用于对冲基金文档这一自动化文本分析未涉足领域，使用来自1,125家对冲基金管理人的超过35,000份文档数据集，比较了潜在狄利克雷分配（LDA）、Top2Vec和BERTopic三种前沿方法。研究发现，20个主题的LDA对人类用户最具可解释性，且在主题数量变化时表现出更高鲁棒性，而Top2Vec则展现更优的分类性能。其次，建立了一个将文档情感与基金表现相关联的量化框架，将传统需要专家解读的定性信息转化为系统性投资信号。在情感分析中，通用模型DistilBERT意外地优于金融专用模型FinBERT，显示出对对冲基金多样化语言模式的更强适应性。",
    "fetch_date": "2025-12-28",
    "id": "20251228_3d108839"
  },
  {
    "title": "Hybrid Quantum-Classical Ensemble Learning for S\\&P 500 Directional Prediction",
    "url": "https://arxiv.org/pdf/2512.15738v1",
    "source": "ArXiv",
    "date": "2025-12-06",
    "abstract": "Financial market prediction is a challenging application of machine learning, where even small improvements in directional accuracy can yield substantial value. Most models struggle to exceed 55--57\\% accuracy due to high noise, non-stationarity, and market efficiency. We introduce a hybrid ensemble framework combining quantum sentiment analysis, Decision Transformer architecture, and strategic model selection, achieving 60.14\\% directional accuracy on S\\&P 500 prediction, a 3.10\\% improvement over individual models.\n  Our framework addresses three limitations of prior approaches. First, architecture diversity dominates dataset diversity: combining different learning algorithms (LSTM, Decision Transformer, XGBoost, Random Forest, Logistic Regression) on the same data outperforms training identical architectures on multiple datasets (60.14\\% vs.\\ 52.80\\%), confirmed by correlation analysis ($r>0.6$ among same-architecture models). Second, a 4-qubit variational quantum circuit enhances sentiment analysis, providing +0.8\\% to +1.5\\% gains per model. Third, smart filtering excludes weak predictors (accuracy $<52\\%$), improving ensemble performance (Top-7 models: 60.14\\% vs.\\ all 35 models: 51.2\\%).\n  We evaluate on 2020--2023 market data across seven instruments, covering diverse regimes including the COVID-19 crash and inflation-driven correction. McNemar's test confirms statistical significance ($p<0.05$). Preliminary backtesting with confidence-based filtering (6+ model consensus) yields a Sharpe ratio of 1.2 versus buy-and-hold's 0.8, demonstrating practical trading potential.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "该论文提出了一种混合量子-经典集成学习框架，用于标普500指数的方向性预测。核心创新包括：1）架构多样性优于数据集多样性——在相同数据上结合不同算法（LSTM、决策Transformer、XGBoost等）比单一架构多数据集训练效果更佳（60.14% vs. 52.80%）；2）4量子比特变分量子电路增强情感分析，为各模型带来0.8%-1.5%的准确率提升；3）智能筛选排除弱预测器（准确率<52%），优化集成性能。最终实现60.14%的方向预测准确率，较单一模型提升3.10%，对量化交易实战具有直接应用价值。",
    "fetch_date": "2025-12-28",
    "id": "20251228_fab16cfe"
  },
  {
    "title": "Deep learning approaches in Finance: Forecasting volatility and enhancing Quantitative trading strategies",
    "url": "https://etheses.whiterose.ac.uk/id/eprint/27202/",
    "source": "Scholar",
    "date": "2025-12-28",
    "abstract": "… services industry using Deep Learning architectures. The main focus is on advancing current approaches in the areas of Risk Management and Quantitative Trading. The former is …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文聚焦于深度学习在金融领域的应用，主要致力于推动风险管理与量化交易领域的现有方法。核心内容包括利用深度学习架构预测波动率，并以此增强量化交易策略。",
    "fetch_date": "2025-12-28",
    "id": "20251228_6403d992"
  },
  {
    "title": "Intraday and Post-Market Investor Sentiment for Stock Price Prediction: A Deep Learning Framework with Explainability and Quantitative Trading Strategy",
    "url": "https://www.mdpi.com/2079-8954/13/5/390",
    "source": "Scholar",
    "date": "2025-12-28",
    "abstract": "… In contrast to traditional deep learning models, which are often … Quantitative trading backtesting under the T+1 trading … Most academic studies neglect real-world trading constraints…",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文提出了一种用于股价预测的深度学习框架，结合了盘中与盘后投资者情绪分析，并具备模型可解释性。研究特别设计了考虑T+1交易制度的量化交易策略进行回测，强调了传统学术研究常忽略的实际交易约束，对实战交易具有直接应用价值。",
    "fetch_date": "2025-12-28",
    "id": "20251228_ce0d31fc"
  },
  {
    "title": "Research on quantitative investment strategies based on deep learning",
    "url": "https://www.mdpi.com/1999-4893/12/2/35",
    "source": "Scholar",
    "date": "2025-12-28",
    "abstract": "… with four trading strategies (Long Call, Short Call, Long Put, Short Put) where deep learning … mirror the impact of its accuracy on quantitative trading strategies in a straightforward way. …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "基于深度学习的量化投资策略研究，涉及四种交易策略（买入看涨期权、卖出看涨期权、买入看跌期权、卖出看跌期权），通过深度学习模型直接反映其预测准确性对量化交易策略的影响。",
    "fetch_date": "2025-12-28",
    "id": "20251228_d4332f98"
  },
  {
    "title": "Inferring Latent Market Forces: Evaluating LLM Detection of Gamma Exposure Patterns via Obfuscation Testing",
    "url": "https://arxiv.org/pdf/2512.17923v1",
    "source": "ArXiv",
    "date": "2025-12-08",
    "abstract": "We introduce obfuscation testing, a novel methodology for validating whether large language models detect structural market patterns through causal reasoning rather than temporal association. Testing three dealer hedging constraint patterns (gamma positioning, stock pinning, 0DTE hedging) on 242 trading days (95.6% coverage) of S&P 500 options data, we find LLMs achieve 71.5% detection rate using unbiased prompts that provide only raw gamma exposure values without regime labels or temporal context. The WHO-WHOM-WHAT causal framework forces models to identify the economic actors (dealers), affected parties (directional traders), and structural mechanisms (forced hedging) underlying observed market dynamics. Critically, detection accuracy (91.2%) remains stable even as economic profitability varies quarterly, demonstrating that models identify structural constraints rather than profitable patterns. When prompted with regime labels, detection increases to 100%, but the 71.5% unbiased rate validates genuine pattern recognition. Our findings suggest LLMs possess emergent capabilities for detecting complex financial mechanisms through pure structural reasoning, with implications for systematic strategy development, risk management, and our understanding of how transformer architectures process financial market dynamics.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "我们引入了一种新颖的混淆测试方法，用于验证大型语言模型是否通过因果推理而非时间关联来检测结构性市场模式。在标普500期权数据的242个交易日（覆盖95.6%）上测试三种做市商对冲约束模式（伽马持仓、股票钉住、0DTE对冲），我们发现LLM使用无偏提示（仅提供原始伽马暴露值，无制度标签或时间背景）实现了71.5%的检测率。WHO-WHOM-WHAT因果框架迫使模型识别观察到的市场动态背后的经济参与者（做市商）、受影响方（方向性交易者）和结构性机制（强制对冲）。关键的是，即使季度经济盈利能力变化，检测准确率（91.2%）保持稳定，表明模型识别的是结构性约束而非盈利模式。当提供制度标签时，检测率提升至100%，但71.5%的无偏率验证了真正的模式识别。我们的发现表明，LLM通过纯结构性推理检测复杂金融机制具有新兴能力，对系统交易有潜在影响。",
    "fetch_date": "2025-12-28",
    "id": "20251228_19f9e1af"
  },
  {
    "title": "Bayesian Modeling for Uncertainty Management in Financial Risk Forecasting and Compliance",
    "url": "https://arxiv.org/pdf/2512.15739v1",
    "source": "ArXiv",
    "date": "2025-12-06",
    "abstract": "A Bayesian analytics framework that precisely quantifies uncertainty offers a significant advance for financial risk management. We develop an integrated approach that consistently enhances the handling of risk in market volatility forecasting, fraud detection, and compliance monitoring. Our probabilistic, interpretable models deliver reliable results: We evaluate the performance of one-day-ahead 95% Value-at-Risk (VaR) forecasts on daily S&P 500 returns, with a training period from 2000 to 2019 and an out-of-sample test period spanning 2020 to 2024. Formal tests of unconditional (Kupiec) and conditional (Christoffersen) coverage reveal that an LSTM baseline achieves near-nominal calibration. In contrast, a GARCH(1,1) model with Student-t innovations underestimates tail risk. Our proposed discount-factor DLM model produces a slightly liberal VaR estimate, with evidence of clustered violations. Bayesian logistic regression improves recall and AUC-ROC for fraud detection, and a hierarchical Beta state-space model provides transparent and adaptive compliance risk assessment. The pipeline is distinguished by precise uncertainty quantification, interpretability, and GPU-accelerated analysis, delivering up to 50x speedup. Remaining challenges include sparse fraud data and proxy compliance labels, but the framework enables actionable risk insights. Future expansion will extend feature sets, explore regime-switching priors, and enhance scalable inference.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文提出了一种贝叶斯分析框架，用于金融风险预测与合规中的不确定性管理。该方法在波动率预测、欺诈检测和合规监控方面提升了风险处理能力。通过评估标普500指数日收益率的单日95%风险价值预测（训练期2000-2019，测试期2020-2024），发现LSTM基线接近名义校准，而带学生t分布的GARCH(1,1)模型低估尾部风险。提出的折扣因子DLM模型产生略宽松的VaR估计，存在聚集性违规证据。贝叶斯逻辑回归提高了欺诈检测的召回率和AUC-ROC，分层Beta状态空间模型提供了透明自适应的合规风险评估。该框架以精确的不确定性量化、可解释性和GPU加速分析为特点。",
    "fetch_date": "2025-12-28",
    "id": "20251228_29b631c7"
  },
  {
    "title": "Analysis of Contagion in China's Stock Market: A Hawkes Process Perspective",
    "url": "https://arxiv.org/pdf/2512.08000v1",
    "source": "ArXiv",
    "date": "2025-12-08",
    "abstract": "This study explores contagion in the Chinese stock market using Hawkes processes to analyze autocorrelation and cross-correlation in multivariate time series data. We examine whether market indices exhibit trending behavior and whether sector indices influence one another. By fitting self-exciting and inhibitory Hawkes processes to daily returns of indices like the Shanghai Composite, Shenzhen Component, and ChiNext, as well as sector indices (CSI Consumer, Healthcare, and Financial), we identify long-term dependencies and trending patterns, including upward, downward, and oversold rebound trends. Results show that during high trading activity, sector indices tend to sustain their trends, while low activity periods exhibit strong sector rotation. This research models stock price movements using spatiotemporal Hawkes processes, leveraging conditional intensity functions to explain sector rotation, advancing the understanding of financial contagion.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本研究使用Hawkes过程分析中国股市的传染效应，通过拟合自激励和抑制型Hawkes过程到上证综指、深证成指、创业板指及消费、医疗、金融等行业指数的日收益率数据，识别长期依赖性和趋势模式（包括上升、下降和超跌反弹趋势）。研究发现高交易活跃度期间行业指数倾向于维持趋势，低活跃度期间则呈现显著的行业轮动现象。该研究通过时空Hawkes过程建模股价变动，利用条件强度函数解释行业轮动，深化了对金融传染机制的理解。",
    "fetch_date": "2025-12-28",
    "id": "20251228_d0ecab01"
  },
  {
    "title": "Asian option valuation under price impact",
    "url": "https://arxiv.org/pdf/2512.07154v1",
    "source": "ArXiv",
    "date": "2025-12-08",
    "abstract": "We study the valuation of Asian options in a binomial market with permanent price impact, extending the Cox-Ross-Rubinstein framework under a modified risk-neutral probability. We obtain an exact pathwise representation for geometric Asian options and derive two-sided bounds for arithmetic Asian options. Our analysis identifies the no-arbitrage region in terms of hedging volumes and shows that permanent price impact systematically raises Asian option prices. Numerical examples illustrate the effect of the impact parameter and hedging volumes on the resulting prices.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文在带有永久价格影响的二项式市场中研究亚式期权的定价，扩展了修正风险中性概率下的Cox-Ross-Rubinstein框架。研究获得了几何亚式期权的精确路径表示，并推导了算术亚式期权的双边边界。分析从对冲头寸角度识别了无套利区间，表明永久价格影响会系统性提高亚式期权价格。数值示例展示了影响参数和对冲头寸对最终价格的影响。",
    "fetch_date": "2025-12-28",
    "id": "20251228_a5b016a2"
  },
  {
    "title": "Market Reactions and Information Spillovers in Bank Mergers: A Multi-Method Analysis of the Japanese Banking Sector",
    "url": "https://arxiv.org/pdf/2512.06550v1",
    "source": "ArXiv",
    "date": "2025-12-06",
    "abstract": "Major bank mergers and acquisitions (M&A) transform the financial market structure, but their valuation and spillover effects remain open to question. This study examines the market reaction to two M&A events: the 2005 creation of Mitsubishi UFJ Financial Group following the Financial Big Bang in Japan, and the 2018 merger involving Resona Holdings after the global financial crisis. The multi-method analysis in this research combines several distinct methods to explore these M&A events. An event study using the market model, the capital asset pricing model (CAPM), and the Fama-French three-factor model is implemented to estimate cumulative abnormal returns (CAR) for valuation purposes. Vector autoregression (VAR) models are used to test for Granger causality and map dynamic effects using impulse response functions (IRFs) to investigate spillovers. Propensity score matching (PSM) helps provide a causal estimate of the average treatment effect on the treated (ATT). The analysis detected a significant positive market reaction to the mergers. The findings also suggest the presence of prolonged positive spillovers to other banks, which may indicate a synergistic effect among Japanese banks. Combining these methods provides a unique perspective on M&A events in the Japanese banking sector, offering valuable insights for investors, managers, and regulators concerned with market efficiency and systemic stability",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本研究通过多方法分析评估日本银行业两次重大并购事件（2005年三菱UFJ金融集团成立与2018年Resona控股合并）的市场反应与信息溢出效应。采用事件研究法（市场模型、CAPM、Fama-French三因子模型）计算累积异常收益（CAR），运用向量自回归（VAR）模型检验格兰杰因果关系并通过脉冲响应函数（IRFs）分析动态溢出效应，辅以倾向得分匹配（PSM）估计平均处理效应（ATT）。研究发现并购产生显著正向市场反应，并存在对其他银行的持续正向溢出效应，暗示日本银行业可能存在协同效应。",
    "fetch_date": "2025-12-28",
    "id": "20251228_b46875b4"
  },
  {
    "title": "Amortizing Perpetual Options",
    "url": "https://arxiv.org/pdf/2512.06505v1",
    "source": "ArXiv",
    "date": "2025-12-06",
    "abstract": "In this work, we introduce amortizing perpetual options (AmPOs), a fungible variant of continuous-installment options suitable for exchange-based trading. Traditional installment options lapse when holders cease their payments, destroying fungibility across units of notional. AmPOs replace explicit installment payments and the need for lapsing logic with an implicit payment scheme via a deterministic decay in the claimable notional. This amortization ensures all units evolve identically, preserving fungibility. Under the Black-Scholes framework, AmPO valuation can be reduced to an equivalent vanilla perpetual American option on a dividend-paying asset. In this way, analytical expressions are possible for the exercise boundaries and risk-neutral valuations for calls and puts. These formulas and relations allow us to derive the Greeks and study comparative statics with respect to the amortization rate. Illustrative numerical case studies demonstrate how the amortization rate shapes option behavior and reveal the resulting tradeoffs in the effective volatility sensitivity.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文介绍了摊销型永续期权（AmPOs），这是一种适用于交易所交易的可替代连续分期期权变体。传统分期期权在持有人停止支付时会失效，破坏了名义金额单位间的可替代性。AmPOs通过可索赔名义金额的确定性衰减隐含支付方案，取代了显性分期付款和失效逻辑。这种摊销确保所有单位以相同方式演变，保持了可替代性。在Black-Scholes框架下，AmPO估值可简化为等价于带股息资产上的普通永续美式期权。通过这种方式，可以得出看涨和看跌期权的行权边界和风险中性估值的解析表达式。这些公式和关系使我们能够推导希腊字母，并研究相对于摊销率的比较静态。示例数值案例研究展示了摊销率如何塑造期权行为，并揭示了有效波动率敏感性中的权衡取舍。",
    "fetch_date": "2025-12-28",
    "id": "20251228_7b969bb3"
  },
  {
    "title": "Detrended cross-correlations and their random matrix limit: an example from the cryptocurrency market",
    "url": "https://arxiv.org/pdf/2512.06473v1",
    "source": "ArXiv",
    "date": "2025-12-06",
    "abstract": "Correlations in complex systems are often obscured by nonstationarity, long-range memory, and heavy-tailed fluctuations, which limit the usefulness of traditional covariance-based analyses. To address these challenges, we construct scale and fluctuation-dependent correlation matrices using the multifractal detrended cross-correlation coefficient $ρ_r$ that selectively emphasizes fluctuations of different amplitudes. We examine the spectral properties of these detrended correlation matrices and compare them to the spectral properties of the matrices calculated in the same way from synthetic Gaussian and $q$Gaussian signals. Our results show that detrending, heavy tails, and the fluctuation-order parameter $r$ jointly produce spectra, which substantially depart from the random case even under absence of cross-correlations in time series. Applying this framework to one-minute returns of 140 major cryptocurrencies from 2021-2024 reveals robust collective modes, including a dominant market factor and several sectoral components whose strength depends on the analyzed scale and fluctuation order. After filtering out the market mode, the empirical eigenvalue bulk aligns closely with the limit of random detrended cross-correlations, enabling clear identification of structurally significant outliers. Overall, the study provides a refined spectral baseline for detrended cross-correlations and offers a promising tool for distinguishing genuine interdependencies from noise in complex, nonstationary, heavy-tailed systems.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "复杂系统中的相关性常被非平稳性、长程记忆和重尾波动所掩盖，限制了传统协方差分析的有效性。为应对这些挑战，本文使用多分形去趋势互相关系数ρ_r构建了尺度与波动依赖的相关矩阵，该系数能选择性地强调不同幅度的波动。作者检验了这些去趋势相关矩阵的谱特性，并与从合成高斯及q高斯信号以相同方式计算得到的矩阵谱特性进行比较。结果表明，即使在时间序列不存在互相关的情况下，去趋势处理、重尾分布和波动阶参数r共同产生的谱也与随机情况显著偏离。将该框架应用于2021-2024年间140种主要加密货币的一分钟收益率数据，揭示了稳健的集体模式，包括一个主导的市场因子和几个行业成分，其强度取决于分析的尺度和波动阶。在滤除市场模式后，经验特征值的主体部分与随机矩阵理论预测的极限分布紧密对齐。",
    "fetch_date": "2025-12-28",
    "id": "20251228_ae9ae498"
  },
  {
    "title": "Wealth or Stealth? The Camouflage Effect in Insider Trading",
    "url": "https://arxiv.org/pdf/2512.06309v1",
    "source": "ArXiv",
    "date": "2025-12-06",
    "abstract": "We consider a Kyle-type model where insider trading takes place among a potentially large population of liquidity traders and is subject to legal penalties. Insiders exploit the liquidity provided by the trading masses to \"camouflage\" their actions and balance expected wealth with the necessary stealth to avoid detection. Under a diverse spectrum of prosecution schemes, we establish the existence of equilibria for arbitrary population sizes and a unique limiting equilibrium. A convergence analysis determines the scale of insider trading by a stealth index $γ$, revealing that the equilibrium can be closely approximated by a simple limit due to diminished price informativeness. Empirical aspects are derived from two calibration experiments using non-overlapping data sets spanning from 1980 to 2018, which underline the indispensable role of a large population in insider trading models with legal risk, along with important implications for the incidence of stealth trading and the deterrent effect of legal enforcement.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文构建了一个Kyle型模型，研究内幕交易者在面临法律处罚风险时，如何利用大量流动性交易者提供的流动性来“伪装”其交易行为，在预期财富与避免被发现的必要隐蔽性之间取得平衡。通过分析多种起诉方案，证明了任意市场规模下均衡的存在性及唯一的极限均衡。收敛分析通过隐蔽指数γ确定内幕交易规模，并揭示由于价格信息性减弱，均衡可被一个简单极限近似逼近。实证部分基于1980年至2018年的两个非重叠数据集进行校准实验，强调了在考虑法律风险的内幕交易模型中大规模交易群体的不可或缺作用，并对隐蔽交易的发生频率及法律执行的威慑效应提出了重要启示。",
    "fetch_date": "2025-12-28",
    "id": "20251228_6e05cc4e"
  },
  {
    "title": "Not All Factors Crowd Equally: Modeling, Measuring, and Trading on Alpha Decay",
    "url": "https://arxiv.org/pdf/2512.11913v1",
    "source": "ArXiv",
    "date": "2025-12-11",
    "abstract": "We derive a specific functional form for factor alpha decay -- hyperbolic decay alpha(t) = K/(1+lambda*t) -- from a game-theoretic equilibrium model, and test it against linear and exponential alternatives. Using eight Fama-French factors (1963--2024), we find: (1) Hyperbolic decay fits mechanical factors. Momentum exhibits clear hyperbolic decay (R^2 = 0.65), outperforming linear (0.51) and exponential (0.61) baselines -- validating the equilibrium foundation. (2) Not all factors crowd equally. Mechanical factors (momentum, reversal) fit the model; judgment-based factors (value, quality) do not -- consistent with a signal-ambiguity taxonomy paralleling Hua and Sun's \"barriers to entry.\" (3) Crowding accelerated post-2015. Out-of-sample, the model over-predicts remaining alpha (0.30 vs. 0.15), correlating with factor ETF growth (rho = -0.63). (4) Average returns are efficiently priced. Crowding-based factor selection fails to generate alpha (Sharpe: 0.22 vs. 0.39 factor momentum benchmark). (5) Crowding predicts tail risk. Out-of-sample (2001--2024), crowded reversal factors show 1.7--1.8x higher crash probability (bottom decile returns), while crowded momentum shows lower crash risk (0.38x, p = 0.006). Our findings extend equilibrium crowding models (DeMiguel et al.) to temporal dynamics and show that crowding predicts crashes, not means -- useful for risk management, not alpha generation.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "该论文从博弈论均衡模型推导出因子阿尔法衰减的特定函数形式——双曲衰减alpha(t)=K/(1+lambda*t)，并在线性和指数衰减基准上进行检验。基于八个Fama-French因子（1963-2024）的研究发现：（1）机械因子（如动量）呈现清晰的双曲衰减（R²=0.65），验证了均衡基础；（2）因子拥挤存在异质性——机械因子（动量、反转）符合模型，而基于判断的因子（价值、质量）则不符合，这与Hua和Sun的“进入壁垒”信号模糊度分类一致；（3）2015年后拥挤加速，样本外模型高估剩余阿尔法（0.30 vs. 0.15），且与因子ETF增长负相关（ρ=-0.63）；（4）平均收益已被有效定价，基于拥挤的因子选择未能产生阿尔法（夏普比率：0.22 vs. 因子动量基准0.39）；（5）拥挤可预测尾部风险——样本外（2001-2024）拥挤的反转因子崩盘概率高1.7-1.8倍，而拥挤的动量因子崩盘风险较低。",
    "fetch_date": "2025-12-27",
    "id": "20251227_0101e588"
  },
  {
    "title": "Risk-Aware Financial Forecasting Enhanced by Machine Learning and Intuitionistic Fuzzy Multi-Criteria Decision-Making",
    "url": "https://arxiv.org/pdf/2512.17936v1",
    "source": "ArXiv",
    "date": "2025-12-11",
    "abstract": "In the face of increasing financial uncertainty and market complexity, this study presents a novel risk-aware financial forecasting framework that integrates advanced machine learning techniques with intuitionistic fuzzy multi-criteria decision-making (MCDM). Tailored to the BIST 100 index and validated through a case study of a major defense company in Türkiye, the framework fuses structured financial data, unstructured text data, and macroeconomic indicators to enhance predictive accuracy and robustness. It incorporates a hybrid suite of models, including extreme gradient boosting (XGBoost), long short-term memory (LSTM) network, graph neural network (GNN), to deliver probabilistic forecasts with quantified uncertainty. The empirical results demonstrate high forecasting accuracy, with a net profit mean absolute percentage error (MAPE) of 3.03% and narrow 95% confidence intervals for key financial indicators. The risk-aware analysis indicates a favorable risk-return profile, with a Sharpe ratio of 1.25 and a higher Sortino ratio of 1.80, suggesting relatively low downside volatility and robust performance under market fluctuations. Sensitivity analysis shows that the key financial indicator predictions are highly sensitive to variations of inflation, interest rates, sentiment, and exchange rates. Additionally, using an intuitionistic fuzzy MCDM approach, combining entropy weighting, evaluation based on distance from the average solution (EDAS), and the measurement of alternatives and ranking according to compromise solution (MARCOS) methods, the tabular data learning network (TabNet) outperforms the other models and is identified as the most suitable candidate for deployment. Overall, the findings of this work highlight the importance of integrating advanced machine learning, risk quantification, and fuzzy MCDM methodologies in financial forecasting, particularly in emerging markets.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "面对日益增长的金融不确定性和市场复杂性，本研究提出了一种新颖的风险感知金融预测框架，该框架将先进的机器学习技术与直觉模糊多准则决策（MCDM）相结合。该框架专为BIST 100指数设计，并通过土耳其一家主要国防公司的案例研究进行验证，融合了结构化金融数据、非结构化文本数据和宏观经济指标，以提高预测准确性和鲁棒性。它包含一套混合模型，包括极端梯度提升（XGBoost）、长短期记忆（LSTM）网络和图神经网络（GNN），以提供具有量化不确定性的概率预测。实证结果显示高预测准确性，净利润平均绝对百分比误差（MAPE）为3.03%，关键财务指标的95%置信区间较窄。风险感知分析显示有利的风险回报特征，夏普比率为1.25，索提诺比率更高为1.80，表明在市场波动下相对较低的下行波动性和稳健表现。敏感性分析表明关键财务指标具有稳定性。",
    "fetch_date": "2025-12-27",
    "id": "20251227_96d3f766"
  },
  {
    "title": "Exploratory Mean-Variance with Jumps: An Equilibrium Approach",
    "url": "https://arxiv.org/pdf/2512.09224v1",
    "source": "ArXiv",
    "date": "2025-12-10",
    "abstract": "Revisiting the continuous-time Mean-Variance (MV) Portfolio Optimization problem, we model the market dynamics with a jump-diffusion process and apply Reinforcement Learning (RL) techniques to facilitate informed exploration within the control space. We recognize the time-inconsistency of the MV problem and adopt the time-inconsistent control (TIC) approach to analytically solve for an exploratory equilibrium investment policy, which is a Gaussian distribution centered on the equilibrium control of the classical MV problem. Our approach accounts for time-inconsistent preferences and actions, and our equilibrium policy is the best option an investor can take at any given time during the investment period. Moreover, we leverage the martingale properties of the equilibrium policy, design a RL model, and propose an Actor-Critic RL algorithm. All of our RL model parameters converge to the corresponding true values in a simulation study. Our numerical study on 24 years of real market data shows that the proposed RL model is profitable in 13 out of 14 tests, demonstrating its practical applicability in real world investment.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "本文重新审视连续时间均值-方差（MV）投资组合优化问题，采用跳跃扩散过程建模市场动态，并应用强化学习（RL）技术在控制空间内进行知情探索。针对MV问题的时间不一致性，采用时间不一致控制（TIC）方法解析求解探索性均衡投资策略——一个以经典MV问题均衡控制为中心的高斯分布。该策略考虑了时间不一致的偏好与行动，是投资期内任一时刻的最佳选择。此外，利用均衡策略的鞅性质设计RL模型，提出Actor-Critic RL算法。模拟研究中所有RL模型参数均收敛至真实值，基于24年真实市场数据的数值研究表明，所提RL模型在14次测试中13次盈利，证明了其在实际投资中的适用性。",
    "fetch_date": "2025-12-27",
    "id": "20251227_b4ce1604"
  },
  {
    "title": "Deep Learning Enhanced Multi-Day Turnover Quantitative Trading Algorithm for Chinese A-Share Market",
    "url": "https://arxiv.org/abs/2506.06356",
    "source": "Scholar",
    "date": "2025-12-27",
    "abstract": "… -day turnover quantitative trading algorithm that integrates advanced deep learning techniques … Index Terms—quantitative trading, deep learning, crosssectional prediction, multi-day …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "深度学习增强的多日换手率量化交易算法应用于中国A股市场。该算法整合了先进的深度学习技术，专注于横截面预测和多日交易策略。",
    "fetch_date": "2025-12-27",
    "id": "20251227_c3728bb7"
  },
  {
    "title": "Intelligent optimization based multi-factor deep learning stock selection model and quantitative trading strategy",
    "url": "https://www.mdpi.com/2227-7390/10/4/566",
    "source": "Scholar",
    "date": "2025-12-27",
    "abstract": "… Thirdly, this paper designs and implements a quantitative trading strategy. Based on the CS-GRU stock selection model, this paper designs and implements a quantitative trading …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "本文提出了一种基于智能优化的多因子深度学习选股模型与量化交易策略。首先，构建了CS-GRU选股模型（结合了Cuckoo Search优化算法与门控循环单元网络），用于预测股票收益。其次，基于该模型设计并实施了量化交易策略，包括信号生成、仓位管理和风险控制等实战环节。最后，通过回测验证了策略的有效性，表明该模型在实战交易中具有潜在应用价值。",
    "fetch_date": "2025-12-27",
    "id": "20251227_887f4f01"
  },
  {
    "title": "Research on Deep Learning-Based Quantitative Trading Models",
    "url": "https://link.springer.com/chapter/10.1007/978-3-031-99477-7_12",
    "source": "Scholar",
    "date": "2025-12-27",
    "abstract": "… This paper examines the role of quantitative trading in finance and the potential applications of deep learning. Quantitative trading automates investment strategies using mathematical …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "本文探讨了量化交易在金融领域的作用及深度学习的潜在应用。量化交易利用数学模型自动化投资策略...",
    "fetch_date": "2025-12-27",
    "id": "20251227_ed097bf0"
  },
  {
    "title": "Sustainability, accuracy, fairness, and explainability (safe) machine learning in quantitative trading",
    "url": "https://www.mdpi.com/2227-7390/13/3/442",
    "source": "Scholar",
    "date": "2025-12-27",
    "abstract": "… based signal strategies: those based on deep learning models and those grounded in classical machine learning techniques. The deep learning models employed in this research were …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文探讨了可持续性、准确性、公平性和可解释性（SAFE）机器学习在量化交易中的应用，比较了基于深度学习模型和经典机器学习技术的信号策略。研究采用的深度学习模型包括...，对实战交易具有较高参考价值。",
    "fetch_date": "2025-12-27",
    "id": "20251227_020ded1a"
  },
  {
    "title": "Reinforcement Learning in Financial Decision Making: A Systematic Review of Performance, Challenges, and Implementation Strategies",
    "url": "https://arxiv.org/pdf/2512.10913v1",
    "source": "ArXiv",
    "date": "2025-12-11",
    "abstract": "Reinforcement learning (RL) is an innovative approach to financial decision making, offering specialized solutions to complex investment problems where traditional methods fail. This review analyzes 167 articles from 2017--2025, focusing on market making, portfolio optimization, and algorithmic trading. It identifies key performance issues and challenges in RL for finance. Generally, RL offers advantages over traditional methods, particularly in market making. This study proposes a unified framework to address common concerns such as explainability, robustness, and deployment feasibility. Empirical evidence with synthetic data suggests that implementation quality and domain knowledge often outweigh algorithmic complexity. The study highlights the need for interpretable RL architectures for regulatory compliance, enhanced robustness in nonstationary environments, and standardized benchmarking protocols. Organizations should focus less on algorithm sophistication and more on market microstructure, regulatory constraints, and risk management in decision-making.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "强化学习（RL）作为一种金融决策的创新方法，为传统方法难以解决的复杂投资问题提供了专门解决方案。该综述分析了2017-2025年的167篇文章，重点关注做市、投资组合优化和算法交易。研究发现RL在金融应用中存在关键性能问题和挑战，但在做市等领域相比传统方法具有优势。研究提出了一个统一框架来解决可解释性、鲁棒性和部署可行性等常见问题。基于合成数据的实证证据表明，实施质量和领域知识通常比算法复杂性更重要。研究强调需要可解释的RL架构以满足监管要求、增强非平稳环境下的鲁棒性，并建立标准化基准测试协议。建议机构应减少对算法复杂性的关注，更多关注市场微观结构、监管约束和风险管理。",
    "fetch_date": "2025-12-27",
    "id": "20251227_801c29bb"
  },
  {
    "title": "Local and Global Balance in Financial Correlation Networks: an Application to Investment Decisions",
    "url": "https://arxiv.org/pdf/2512.10606v1",
    "source": "ArXiv",
    "date": "2025-12-11",
    "abstract": "The global balance is a well-known indicator of the behavior of a signed network. Recent literature has introduced the concept of local balance as a measure of the contribution of a single node to the overall balance of the network. In the present research, we investigate the potential of using deviations of local balance from global balance as a criterion for selecting outperforming assets. The underlying idea is that, during financial crises, most assets in the investment universe behave similarly: losses are severe and widespread, and the global balance of the correlation-based signed network reaches its maximum value. Under such circumstances, standard diversification (mainly related to portfolio size) is unable to reduce risk or limit losses. Therefore, it may be useful to concentrate portfolio exposures on the few assets - if such assets exist-that behave differently from the rest of the market. We argue that these assets are those for which the local balance strongly departs from the global balance of the underlying signed network. The paper supports this hypothesis through an application using real financial data. The results, in both descriptive and predictive contexts, confirm the proposed intuition.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文提出了一种基于金融相关网络局部平衡与全局平衡偏离度的资产选择方法。核心观点是：在金融危机期间，大多数资产表现趋同，传统分散化策略失效；此时，应集中投资于那些局部平衡与网络全局平衡显著偏离的资产，因为这些资产的市场行为与整体市场不同。研究通过真实金融数据验证了这一假设，表明该方法在描述性和预测性场景下均能识别出表现优异的资产。",
    "fetch_date": "2025-12-27",
    "id": "20251227_9fed57fe"
  },
  {
    "title": "A New Application of Hoeffding's Inequality Can Give Traders Early Warning of Financial Regime Change",
    "url": "https://arxiv.org/pdf/2512.08851v1",
    "source": "ArXiv",
    "date": "2025-12-09",
    "abstract": "Hoeffding's Inequality provides the maximum probability that a series of n draws from a bounded random variable differ from the variable's true expectation u by more than given tolerance t. The random variable is typically the error rate of a classifier in machine learning applications. Here, a trading strategy is premised on the assumption of an underlying distribution of causal factors, in other words, a market regime, and the random variable is the performance of that trading strategy. A larger deviation of observed performance from the trader's expectation u can be characterized as a lower probability that the financial regime supporting that strategy remains in force, and a higher probability of financial regime change. The changing Hoeffding probabilities can be used as an early warning indicator of this change.",
    "broker": "Cornell Univ",
    "score": 5,
    "summary": "本文提出了一种将霍夫丁不等式应用于量化交易的新方法。该方法将交易策略的绩效视为有界随机变量，通过计算观察到的绩效与预期绩效之间的偏差概率，来评估当前市场状态（即金融制度）是否发生变化。当偏差增大时，霍夫丁概率降低，表明支持该策略的市场制度可能不再有效，从而为金融制度变更提供早期预警。该方法为基于市场制度假设的交易策略提供了一种理论上的风险监控工具。",
    "fetch_date": "2025-12-27",
    "id": "20251227_d6fbced2"
  },
  {
    "title": "Pareto-optimal reinsurance under dependence uncertainty",
    "url": "https://arxiv.org/pdf/2512.11430v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "This paper studies Pareto-optimal reinsurance design in a monopolistic market with multiple primary insurers and a single reinsurer, all with heterogeneous risk preferences. The risk preferences are characterized by a family of risk measures, called Range Value-at-Risk (RVaR), which includes both Value-at-Risk (VaR) and Expected Shortfall (ES) as special cases. Recognizing the practical difficulty of accurately estimating the dependence structure among the insurers' losses, we adopt a robust optimization approach that assumes the marginal distributions are known while leaving the dependence structure unspecified. We provide a complete characterization of optimal indemnity schedules under the worst-case scenario, showing that the infinite-dimensional optimization problem can be reduced to a tractable finite-dimensional problem involving only two or three parameters for each indemnity function. Additionally, for independent and identically distributed risks, we exploit the argument of asymptotic normality to derive optimal two-parameter layer contracts. Finally, numerical applications are considered in a two-insurer setting to illustrate the influence of the dependence structures and heterogeneous risk tolerances on optimal strategies and the corresponding risk evaluation.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文研究垄断市场中多个原保险公司与单一再保险公司之间的帕累托最优再保险设计，各方具有异质性风险偏好。风险偏好由一系列风险度量（称为范围风险价值，RVaR）表征，该度量包含风险价值（VaR）和预期损失（ES）作为特例。考虑到准确估计保险公司损失间依赖结构的实际困难，作者采用鲁棒优化方法，假设边际分布已知而依赖结构未指定。在最坏情况下，作者完整刻画了最优赔偿方案，表明无限维优化问题可简化为仅涉及每个赔偿函数两到三个参数的可处理有限维问题。此外，对于独立同分布风险，作者利用渐近正态性论证推导出最优两参数分层合约。最后，通过双保险公司设置的数值应用说明了依赖结构的影响。",
    "fetch_date": "2025-12-27",
    "id": "20251227_80cceaa5"
  },
  {
    "title": "Generative AI for Analysts",
    "url": "https://arxiv.org/pdf/2512.19705v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "We study how generative artificial intelligence (AI) transforms the work of financial analysts. Using the 2023 launch of FactSet's AI platform as a natural experiment, we find that adoption produces markedly richer and more comprehensive reports -- featuring 40% more distinct information sources, 34% broader topical coverage, and 25% greater use of advanced analytical methods -- while also improving timeliness. However, forecast errors rise by 59% as AI-assisted reports convey a more balanced mix of positive and negative information that is harder to synthesize, particularly for analysts facing heavier cognitive demands. Placebo tests using other data vendors confirm that these effects are unique to FactSet's AI integration. Overall, our findings reveal both the productivity gains and cognitive limits of generative AI in financial information production.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本研究探讨生成式人工智能（AI）如何改变金融分析师的工作。以2023年FactSet AI平台上线为自然实验，发现采用AI后报告内容显著丰富全面——信息源增加40%，主题覆盖扩大34%，高级分析方法使用提升25%，同时时效性改善。然而，预测误差上升59%，因为AI辅助报告呈现更平衡的正负面信息，尤其对认知负荷较重的分析师更难整合。使用其他数据供应商的安慰剂测试证实这些效应是FactSet AI集成独有的。总体而言，研究揭示了生成式AI在金融信息生产中既带来生产力提升，也存在认知局限。",
    "fetch_date": "2025-12-27",
    "id": "20251227_778da003"
  },
  {
    "title": "Option-Implied Zero-Coupon Yields: Unifying Bond and Equity Markets",
    "url": "https://arxiv.org/pdf/2512.10823v1",
    "source": "ArXiv",
    "date": "2025-12-11",
    "abstract": "This paper addresses a critical inconsistency in models of the term structure of interest rates (TSIR), where zero-coupon bonds are priced under risk-neutral measures distinct from those used in equity markets. We propose a unified TSIR framework that treats zero-coupon bonds as European options with deterministic payoffs ensuring that they are priced under the same risk-neutral measure that governs equity derivatives. Using put-call parity, we extract zero-coupon bond implied yield curves from S&P 500 index options and compare them with the US daily treasury par yield curves. As the implied yield curves contain maturity time T and strike price K as independent variables, we investigate the K-dependence of the implied yield curve. Our findings, that at-the-money, option-implied yield curves provide the closest match to treasury par yield curves, support the view that the equity options market contains information that is highly relevant for the TSIR. By insisting that the risk-neutral measure used for bond valuation is the same as that revealed by equity derivatives, we offer a new organizing principle for future TSIR research.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文针对利率期限结构模型中的关键不一致性提出解决方案，即零息债券与权益衍生品使用不同的风险中性测度定价。作者提出统一框架，将零息债券视为具有确定性收益的欧式期权，确保其与权益衍生品在同一风险中性测度下定价。利用看跌-看涨平价关系，从标普500指数期权中提取零息债券隐含收益率曲线，并与美国国债平价收益率曲线比较。研究发现，平值期权隐含收益率曲线与国债曲线最接近，表明权益期权市场包含对利率期限结构高度相关的信息。该框架为未来TSIR研究提供了新的组织原则。",
    "fetch_date": "2025-12-27",
    "id": "20251227_d45f5bf0"
  },
  {
    "title": "Volatility time series modeling by single-qubit quantum circuit learning",
    "url": "https://arxiv.org/pdf/2512.10584v1",
    "source": "ArXiv",
    "date": "2025-12-11",
    "abstract": "We employ single-qubit quantum circuit learning (QCL) to model the dynamics of volatility time series. To assess its effectiveness, we generate synthetic data using the Rational GARCH model, which is specifically designed to capture volatility asymmetry. Our results show that QCL-based volatility predictions preserve the negative return-volatility correlation, a hallmark of asymmetric volatility dynamics. Moreover, analysis of the Hurst exponent and multifractal characteristics indicates that the predicted series, like the original synthetic data, exhibits anti-persistent behavior and retains its multifractal structure.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该研究采用单量子比特量子电路学习（QCL）对波动率时间序列进行建模。通过使用专门捕捉波动率不对称性的Rational GARCH模型生成合成数据进行评估，结果表明基于QCL的波动率预测保留了负收益-波动率相关性（这是不对称波动率动态的标志特征）。此外，对赫斯特指数和多重分形特征的分析表明，预测序列与原始合成数据类似，表现出反持续性行为并保留了其多重分形结构。",
    "fetch_date": "2025-12-27",
    "id": "20251227_568b9ce8"
  },
  {
    "title": "Reinforcement Learning for Monetary Policy Under Macroeconomic Uncertainty: Analyzing Tabular and Function Approximation Methods",
    "url": "https://arxiv.org/pdf/2512.17929v1",
    "source": "ArXiv",
    "date": "2025-12-09",
    "abstract": "We study how a central bank should dynamically set short-term nominal interest rates to stabilize inflation and unemployment when macroeconomic relationships are uncertain and time-varying. We model monetary policy as a sequential decision-making problem where the central bank observes macroeconomic conditions quarterly and chooses interest rate adjustments. Using publically accessible historical Federal Reserve Economic Data (FRED), we construct a linear-Gaussian transition model and implement a discrete-action Markov Decision Process with a quadratic loss reward function. We chose to compare nine different reinforcement learning style approaches against Taylor Rule and naive baselines, including tabular Q-learning variants, SARSA, Actor-Critic, Deep Q-Networks, Bayesian Q-learning with uncertainty quantification, and POMDP formulations with partial observability. Surprisingly, standard tabular Q-learning achieved the best performance (-615.13 +- 309.58 mean return), outperforming both enhanced RL methods and traditional policy rules. Our results suggest that while sophisticated RL techniques show promise for monetary policy applications, simpler approaches may be more robust in this domain, highlighting important challenges in applying modern RL to macroeconomic policy.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "我们研究了在宏观经济关系不确定且随时间变化的情况下，中央银行应如何动态设定短期名义利率以稳定通胀和失业率。我们将货币政策建模为一个序贯决策问题，中央银行每季度观察宏观经济状况并选择利率调整。使用公开可用的历史联邦储备经济数据（FRED），我们构建了一个线性高斯转移模型，并实现了一个具有二次损失奖励函数的离散动作马尔可夫决策过程。我们选择了九种不同的强化学习方法与泰勒规则和朴素基线进行比较，包括表格Q学习变体、SARSA、Actor-Critic、深度Q网络、具有不确定性量化的贝叶斯Q学习以及具有部分可观测性的POMDP公式。令人惊讶的是，标准的表格Q学习取得了最佳性能（-615.13 ± 309.58 平均回报），优于增强的RL方法和传统政策规则。我们的结果表明，虽然复杂的RL技术在货币政策应用中显示出前景，但更简单的方法在应对不确定性时可能更稳健。",
    "fetch_date": "2025-12-27",
    "id": "20251227_ebb24070"
  },
  {
    "title": "EXFormer: A Multi-Scale Trend-Aware Transformer with Dynamic Variable Selection for Foreign Exchange Returns Prediction",
    "url": "https://arxiv.org/pdf/2512.12727v1",
    "source": "ArXiv",
    "date": "2025-12-14",
    "abstract": "Accurately forecasting daily exchange rate returns represents a longstanding challenge in international finance, as the exchange rate returns are driven by a multitude of correlated market factors and exhibit high-frequency fluctuations. This paper proposes EXFormer, a novel Transformer-based architecture specifically designed for forecasting the daily exchange rate returns. We introduce a multi-scale trend-aware self-attention mechanism that employs parallel convolutional branches with differing receptive fields to align observations on the basis of local slopes, preserving long-range dependencies while remaining sensitive to regime shifts. A dynamic variable selector assigns time-varying importance weights to 28 exogenous covariates related to exchange rate returns, providing pre-hoc interpretability. An embedded squeeze-and-excitation block recalibrates channel responses to emphasize informative features and depress noise in the forecasting. Using the daily data for EUR/USD, USD/JPY, and GBP/USD, we conduct out-of-sample evaluations across five different sliding windows. EXFormer consistently outperforms the random walk and other baselines, improving directional accuracy by a statistically significant margin of up to 8.5--22.8%. In nearly one year of trading backtests, the model converts these gains into cumulative returns of 18%, 25%, and 18% for the three pairs, with Sharpe ratios exceeding 1.8. When conservative transaction costs and slippage are accounted for, EXFormer retains cumulative returns of 7%, 19%, and 9%, while other baselines achieve negative. The robustness checks further confirm the model's superiority under high-volatility and bear-market regimes. EXFormer furnishes both economically valuable forecasts and transparent, time-varying insights into the drivers of exchange rate dynamics for international investors, corporations, and central bank practitioners.",
    "broker": "Cornell Univ",
    "score": 9,
    "summary": "EXFormer：一种用于外汇收益率预测的多尺度趋势感知Transformer，具有动态变量选择功能。该论文提出了一种新颖的基于Transformer的架构，专门用于预测每日汇率收益率。它引入了多尺度趋势感知自注意力机制，采用具有不同感受野的并行卷积分支，以基于局部斜率对齐观测值，在保持长程依赖性的同时对制度转换保持敏感。动态变量选择器为28个与汇率收益率相关的外生协变量分配时变重要性权重，提供先验可解释性。嵌入的挤压-激励块重新校准通道响应，以强调信息特征并抑制预测中的噪声。使用欧元/美元、美元/日元和英镑/美元的每日数据，在五个不同的滑动窗口上进行了样本外评估。EXFormer始终优于随机游走和其他基线模型，提高了方向准确性。",
    "fetch_date": "2025-12-26",
    "id": "20251226_95743fd6"
  },
  {
    "title": "Stochastic Volatility Modelling with LSTM Networks: A Hybrid Approach for S&P 500 Index Volatility Forecasting",
    "url": "https://arxiv.org/pdf/2512.12250v1",
    "source": "ArXiv",
    "date": "2025-12-13",
    "abstract": "Accurate volatility forecasting is essential in banking, investment, and risk management, because expectations about future market movements directly influence current decisions. This study proposes a hybrid modelling framework that integrates a Stochastic Volatility model with a Long Short Term Memory neural network. The SV model improves statistical precision and captures latent volatility dynamics, especially in response to unforeseen events, while the LSTM network enhances the model's ability to detect complex nonlinear patterns in financial time series. The forecasting is conducted using daily data from the S and P 500 index, covering the period from January 1 1998 to December 31 2024. A rolling window approach is employed to train the model and generate one step ahead volatility forecasts. The performance of the hybrid SV-LSTM model is evaluated through both statistical testing and investment simulations. The results show that the hybrid approach outperforms both the standalone SV and LSTM models and contributes to the development of volatility modelling techniques, providing a foundation for improving risk assessment and strategic investment planning in the context of the S and P 500.",
    "broker": "Cornell Univ",
    "score": 9,
    "summary": "该研究提出了一种混合建模框架，将随机波动率模型与长短期记忆神经网络相结合，用于标普500指数的波动率预测。SV模型提升了统计精度并捕捉了潜在的波动动态，特别是在应对突发事件时；LSTM网络则增强了模型检测金融时间序列中复杂非线性模式的能力。研究采用滚动窗口方法训练模型并生成一步超前波动率预测，通过统计测试和投资模拟评估了混合SV-LSTM模型的性能。结果表明，该混合方法优于单独的SV和LSTM模型，为改进风险评估和战略投资规划提供了基础。",
    "fetch_date": "2025-12-26",
    "id": "20251226_36f39515"
  },
  {
    "title": "Deep Hedging with Reinforcement Learning: A Practical Framework for Option Risk Management",
    "url": "https://arxiv.org/pdf/2512.12420v1",
    "source": "ArXiv",
    "date": "2025-12-13",
    "abstract": "We present a reinforcement-learning (RL) framework for dynamic hedging of equity index option exposures under realistic transaction costs and position limits. We hedge a normalized option-implied equity exposure (one unit of underlying delta, offset via SPY) by trading the underlying index ETF, using the option surface and macro variables only as state information and not as a direct pricing engine. Building on the \"deep hedging\" paradigm of Buehler et al. (2019), we design a leak-free environment, a cost-aware reward function, and a lightweight stochastic actor-critic agent trained on daily end-of-day panel data constructed from SPX/SPY implied volatility term structure, skew, realized volatility, and macro rate context. On a fixed train/validation/test split, the learned policy improves risk-adjusted performance versus no-hedge, momentum, and volatility-targeting baselines (higher point-estimate Sharpe); only the GAE policy's test-sample Sharpe is statistically distinguishable from zero, although confidence intervals overlap with a long-SPY benchmark so we stop short of claiming formal dominance. Turnover remains controlled and the policy is robust to doubled transaction costs. The modular codebase, comprising a data pipeline, simulator, and training scripts, is engineered for extensibility to multi-asset overlays, alternative objectives (e.g., drawdown or CVaR), and intraday data. From a portfolio management perspective, the learned overlay is designed to sit on top of an existing SPX or SPY allocation, improving the portfolio's mean-variance trade-off with controlled turnover and drawdowns. We discuss practical implications for portfolio overlays and outline avenues for future work.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "本文提出了一种基于强化学习的深度对冲框架，用于在现实交易成本和头寸限制下动态管理股指期权风险敞口。该方法采用无泄漏环境设计、成本感知的奖励函数和轻量级随机演员-评论家智能体，使用SPX/SPY隐含波动率期限结构、偏度、已实现波动率和宏观利率等日频面板数据进行训练。在固定训练/验证/测试集划分下，学习到的策略相比无对冲、动量策略和波动率目标基准展现出更高的风险调整后绩效（夏普比率点估计值更高），且交易周转率受控，策略对加倍交易成本具有稳健性。",
    "fetch_date": "2025-12-26",
    "id": "20251226_dfaa45fb"
  },
  {
    "title": "VERAFI: Verified Agentic Financial Intelligence through Neurosymbolic Policy Generation",
    "url": "https://arxiv.org/pdf/2512.14744v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "Financial AI systems suffer from a critical blind spot: while Retrieval-Augmented Generation (RAG) excels at finding relevant documents, language models still generate calculation errors and regulatory violations during reasoning, even with perfect retrieval. This paper introduces VERAFI (Verified Agentic Financial Intelligence), an agentic framework with neurosymbolic policy generation for verified financial intelligence. VERAFI combines state-of-the-art dense retrieval and cross-encoder reranking with financial tool-enabled agents and automated reasoning policies covering GAAP compliance, SEC requirements, and mathematical validation. Our comprehensive evaluation on FinanceBench demonstrates remarkable improvements: while traditional dense retrieval with reranking achieves only 52.4\\% factual correctness, VERAFI's integrated approach reaches 94.7\\%, an 81\\% relative improvement. The neurosymbolic policy layer alone contributes a 4.3 percentage point gain over pure agentic processing, specifically targeting persistent mathematical and logical errors. By integrating financial domain expertise directly into the reasoning process, VERAFI offers a practical pathway toward trustworthy financial AI that meets the stringent accuracy demands of regulatory compliance, investment decisions, and risk management.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "论文《VERAFI：通过神经符号策略生成实现可验证的代理金融智能》针对金融AI系统在推理中产生计算错误和违反监管规定（即使检索完美）的盲点，提出了一个结合神经符号策略生成的代理框架。VERAFI融合了最先进的密集检索与交叉编码器重排序、支持金融工具的代理，以及覆盖GAAP合规性、SEC要求和数学验证的自动化推理策略。在FinanceBench上的综合评估显示显著改进：传统密集检索加重排序仅实现52.4%的事实正确率，而VERAFI的综合方法达到94.7%，相对提升81%。神经符号策略层本身比纯代理处理贡献了4.3个百分点的增益，专门针对持续的数学和逻辑错误。通过将金融领域专业知识直接整合到推理过程中，VERAFI为在实战交易中实现可信赖的金融智能提供了一条实用路径。",
    "fetch_date": "2025-12-26",
    "id": "20251226_b47b6951"
  },
  {
    "title": "Transfer Learning (Il)liquidity",
    "url": "https://arxiv.org/pdf/2512.11731v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "The estimation of the Risk Neutral Density (RND) implicit in option prices is challenging, especially in illiquid markets. We introduce the Deep Log-Sum-Exp Neural Network, an architecture that leverages Deep and Transfer learning to address RND estimation in the presence of irregular and illiquid strikes. We prove key statistical properties of the model and the consistency of the estimator. We illustrate the benefits of transfer learning to improve the estimation of the RND in severe illiquidity conditions through Monte Carlo simulations, and we test it empirically on SPX data, comparing it with popular estimation methods. Overall, our framework shows recovery of the RND in conditions of extreme illiquidity with as few as three option quotes.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "论文《迁移学习（非）流动性》提出了一种用于估计期权价格中隐含风险中性密度（RND）的深度对数求和指数神经网络架构，特别针对非流动性和不规则行权价市场。该模型利用深度学习和迁移学习技术，在极端流动性不足条件下（仅需三个期权报价）仍能有效恢复RND，并通过蒙特卡洛模拟和SPX数据实证验证了其优于传统方法的性能。",
    "fetch_date": "2025-12-26",
    "id": "20251226_f3dbe600"
  },
  {
    "title": "What's the Price of Monotonicity? A Multi-Dataset Benchmark of Monotone-Constrained Gradient Boosting for Credit PD",
    "url": "https://arxiv.org/pdf/2512.17945v1",
    "source": "ArXiv",
    "date": "2025-12-14",
    "abstract": "Financial institutions face a trade-off between predictive accuracy and interpretability when deploying machine learning models for credit risk. Monotonicity constraints align model behavior with domain knowledge, but their performance cost - the price of monotonicity - is not well quantified. This paper benchmarks monotone-constrained versus unconstrained gradient boosting models for credit probability of default across five public datasets and three libraries. We define the Price of Monotonicity (PoM) as the relative change in standard performance metrics when moving from unconstrained to constrained models, estimated via paired comparisons with bootstrap uncertainty. In our experiments, PoM in AUC ranges from essentially zero to about 2.9 percent: constraints are almost costless on large datasets (typically less than 0.2 percent, often indistinguishable from zero) and most costly on smaller datasets with extensive constraint coverage (around 2-3 percent). Thus, appropriately specified monotonicity constraints can often deliver interpretability with small accuracy losses, particularly in large-scale credit portfolios.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "金融机构在部署机器学习模型进行信用风险评估时，面临预测准确性与可解释性之间的权衡。单调性约束使模型行为与领域知识保持一致，但其性能成本——即“单调性的代价”——尚未得到充分量化。本文在五个公共数据集和三个库上，对信用违约概率的单调约束与无约束梯度提升模型进行了基准测试。我们将单调性代价定义为从无约束模型转向约束模型时标准性能指标的相对变化，通过配对比较和自助法不确定性进行估计。实验结果表明，AUC的单调性代价范围从基本为零到约2.9%：在大型数据集上约束几乎无成本（通常低于0.2%，常与零无异），而在约束覆盖广泛的小型数据集上成本最高（约2-3%）。因此，适当指定的单调性约束通常能以较小的准确性损失提供可解释性，特别是在大规模信用组合中。",
    "fetch_date": "2025-12-26",
    "id": "20251226_b992ef93"
  },
  {
    "title": "The Impact of Bitcoin ETF Approval on Bitcoin's Hedging Properties Against Traditional Assets",
    "url": "https://arxiv.org/pdf/2512.12815v1",
    "source": "ArXiv",
    "date": "2025-12-14",
    "abstract": "The approval of the Bitcoin Spot ETF in January 2024 marked a transformative event in cryptocurrency markets, signaling increased institutional adoption and integration into traditional finance. This study examines Bitcoin's changing relationships with traditional assets, including equities, gold, and fiat currencies, following this milestone. Using rolling correlation analysis, Chow tests, and DCC-GARCH models, we found that Bitcoin's correlation with the S\\&P 500 increased significantly post-ETF approval, indicating stronger alignment with equities. Its relationship with gold stabilized near zero, while its correlation with the U.S. Dollar Index remained consistently negative, reflecting its continued independence from fiat currencies. These findings offer insights into Bitcoin's evolving role in portfolios, implications for market stability, and future research opportunities on cryptocurrency integration into traditional financial systems.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "2024年1月比特币现货ETF获批标志着加密货币市场进入机构化与主流金融整合的新阶段。本研究通过滚动相关性分析、邹检验和DCC-GARCH模型，实证分析了该事件后比特币与传统资产（股票、黄金、法币）的动态关系。核心发现：比特币与标普500指数的相关性显著增强，表明其与股票市场联动性提升；与黄金的相关性稳定在零值附近；与美元指数的负相关性持续，保持对法币的独立性。这些结果为投资组合配置、市场稳定性评估及加密货币与传统金融体系融合研究提供了实证依据。",
    "fetch_date": "2025-12-26",
    "id": "20251226_aa031b92"
  },
  {
    "title": "Institutionalizing risk curation in decentralized credit",
    "url": "https://arxiv.org/pdf/2512.11976v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "This paper maps the emerging market for decentralized credit in which ERC 4626 vaults and third-party curators, rather than monolithic lending protocols alone, increasingly determine underwriting and leverage decisions. We show that modular vaults differ in capital utilization, cross-chain and cross asset concentration, and liquidity risk structure. Further, we show that a small set of curators intermediates a disproportionate share of system TVL, exhibits clustered tail co movement, and captures markedly different fee margins despite broadly similar collateral composition. These findings indicate that the main locus of risk in DeFi lending has migrated upward from base protocols, where underwriting is effectively centralized in a single DAO governed parameter set, to a permissionless curator layer in which competing vault managers decide which assets and loans are originated. We argue that this shift requires a corresponding upgrade in transparency standards and outline a simple set of onchain disclosures that would allow users and DAOs to evaluate curator strategies on a comparable, money market style basis.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文研究了去中心化信贷市场中ERC 4626金库和第三方策展人（而非单一借贷协议）日益主导承销和杠杆决策的新兴格局。研究发现模块化金库在资本利用率、跨链跨资产集中度及流动性风险结构方面存在差异，少数策展人中介了不成比例的系统总锁定价值（TVL），表现出聚集性尾部联动，且尽管抵押品构成相似却获得显著不同的费用边际。这表明DeFi借贷的主要风险点已从基础协议（承销权集中于单一DAO治理参数集）上移至无需许可的策展层，由竞争性金库管理者决定资产和贷款的发起。作者主张需相应提升透明度标准，并提出一套简单的链上披露方案，使用户和DAO能以可比的货币市场风格评估策展策略。",
    "fetch_date": "2025-12-26",
    "id": "20251226_470ff790"
  },
  {
    "title": "Empirical Mode Decomposition and Graph Transformation of the MSCI World Index: A Multiscale Topological Analysis for Graph Neural Network Modeling",
    "url": "https://arxiv.org/pdf/2512.12526v1",
    "source": "ArXiv",
    "date": "2025-12-14",
    "abstract": "This study applies Empirical Mode Decomposition (EMD) to the MSCI World index and converts the resulting intrinsic mode functions (IMFs) into graph representations to enable modeling with graph neural networks (GNNs). Using CEEMDAN, we extract nine IMFs spanning high-frequency fluctuations to long-term trends. Each IMF is transformed into a graph using four time-series-to-graph methods: natural visibility, horizontal visibility, recurrence, and transition graphs. Topological analysis shows clear scale-dependent structure: high-frequency IMFs yield dense, highly connected small-world graphs, whereas low-frequency IMFs produce sparser networks with longer characteristic path lengths. Visibility-based methods are more sensitive to amplitude variability and typically generate higher clustering, while recurrence graphs better preserve temporal dependencies. These results provide guidance for designing GNN architectures tailored to the structural properties of decomposed components, supporting more effective predictive modeling of financial time series.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "本研究对MSCI世界指数应用经验模态分解（EMD），将得到的本征模态函数（IMFs）转化为图表示，以便用图神经网络（GNNs）建模。使用CEEMDAN提取了九个IMF，涵盖高频波动到长期趋势。每个IMF通过四种时间序列到图的方法（自然可见性、水平可见性、递归图和转移图）转化为图。拓扑分析显示明显的尺度依赖结构：高频IMF产生密集、高度连接的小世界图，而低频IMF产生更稀疏、特征路径长度更长的网络。基于可见性的方法对振幅变化更敏感，通常产生更高的聚类，而递归图更好地保留了时间依赖性。这些结果为设计针对分解成分结构特性的GNN架构提供了指导，支持更有效的金融时间序列预测建模。",
    "fetch_date": "2025-12-26",
    "id": "20251226_17fa87b6"
  },
  {
    "title": "Explainable Prediction of Economic Time Series Using IMFs and Neural Networks",
    "url": "https://arxiv.org/pdf/2512.12499v1",
    "source": "ArXiv",
    "date": "2025-12-13",
    "abstract": "This study investigates the contribution of Intrinsic Mode Functions (IMFs) derived from economic time series to the predictive performance of neural network models, specifically Multilayer Perceptrons (MLP) and Long Short-Term Memory (LSTM) networks. To enhance interpretability, DeepSHAP is applied, which estimates the marginal contribution of each IMF while keeping the rest of the series intact. Results show that the last IMFs, representing long-term trends, are generally the most influential according to DeepSHAP, whereas high-frequency IMFs contribute less and may even introduce noise, as evidenced by improved metrics upon their removal. Differences between MLP and LSTM highlight the effect of model architecture on feature relevance distribution, with LSTM allocating importance more evenly across IMFs.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "本研究探讨了从经济时间序列中提取的本征模态函数（IMFs）对神经网络模型（特别是多层感知机MLP和长短期记忆网络LSTM）预测性能的贡献。为增强可解释性，应用DeepSHAP方法评估每个IMF的边际贡献，同时保持序列其余部分不变。结果表明，根据DeepSHAP分析，代表长期趋势的最后几个IMF通常最具影响力，而高频IMF贡献较小甚至可能引入噪声——移除这些高频分量后模型指标得到改善。MLP与LSTM之间的差异凸显了模型架构对特征相关性分布的影响，其中LSTM在IMF间的权重分配更为均匀。",
    "fetch_date": "2025-12-26",
    "id": "20251226_b8bacb63"
  },
  {
    "title": "Unified Approach to Portfolio Optimization using the `Gain Probability Density Function' and Applications",
    "url": "https://arxiv.org/pdf/2512.11649v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "This article proposes a unified framework for portfolio optimization (PO), recognizing an object called the `gain probability density function (PDF)' as the fundamental object of the problem from which any objective function could be derived. The gain PDF has the advantage of being 1-dimensional for any given portfolio and thus is easy to visualize and interpret. The framework allows us to naturally incorporate all existing approaches (Markowitz, CVaR-deviation, higher moments...) and represents an interesting basis to develop new approaches. It leads us to propose a method to directly match a target PDF defined by the portfolio manager, giving them maximal control on the PO problem and moving beyond approaches that focus only on expected return and risk. As an example, we develop an application involving a new objective function to control high profits, to be applied after a conventional PO (including expected return and risk criteria) and thus leading to sub-optimality w.r.t. the conventional objective function. We then propose a methodology to quantify a cost associated with this optimality deviation in a common budget unit, providing a meaningful information to portfolio managers. Numerical experiments considering portfolios with energy-producing assets illustrate our approach. The framework is flexible and can be applied to other sectors (financial assets, etc).",
    "broker": "Cornell Univ",
    "score": 5,
    "summary": "本文提出了一种基于“收益概率密度函数（PDF）”的统一投资组合优化框架，该框架将收益PDF视为问题的基本对象，任何目标函数均可从中推导。该PDF具有一维特性，易于可视化和解释，能够自然整合现有方法（如马科维茨、CVaR-偏差、高阶矩等），并为开发新方法提供了基础。文章提出了一种直接匹配投资组合经理定义的目标PDF的方法，使其能超越仅关注预期收益和风险的传统方法，对优化问题实现最大控制。作为示例，文章开发了一种在传统优化后控制高利润的新目标函数应用，这会导致相对于传统目标函数的次优性，并提出了一种以通用预算单位量化这种最优性偏差成本的方法，为投资组合经理提供有意义的信息。",
    "fetch_date": "2025-12-26",
    "id": "20251226_32dbca85"
  },
  {
    "title": "Extending the application of dynamic Bayesian networks in calculating market risk: Standard and stressed expected shortfall",
    "url": "https://arxiv.org/pdf/2512.12334v1",
    "source": "ArXiv",
    "date": "2025-12-13",
    "abstract": "In the last five years, expected shortfall (ES) and stressed ES (SES) have become key required regulatory measures of market risk in the banking sector, especially following events such as the global financial crisis. Thus, finding ways to optimize their estimation is of great importance. We extend the application of dynamic Bayesian networks (DBNs) to the estimation of 10-day 97.5% ES and stressed ES, building on prior work applying DBNs to value at risk. Using the S&P 500 index as a proxy for the equities trading desk of a US bank, we compare the performance of three DBN structure-learning algorithms with several traditional market risk models, using either the normal or the skewed Student's t return distributions. Backtesting shows that all models fail to produce statistically accurate ES and SES forecasts at the 2.5% level, reflecting the difficulty of modeling extreme tail behavior. For ES, the EGARCH(1,1) model (normal) produces the most accurate forecasts, while, for SES, the GARCH(1,1) model (normal) performs best. All distribution-dependent models deteriorate substantially when using the skewed Student's t distribution. The DBNs perform comparably to the historical simulation model, but their contribution to tail prediction is limited by the small weight assigned to their one-day-ahead forecasts within the return distribution. Future research should examine weighting schemes that enhance the influence of forward-looking DBN forecasts on tail risk estimation.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文扩展了动态贝叶斯网络（DBN）在计算市场风险中的应用，用于估计10天97.5%的预期损失（ES）和压力预期损失（SES）。研究以标普500指数为代理，比较了三种DBN结构学习算法与多种传统市场风险模型（使用正态或偏斜t分布）的表现。回测显示，所有模型在2.5%水平下均未能产生统计上准确的ES和SES预测，反映了建模极端尾部行为的困难。对于ES，EGARCH(1,1)模型（正态）预测最准确；对于SES，GARCH(1,1)模型（正态）表现最佳。所有依赖分布的模型在使用偏斜t分布时性能显著下降。DBN的表现与历史模拟法相当。",
    "fetch_date": "2025-12-26",
    "id": "20251226_5b6423f9"
  },
  {
    "title": "Universal Dynamics of Financial Bubbles in Isolated Markets: Evidence from the Iranian Stock Market",
    "url": "https://arxiv.org/pdf/2512.12054v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "Speculative bubbles exhibit common statistical signatures across many financial markets, suggesting the presence of universal underlying mechanisms. We test this hypothesis in the Iranian stock market, an economy that is highly isolated, subject to capital controls, and largely inaccessible to foreign investors. Using the Log-Periodic Power Law Singularity (LPPLS) model, we analyze two major bubble episodes in 2020 and 2023. The estimated critical exponents beta around 0.46 and 0.20 fall within the empirical ranges documented for canonical historical bubbles such as the 1929 DJIA crash and the 2000 Nasdaq episode. The Tehran Stock Exchange displays clear LPPLS hallmarks, including faster-than-exponential price acceleration, log-periodic corrections, and stable estimates of the critical time horizon. These results indicate that endogenous herding, imitation, and positive-feedback dynamics, rather than exogenous shocks, play a dominant role even in politically and economically isolated markets. By showing that an emerging and semi-closed financial system conforms to the same dynamical patterns observed in global markets, this paper provides new empirical support for the universality of bubble dynamics. To the best of our knowledge, it also presents the first systematic LPPLS analysis of bubbles in the Tehran Stock Exchange. The findings highlight the usefulness of LPPLS-based diagnostic tools for monitoring systemic risk in emerging or restricted economies.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文通过应用对数周期幂律奇异性（LPPLS）模型，分析了伊朗股市（一个高度孤立、受资本管制且外国投资者难以进入的市场）在2020年和2023年的两次主要泡沫事件。研究发现，其估算的关键指数β值（约0.46和0.20）与历史上经典泡沫（如1929年道琼斯工业平均指数崩盘和2000年纳斯达克泡沫）的经验范围一致。德黑兰证券交易所显示出清晰的LPPLS特征，包括快于指数的价格加速、对数周期性修正以及关键时间范围的稳定估计。结果表明，即使是在政治和经济上孤立的市场中，内生的羊群效应、模仿行为和正反馈动态，而非外生冲击，也起着主导作用。通过展示一个新兴的半封闭金融体系遵循与全球市场相同的动态模式，该论文为泡沫动力学的普适性提供了新的实证支持。",
    "fetch_date": "2025-12-26",
    "id": "20251226_16dc055e"
  },
  {
    "title": "High-Frequency Analysis of a Trading Game with Transient Price Impact",
    "url": "https://arxiv.org/pdf/2512.11765v1",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "We study the high-frequency limit of an $n$-trader optimal execution game in discrete time. Traders face transient price impact of Obizhaeva--Wang type in addition to quadratic instantaneous trading costs $θ(ΔX_t)^2$ on each transaction $ΔX_t$. There is a unique Nash equilibrium in which traders choose liquidation strategies minimizing expected execution costs. In the high-frequency limit where the grid of trading dates converges to the continuous interval $[0,T]$, the discrete equilibrium inventories converge at rate $1/N$ to the continuous-time equilibrium of an Obizhaeva--Wang model with additional quadratic costs $\\vartheta_0(ΔX_0)^2$ and $\\vartheta_T(ΔX_T)^2$ on initial and terminal block trades, where $\\vartheta_0=(n-1)/2$ and $\\vartheta_T=1/2$. The latter model was introduced by Campbell and Nutz as the limit of continuous-time equilibria with vanishing instantaneous costs. Our results extend and refine previous results of Schied, Strehle, and Zhang for the particular case $n=2$ where $\\vartheta_0=\\vartheta_T=1/2$. In particular, we show how the coefficients $\\vartheta_0=(n-1)/2$ and $\\vartheta_T=1/2$ arise endogenously in the high-frequency limit: the initial and terminal block costs of the continuous-time model are identified as the limits of the cumulative discrete instantaneous costs incurred over small neighborhoods of $0$ and $T$, respectively, and these limits are independent of $θ>0$. By contrast, when $θ=0$ the discrete-time equilibrium strategies and costs exhibit persistent oscillations and admit no high-frequency limit, mirroring the non-existence of continuous-time equilibria without boundary block costs. Our results show that two different types of trading frictions -- a fine time discretization and small instantaneous costs in continuous time -- have similar regularizing effects and select a canonical model in the limit.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文研究了具有瞬态价格影响的n交易者最优执行博弈的高频极限。交易者面临Obizhaeva-Wang型瞬态价格影响以及每笔交易ΔX_t的二次瞬时交易成本θ(ΔX_t)^2。存在唯一的纳什均衡，交易者选择最小化预期执行成本的清算策略。在高频极限下，离散均衡库存以1/N的速率收敛于具有额外二次成本ϑ_0(ΔX_0)^2和ϑ_T(ΔX_T)^2的Obizhaeva-Wang模型的连续时间均衡，其中ϑ_0=(n-1)/2，ϑ_T=1/2。该结果扩展并改进了先前针对n=2情况的研究。",
    "fetch_date": "2025-12-26",
    "id": "20251226_54f3bc58"
  },
  {
    "title": "Risk Limited Asset Allocation with a Budget Threshold Utility Function and Leptokurtotic Distributions of Returns",
    "url": "https://arxiv.org/pdf/2512.11666v2",
    "source": "ArXiv",
    "date": "2025-12-12",
    "abstract": "An analytical solution to single-horizon asset allocation for an investor with a piecewise-linear utility function, called herein the \"budget threshold utility,\" and exogenous position limits is presented. The resulting functional form has a surprisingly simple structure and can be readily interpreted as representing the addition of a simple \"risk cost\" to otherwise frictionless trading.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文针对具有预算阈值效用函数和外部头寸限制的投资者，提出了单期资产配置的解析解。该解具有简洁的结构，可解释为在无摩擦交易基础上增加了简单的“风险成本”。",
    "fetch_date": "2025-12-26",
    "id": "20251226_2daddc47"
  },
  {
    "title": "Sources and Nonlinearity of High Volume Return Premium: An Empirical Study on the Differential Effects of Investor Identity versus Trading Intensity (2020-2024)",
    "url": "https://arxiv.org/pdf/2512.14134v2",
    "source": "ArXiv",
    "date": "2025-12-16",
    "abstract": "Chae and Kang (2019, \\textit{Pacific-Basin Finance Journal}) documented a puzzling Low Volume Return Premium (LVRP) in Korea -- contradicting global High Volume Return Premium (HVRP) evidence. We resolve this puzzle. Using Korean market data (2020-2024), we demonstrate that HVRP exists in Korea but is masked by (1) pooling heterogeneous investor types and (2) using inappropriate intensity normalization. When institutional buying intensity is normalized by market capitalization rather than trading value, a perfect monotonic relationship emerges: highest-conviction institutional buying (Q4) generates +\\institutionLedQFourDayPlusFiftyCAR\\ cumulative abnormal returns over 50 days, while lowest-intensity trades (Q1) yield modest returns (+\\institutionLedQOneDayPlusFiftyCAR). Retail investors exhibit a flat pattern -- their trading generates near-zero returns regardless of conviction level -- confirming the pure noise trader hypothesis. During the Donghak Ant Movement (2020-2021), however, coordinated retail investors temporarily transformed from noise traders to liquidity providers, generating returns comparable to institutional trading. Our findings reconcile conflicting international evidence and demonstrate that detecting informed trading signals requires investor-type decomposition, nonlinear quartile analysis, and conviction-based (market cap) rather than participation-based (trading value) measurement.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "该研究（2020-2024）通过分析韩国市场数据，解决了韩国市场低成交量回报溢价（LVRP）与全球高成交量回报溢价（HVRP）证据相矛盾的谜题。研究发现，当按市值（而非交易额）对机构买入强度进行标准化时，HVRP在韩国市场显现：机构最高确信度买入（Q4）在50天内产生显著累积异常收益（+\\institutionLedQFourDayPlusFiftyCAR），而最低强度交易（Q1）收益较低（+\\institutionLedQOneDayPlusFiftyCAR）。散户交易则呈现平坦模式，收益接近零，符合纯噪声交易者假说；但在东学蚂蚁运动（2020-2021）期间，协调行动的散户暂时转变为流动性提供者，产生与机构相当的收益。研究通过区分投资者身份（机构vs散户）和交易强度标准化方法，调和了国际上的矛盾发现，对实战交易中识别机构驱动信号、优化因子构建具有直接价值。",
    "fetch_date": "2025-12-25",
    "id": "20251225_63fdd5c4"
  },
  {
    "title": "Interpretable Hypothesis-Driven Trading:A Rigorous Walk-Forward Validation Framework for Market Microstructure Signals",
    "url": "https://arxiv.org/pdf/2512.12924v1",
    "source": "ArXiv",
    "date": "2025-12-15",
    "abstract": "We develop a rigorous walk-forward validation framework for algorithmic trading designed to mitigate overfitting and lookahead bias. Our methodology combines interpretable hypothesis-driven signal generation with reinforcement learning and strict out-of-sample testing. The framework enforces strict information set discipline, employs rolling window validation across 34 independent test periods, maintains complete interpretability through natural language hypothesis explanations, and incorporates realistic transaction costs and position constraints. Validating five market microstructure patterns across 100 US equities from 2015 to 2024, the system yields modest annualized returns (0.55%, Sharpe ratio 0.33) with exceptional downside protection (maximum drawdown -2.76%) and market-neutral characteristics (beta = 0.058). Performance exhibits strong regime dependence, generating positive returns during high-volatility periods (0.60% quarterly, 2020-2024) while underperforming in stable markets (-0.16%, 2015-2019). We report statistically insignificant aggregate results (p-value 0.34) to demonstrate a reproducible, honest validation protocol that prioritizes interpretability and extends naturally to advanced hypothesis generators, including large language models. The key empirical finding reveals that daily OHLCV-based microstructure signals require elevated information arrival and trading activity to function effectively. The framework provides complete mathematical specifications and open-source implementation, establishing a template for rigorous trading system evaluation that addresses the reproducibility crisis in quantitative finance research. For researchers, practitioners, and regulators, this work demonstrates that interpretable algorithmic trading strategies can be rigorously validated without sacrificing transparency or regulatory compliance.",
    "broker": "Cornell Univ",
    "score": 8,
    "summary": "本文提出了一种可解释的假设驱动交易框架，采用严格的向前滚动验证方法，旨在减少过拟合和前瞻性偏差。该框架结合了可解释的假设驱动信号生成与强化学习，并执行严格的样本外测试。方法包括：严格执行信息集纪律、在34个独立测试期进行滚动窗口验证、通过自然语言假设解释保持完全可解释性、纳入实际交易成本和头寸约束。在2015-2024年间对100只美国股票验证五种市场微观结构模式，系统产生适中的年化收益（0.55%，夏普比率0.33），具有出色的下行保护（最大回撤-2.76%）和市场中性特征（beta=0.058）。表现呈现强烈的制度依赖性，在高波动期（2020-2024年，季度收益0.60%）产生正收益，而在稳定市场（2015-2019年，-0.16%）表现不佳。报告统计上不显著的总体结果（p值0.34），以展示一个可重复、诚实的验证协议，优先考虑可解释性。",
    "fetch_date": "2025-12-25",
    "id": "20251225_8db06af9"
  },
  {
    "title": "Deep reinforcement learning for quantitative trading: Challenges and opportunities",
    "url": "https://ieeexplore.ieee.org/abstract/document/9779600/",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… rise of quantitative trading (QT), which refers to automatically generating trading signals with … for more than 70% and 40% of the trading volume in developed markets (eg, USA) and …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文探讨了深度强化学习在量化交易中的应用，量化交易指通过算法自动生成交易信号，在发达市场（如美国）已占据超过70%和40%的交易量。论文分析了深度强化学习在量化交易领域面临的挑战与机遇，对实战交易具有较高参考价值。",
    "fetch_date": "2025-12-25",
    "id": "20251225_e3153d4f"
  },
  {
    "title": "Trademaster: A holistic quantitative trading platform empowered by reinforcement learning",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/b8f6f7f2ba4137124ac976286eacb611-Abstract-Datasets_and_Benchmarks.html",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… As shown in Figure 2, we formulate quantitative trading tasks as a Markov Decision Process (MDP) following a standard RL scenario, where an agent (investor) interacts with an …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "Trademaster是一个基于强化学习的综合性量化交易平台。该研究将量化交易任务建模为马尔可夫决策过程，遵循标准强化学习框架，其中智能体（投资者）与环境交互进行决策。",
    "fetch_date": "2025-12-25",
    "id": "20251225_fe85737d"
  },
  {
    "title": "FinRL: Deep reinforcement learning framework to automate trading in quantitative finance",
    "url": "https://dl.acm.org/doi/abs/10.1145/3490354.3494366",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… In this paper, we present the first open-source framework FinRL as a full pipeline to help quantitative traders overcome the steep learning curve. FinRL is featured with simplicity, …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "本文提出了首个开源框架FinRL，作为一个完整的流程，旨在帮助量化交易员克服陡峭的学习曲线。FinRL以简洁性为特点，利用深度强化学习自动化量化金融中的交易。",
    "fetch_date": "2025-12-25",
    "id": "20251225_f95bf03c"
  },
  {
    "title": "Deep reinforcement learning for quantitative trading",
    "url": "https://ieeexplore.ieee.org/abstract/document/10626209/",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… In this section, we explore the distinctive attributes of Quantitative Trading (QT) and elaborate on the rationale behind framing the entire QT process as a Partially Observable Markov …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文探讨了将深度强化学习应用于量化交易，将整个量化交易过程建模为部分可观测马尔可夫决策过程，具有实战价值。",
    "fetch_date": "2025-12-25",
    "id": "20251225_d085e88f"
  },
  {
    "title": "Reinforcement Learning Framework for Quantitative Trading",
    "url": "https://arxiv.org/abs/2411.07585",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… We investigate how a reinforcement learning agent can utilize financial indicators in specific market conditions and trends to enhance overall trading accuracy. By understanding the …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "本文研究强化学习智能体如何利用特定市场条件和趋势下的金融指标来提升整体交易准确性。通过理解市场动态，该框架旨在优化量化交易策略。",
    "fetch_date": "2025-12-25",
    "id": "20251225_c5574310"
  },
  {
    "title": "Deep reinforcement learning in quantitative algorithmic trading: A review",
    "url": "https://arxiv.org/abs/2106.00123",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… Deep Reinforcement Learning (DRL) agents proved to be to … reinforcement learning in the subdomain of AI in finance, more precisely, automated low-frequency quantitative stock trading…",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "深度强化学习在量化算法交易中的应用综述：该论文聚焦于深度强化学习（DRL）在金融人工智能子领域——特别是自动化低频量化股票交易中的实际应用。研究表明，DRL智能体在该领域展现出潜力，通过结合强化学习与深度学习技术，探索在实战交易中生成阿尔法（Alpha）的策略，具有较高的实践参考价值。",
    "fetch_date": "2025-12-25",
    "id": "20251225_307e048c"
  },
  {
    "title": "Quantitative trading on stock market based on deep reinforcement learning",
    "url": "https://ieeexplore.ieee.org/abstract/document/8851831/",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… intelligence, quantitative trading attracts … reinforcement learning in quantitative trading. A LSTM-based agent is proposed to learn the temporal pattern in data and automatically trades …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文提出了一种基于深度强化学习的股票市场量化交易方法，采用LSTM智能体学习数据中的时序模式，实现自动化交易。",
    "fetch_date": "2025-12-25",
    "id": "20251225_92f14b99"
  },
  {
    "title": "Deep Learning in Quantitative Trading",
    "url": "https://www.cambridge.org/core/elements/deep-learning-in-quantitative-trading/C39DE06D255470F6232BC97E2E5474E7",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… for developing deep learning algorithms for quantitative trading. This … deep learning algorithms to various financial problems. One of the most fundamental tasks in quantitative trading …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文探讨深度学习在量化交易中的应用，重点研究开发深度学习算法以解决金融问题，特别是量化交易中的核心任务。",
    "fetch_date": "2025-12-25",
    "id": "20251225_410d6f5e"
  },
  {
    "title": "Portfolio Optimization for Index Tracking with Constraints on Downside Risk and Carbon Footprint",
    "url": "https://arxiv.org/pdf/2512.21092v1",
    "source": "ArXiv",
    "date": "2025-12-24",
    "abstract": "Historically, financial risk management has mostly addressed risk factors that arise from the financial environment. Climate risks present a novel and significant challenge for companies and financial markets. Investors aiming for avoidance of firms with high carbon footprints require suitable risk measures and portfolio management strategies. This paper presents the construction of decarbonized indices for tracking the S \\& P-500 index of the U.S. stock market, as well as the Indian index NIFTY-50, employing two distinct methodologies and study their performances. These decarbonized indices optimize the portfolio weights by minimizing the mean-VaR and mean-ES and seek to reduce the risk of significant financial losses while still pursuing decarbonization goals. Investors can thereby find a balance between financial performance and environmental responsibilities. Ensuring transparency in the development of these indices will encourage the excluded and under-weighted asset companies to lower their carbon footprints through appropriate action plans. For long-term passive investors, these indices may present a more favourable option than green stocks.",
    "broker": "Cornell Univ",
    "score": 5,
    "summary": "本文提出了两种构建去碳化指数的方法，用于跟踪美国标普500指数和印度NIFTY-50指数。通过最小化均值-风险价值（mean-VaR）和均值-期望损失（mean-ES）来优化投资组合权重，旨在降低重大财务损失风险的同时实现去碳化目标。投资者可借此在财务绩效与环境责任间取得平衡，这些指数为长期被动投资者提供了比绿色股票更优的选择，并可能激励高碳排企业降低碳足迹。",
    "fetch_date": "2025-12-25",
    "id": "20251225_9ee0c108"
  },
  {
    "title": "Reinforcement learning in quantitative trading: A survey",
    "url": "https://www.techrxiv.org/doi/full/10.36227/techrxiv.19303853",
    "source": "Scholar",
    "date": "2025-12-25",
    "abstract": "… two concepts on quantitative trading evolved with time along with the emergence of RL. To this end, we devote one section to discuss the literature of quantitative trading with the tools of …",
    "broker": "Google Scholar",
    "score": 5,
    "summary": "该论文是一篇关于强化学习在量化交易中应用的综述性研究，主要梳理了随着强化学习发展而演变的两个量化交易概念，并专门用一节讨论了使用相关工具的量化交易文献。作为综述，它提供了理论框架和文献梳理，但缺乏具体的实战策略、代码实现或可验证的Alpha生成方法，因此对直接实战交易的价值有限，更适合作为理论参考。",
    "fetch_date": "2025-12-25",
    "id": "20251225_c48f4542"
  },
  {
    "title": "Discrete-time asset price bubbles with short sales prohibitions under model uncertainty",
    "url": "https://arxiv.org/pdf/2512.21115v1",
    "source": "ArXiv",
    "date": "2025-12-24",
    "abstract": "In this study, we investigate asset price bubbles in a discrete-time, discrete-state market under model uncertainty and short sales prohibitions. Building on a new fundamental theorem of asset pricing and a superhedging duality in this setting, we introduce a notion of bubble based on a novel definition of the fundamental price, and analyze their types and characterization. We show that two distinct types of bubbles arise, depending on the maturity structure of the asset. For assets with bounded maturity and no dividend payments, the $G$-supermartingale property of prices provides a necessary and sufficient condition for the existence of bubbles. In contrast, when maturity is unbounded, the infi-supermartingale property yields a necessary condition, while the $G$-supermartingale property remains sufficient. Moreover, there is no bubble under a strengthened no dominance condition. As applications, we examine price bubbles for several standard contingent claims. We show that put-call parity generally fails for fundamental prices, whereas it holds for market prices under no dominance assumption. Furthermore, we establish bounds for the fundamental and market prices of American call options in terms of the corresponding European call prices, adjusted by the associated bubble components.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本研究在离散时间、离散状态市场下，结合模型不确定性和卖空禁令，探讨资产价格泡沫。基于该设定下的新基本资产定价定理和超对冲对偶性，我们引入了一种基于新定义的基本价格的泡沫概念，并分析了其类型和特征。研究表明，根据资产的期限结构，会出现两种不同类型的泡沫。对于有界期限且无股息支付的资产，价格的G-上鞅性质为泡沫存在提供了必要且充分条件。相比之下，当期限无界时，infi-上鞅性质产生必要条件，而G-上鞅性质仍为充分条件。此外，在强化的无支配条件下不存在泡沫。作为应用，我们检验了几种标准或有债权的价格泡沫。研究表明，基本价格下的看跌-看涨平价通常不成立，而在无支配假设下市场价格则成立。此外，我们建立了美式看涨期权的基本价格和市场价格的界限。",
    "fetch_date": "2025-12-25",
    "id": "20251225_d9f8f8a4"
  },
  {
    "title": "Implicit Numerical Scheme for the Hamilton-Jacobi-Bellman Quasi-Variational Inequality in the Optimal Market-Making Problem with Alpha Signal",
    "url": "https://arxiv.org/pdf/2512.20850v1",
    "source": "ArXiv",
    "date": "2025-12-24",
    "abstract": "We address the problem of combined stochastic and impulse control for a market maker operating in a limit order book. The problem is formulated as a Hamilton-Jacobi-Bellman quasi-variational inequality (HJBQVI). We propose an implicit time-discretization scheme coupled with a policy iteration algorithm. This approach removes time-step restrictions typical of explicit methods and ensures unconditional stability. Convergence to the unique viscosity solution is established by verifying monotonicity, stability, and consistency conditions and applying the comparison principle.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文针对限价订单簿中的做市商，研究了结合随机控制和脉冲控制的最优做市问题。该问题被表述为Hamilton-Jacobi-Bellman拟变分不等式（HJBQVI）。作者提出了一种隐式时间离散化方案，并结合策略迭代算法。该方法消除了显式方法典型的时间步长限制，确保了无条件稳定性。通过验证单调性、稳定性和一致性条件，并应用比较原理，建立了收敛于唯一黏性解的理论基础。",
    "fetch_date": "2025-12-25",
    "id": "20251225_aea7403d"
  },
  {
    "title": "Fixed-Income Pricing and the Replication of Liabilities",
    "url": "https://arxiv.org/pdf/2512.14662v2",
    "source": "ArXiv",
    "date": "2025-12-16",
    "abstract": "This paper develops a model-free framework for static fixed-income pricing and the replication of liability cash flows. We show that the absence of static arbitrage across a universe of fixed-income instruments is equivalent to the existence of a strictly positive discount curve that reproduces all observed market prices. We then study the replication and super-replication of liabilities and establish conditions ensuring the existence of least-cost super-replicating portfolios, including a rigorous interpretation of swap--repo replication within this static framework. The results provide a unified foundation for discount-curve construction and liability-driven investment, with direct relevance for economic capital assessment and regulatory practice.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文提出了一种无模型的静态固定收益定价框架及负债现金流复制方法。研究表明，固定收益工具间不存在静态套利等价于存在严格为正的贴现曲线能重现所有市场价格。进一步探讨了负债的复制与超复制，建立了确保最低成本超复制组合存在的条件，并对互换-回购复制进行了严谨解释。该结果为贴现曲线构建和负债驱动投资提供了统一理论基础，对经济资本评估和监管实践具有直接参考价值。",
    "fetch_date": "2025-12-25",
    "id": "20251225_63fda1dc"
  },
  {
    "title": "Interpretable Deep Learning for Stock Returns: A Consensus-Bottleneck Asset Pricing Model",
    "url": "https://arxiv.org/pdf/2512.16251v2",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "We introduce the Consensus-Bottleneck Asset Pricing Model (CB-APM), a partially interpretable neural network that replicates the reasoning processes of sell-side analysts by capturing how dispersed investor beliefs are compressed into asset prices through a consensus formation process. By modeling this \"bottleneck\" to summarize firm- and macro-level information, CB-APM not only predicts future risk premiums of U.S. equities but also links belief aggregation to expected returns in a structurally interpretable manner. The model improves long-horizon return forecasts and outperforms standard deep learning approaches in both predictive accuracy and explanatory power. Comprehensive portfolio analyses show that CB-APM's out-of-sample predictions translate into economically meaningful payoffs, with monotonic return differentials and stable long-short performance across regularization settings. Empirically, CB-APM leverages consensus as a regularizer to amplify long-horizon predictability and yields interpretable consensus-based components that clarify how information is priced in returns. Moreover, regression and Gibbons-Ross-Shanken (GRS)-based pricing diagnostics reveal that the learned consensus representations capture priced variation only partially spanned by traditional factor models, demonstrating that CB-APM uncovers belief-driven structure in expected returns beyond the canonical factor space. Overall, CB-APM provides an interpretable and empirically grounded framework for understanding belief-driven return dynamics.",
    "broker": "Cornell Univ",
    "score": 9,
    "summary": "我们提出了共识瓶颈资产定价模型（CB-APM），这是一种部分可解释的神经网络，通过捕捉分散的投资者信念如何通过共识形成过程压缩为资产价格，来复制卖方分析师推理过程。该模型通过建模这一“瓶颈”来汇总公司和宏观层面的信息，不仅预测美国股票的未来风险溢价，还在结构上以可解释的方式将信念聚合与预期回报联系起来。CB-APM改进了长期回报预测，在预测准确性和解释力方面均优于标准深度学习方法。全面的投资组合分析表明，CB-APM的样本外预测转化为具有经济意义的回报，具有单调的回报差异和跨正则化设置的稳定多空表现。实证上，CB-APM利用共识作为正则化器来增强长期可预测性，并产生基于共识的可解释组件，阐明信息如何在回报中定价。此外，回归和基于Gibbons-Ross-Shanken（GRS）的定价诊断揭示了所学内容。",
    "fetch_date": "2025-12-24",
    "id": "20251224_da05e7f2"
  },
  {
    "title": "Reinforcement learning for quantitative trading",
    "url": "https://dl.acm.org/doi/abs/10.1145/3582560",
    "source": "Scholar",
    "date": "2025-12-24",
    "abstract": "… we used are reinforcement learning, quantitative finance, algorithmic trading, portfolio … a brief overview of financial markets and quantitative trading. Then, we introduce the preliminaries …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文探讨了强化学习在量化交易中的应用，涵盖量化金融、算法交易和投资组合管理等领域。文章首先概述了金融市场和量化交易的基本概念，随后介绍了强化学习的理论基础及其在交易策略优化中的实际应用。",
    "fetch_date": "2025-12-24",
    "id": "20251224_3a476d40"
  },
  {
    "title": "Adaptive quantitative trading: An imitative deep reinforcement learning approach",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5587",
    "source": "Scholar",
    "date": "2025-12-24",
    "abstract": "… mathematical symbols then formally introduce the quantitative trading problem in detail. … always the goal of quantitative traders. This further proves that our trading agent can benefit from …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "《自适应量化交易：一种模仿深度强化学习方法》提出了一种基于深度强化学习的交易代理，能够从市场数据中学习并自适应调整交易策略。该方法通过模仿学习结合强化学习框架，旨在实现持续盈利这一量化交易的核心目标。论文表明该交易代理能够从历史数据中受益并优化交易决策，具有较高的实战应用潜力。",
    "fetch_date": "2025-12-24",
    "id": "20251224_766e09bf"
  },
  {
    "title": "Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems",
    "url": "https://arxiv.org/pdf/2512.18317v1",
    "source": "ArXiv",
    "date": "2025-12-20",
    "abstract": "This paper presents a trustworthy reinforcement learning approach for the control of industrial compressed air systems. We develop a framework that enables safe and energy-efficient operation under realistic boundary conditions and introduce a multi-level explainability pipeline combining input perturbation tests, gradient-based sensitivity analysis, and SHAP (SHapley Additive exPlanations) feature attribution. An empirical evaluation across multiple compressor configurations shows that the learned policy is physically plausible, anticipates future demand, and consistently respects system boundaries. Compared to the installed industrial controller, the proposed approach reduces unnecessary overpressure and achieves energy savings of approximately 4\\,\\% without relying on explicit physics models. The results further indicate that system pressure and forecast information dominate policy decisions, while compressor-level inputs play a secondary role. Overall, the combination of efficiency gains, predictive behavior, and transparent validation supports the trustworthy deployment of reinforcement learning in industrial energy systems.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文提出了一种可信赖的强化学习方法，用于工业压缩空气系统的控制。该框架能够在实际边界条件下实现安全、节能的运行，并引入了结合输入扰动测试、基于梯度的敏感性分析和SHAP（Shapley Additive exPlanations）特征归因的多层次可解释性管道。对多种压缩机配置的实证评估表明，学习到的策略在物理上是合理的，能够预测未来需求，并始终尊重系统边界。与已安装的工业控制器相比，所提出的方法减少了不必要的过压，在不依赖显式物理模型的情况下实现了约4%的节能。结果进一步表明，系统压力和预测信息主导了策略决策，而压缩机级别的输入则起次要作用。总体而言，效率提升、预测行为和透明验证的结合支持了强化学习在工业能源系统中的可信赖部署。",
    "fetch_date": "2025-12-24",
    "id": "20251224_4eec8973"
  },
  {
    "title": "Asymptotic and finite-sample distributions of one- and two-sample empirical relative entropy, with application to change-point detection",
    "url": "https://arxiv.org/pdf/2512.16411v1",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "Relative entropy, as a divergence metric between two distributions, can be used for offline change-point detection and extends classical methods that mainly rely on moment-based discrepancies. To build a statistical test suitable for this context, we study the distribution of empirical relative entropy and derive several types of approximations: concentration inequalities for finite samples, asymptotic distributions, and Berry-Esseen bounds in a pre-asymptotic regime. For the latter, we introduce a new approach to obtain Berry-Esseen inequalities for nonlinear functions of sum statistics under some convexity assumptions. Our theoretical contributions cover both one- and two-sample empirical relative entropies. We then detail a change-point detection procedure built on relative entropy and compare it, through extensive simulations, with classical methods based on moments or on information criteria. Finally, we illustrate its practical relevance on two real datasets involving temperature series and volatility of stock indices.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文研究了经验相对熵的分布，推导了有限样本的集中不等式、渐近分布以及前渐近状态下的Berry-Esseen界，并提出了一种基于相对熵的变点检测方法。通过模拟和真实数据（包括股票指数波动率）验证了该方法相对于基于矩或信息准则的传统方法的实用性。",
    "fetch_date": "2025-12-24",
    "id": "20251224_c7720f56"
  },
  {
    "title": "Design of a Decentralized Fixed-Income Lending Automated Market Maker Protocol Supporting Arbitrary Maturities",
    "url": "https://arxiv.org/pdf/2512.16080v1",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "In decentralized finance (DeFi), designing fixed-income lending automated market makers (AMMs) is extremely challenging due to time-related complexities. Moreover, existing protocols only support single-maturity lending. Building upon the BondMM protocol, this paper argues that its mathematical invariants are sufficiently elegant to be generalized to arbitrary maturities. This paper thus propose an improved design, BondMM-A, which supports lending activities of any maturity. By integrating fixed-income instruments of varying maturities into a single smart contract, BondMM-A offers users and liquidity providers (LPs) greater operational freedom and capital efficiency. Experimental results show that BondMM-A performs excellently in terms of interest rate stability and financial robustness.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "在去中心化金融（DeFi）中，由于时间相关的复杂性，设计固定收益借贷自动做市商（AMM）极具挑战性。现有协议仅支持单一期限借贷。本文基于BondMM协议，论证其数学不变量足够优雅，可推广至任意期限。因此，本文提出改进设计BondMM-A，支持任何期限的借贷活动。通过将不同期限的固定收益工具整合到单一智能合约中，BondMM-A为用户和流动性提供者（LPs）提供更大的操作自由和资本效率。实验结果表明，BondMM-A在利率稳定性和金融稳健性方面表现优异。",
    "fetch_date": "2025-12-24",
    "id": "20251224_c04304c9"
  },
  {
    "title": "Multi-Objective Bayesian Optimization of Deep Reinforcement Learning for Environmental, Social, and Governance (ESG) Financial Portfolio Management",
    "url": "https://arxiv.org/pdf/2512.14992v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "DRL agents circumvent the issue of classic models in the sense that they do not make assumptions like the financial returns being normally distributed and are able to deal with any information like the ESG score if they are configured to gain a reward that makes an objective better. However, the performance of DRL agents has high variability and it is very sensible to the value of their hyperparameters. Bayesian optimization is a class of methods that are suited to the optimization of black-box functions, that is, functions whose analytical expression is unknown, are noisy and expensive to evaluate. The hyperparameter tuning problem of DRL algorithms perfectly suits this scenario. As training an agent just for one objective is a very expensive period, requiring millions of timesteps, instead of optimizing an objective being a mixture of a risk-performance metric and an ESG metric, we choose to separate the objective and solve the multi-objective scenario to obtain an optimal Pareto set of portfolios representing the best tradeoff between the Sharpe ratio and the ESG mean score of the portfolio and leaving to the investor the choice of the final portfolio. We conducted our experiments using environments encoded within the OpenAI Gym, adapted from the FinRL platform. The experiments are carried out in the Dow Jones Industrial Average (DJIA) and the NASDAQ markets in terms of the Sharpe ratio achieved by the agent and the mean ESG score of the portfolio. We compare the performance of the obtained Pareto sets in hypervolume terms illustrating how portfolios are the best trade-off between the Sharpe ratio and mean ESG score. Also, we show the usefulness of our proposed methodology by comparing the obtained hypervolume with one achieved by a Random Search methodology on the DRL hyperparameter space.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文提出了一种用于环境、社会和治理（ESG）金融投资组合管理的多目标贝叶斯优化深度强化学习方法。深度强化学习（DRL）代理无需假设金融收益服从正态分布，并能处理ESG评分等信息，但其性能对超参数高度敏感。贝叶斯优化适用于优化黑盒函数，DRL的超参数调优正符合此场景。由于单目标训练成本高昂（需数百万时间步），作者将目标分离，通过多目标优化获得代表夏普比率与投资组合ESG平均评分之间最佳权衡的帕累托最优投资组合集，最终由投资者选择具体组合。",
    "fetch_date": "2025-12-24",
    "id": "20251224_e237fd82"
  },
  {
    "title": "Systemic Risk Radar: A Multi-Layer Graph Framework for Early Market Crash Warning",
    "url": "https://arxiv.org/pdf/2512.17185v1",
    "source": "ArXiv",
    "date": "2025-12-19",
    "abstract": "Financial crises emerge when structural vulnerabilities accumulate across sectors, markets, and investor behavior. Predicting these systemic transitions is challenging because they arise from evolving interactions between market participants, not isolated price movements alone. We present Systemic Risk Radar (SRR), a framework that models financial markets as multi-layer graphs to detect early signs of systemic fragility and crash-regime transitions.\n  We evaluate SRR across three major crises: the Dot-com crash, the Global Financial Crisis, and the COVID-19 shock. Our experiments compare snapshot GNNs, a simplified temporal GNN prototype, and standard baselines (logistic regression and Random Forest). Results show that structural network information provides useful early-warning signals compared to feature-based models alone.\n  This correlation-based instantiation of SRR demonstrates that graph-derived features capture meaningful changes in market structure during stress events. The findings motivate extending SRR with additional graph layers (sector/factor exposure, sentiment) and more expressive temporal architectures (LSTM/GRU or Transformer encoders) to better handle diverse crisis types.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "《系统性风险雷达：用于早期市场崩盘预警的多层图框架》提出了一种将金融市场建模为多层图以检测系统性脆弱性和崩盘状态转换早期迹象的框架。该研究评估了SRR在互联网泡沫、全球金融危机和COVID-19冲击三个重大危机中的表现，实验表明结构网络信息相比纯特征模型能提供更有用的早期预警信号。虽然该框架展示了图衍生特征在压力事件期间捕捉市场结构有意义变化的能力，但当前实现主要基于相关性分析，属于理论验证阶段。论文建议通过添加更多图层（行业/因子暴露、情绪）和更强大的时序架构（LSTM/GRU或Transformer编码器）来扩展SRR，这为实战交易系统开发提供了有价值的理论框架和方向指引。",
    "fetch_date": "2025-12-24",
    "id": "20251224_7b111b14"
  },
  {
    "title": "An Efficient Machine Learning Framework for Option Pricing via Fourier Transform",
    "url": "https://arxiv.org/pdf/2512.16115v1",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "The increasing need for rapid recalibration of option pricing models in dynamic markets places stringent computational demands on data generation and valuation algorithms. In this work, we propose a hybrid algorithmic framework that integrates the smooth offset algorithm (SOA) with supervised machine learning models for the fast pricing of multiple path-independent options under exponential Lévy dynamics. Building upon the SOA-generated dataset, we train neural networks, random forests, and gradient boosted decision trees to construct surrogate pricing operators. Extensive numerical experiments demonstrate that, once trained, these surrogates achieve order-of-magnitude acceleration over direct SOA evaluation. Importantly, the proposed framework overcomes key numerical limitations inherent to fast Fourier transform-based methods, including the consistency of input data and the instability in deep out-of-the-money option pricing.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "动态市场中期权定价模型快速重新校准的需求日益增长，这对数据生成和估值算法提出了严格的计算要求。本文提出了一种混合算法框架，将平滑偏移算法（SOA）与监督机器学习模型相结合，用于在指数Lévy动态下快速定价多种路径无关期权。基于SOA生成的数据集，我们训练神经网络、随机森林和梯度提升决策树来构建替代定价算子。大量数值实验表明，一旦训练完成，这些替代模型相比直接SOA评估实现了数量级的加速。重要的是，所提出的框架克服了基于快速傅里叶变换方法固有的关键数值限制，包括输入数据的一致性和深度虚值期权定价的不稳定性。",
    "fetch_date": "2025-12-24",
    "id": "20251224_21c43b5a"
  },
  {
    "title": "SigMA: Path Signatures and Multi-head Attention for Learning Parameters in fBm-driven SDEs",
    "url": "https://arxiv.org/pdf/2512.15088v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "Stochastic differential equations (SDEs) driven by fractional Brownian motion (fBm) are increasingly used to model systems with rough dynamics and long-range dependence, such as those arising in quantitative finance and reliability engineering. However, these processes are non-Markovian and lack a semimartingale structure, rendering many classical parameter estimation techniques inapplicable or computationally intractable beyond very specific cases. This work investigates two central questions: (i) whether integrating path signatures into deep learning architectures can improve the trade-off between estimation accuracy and model complexity, and (ii) what constitutes an effective architecture for leveraging signatures as feature maps. We introduce SigMA (Signature Multi-head Attention), a neural architecture that integrates path signatures with multi-head self-attention, supported by a convolutional preprocessing layer and a multilayer perceptron for effective feature encoding. SigMA learns model parameters from synthetically generated paths of fBm-driven SDEs, including fractional Brownian motion, fractional Ornstein-Uhlenbeck, and rough Heston models, with a particular focus on estimating the Hurst parameter and on joint multi-parameter inference, and it generalizes robustly to unseen trajectories. Extensive experiments on synthetic data and two real-world datasets (i.e., equity-index realized volatility and Li-ion battery degradation) show that SigMA consistently outperforms CNN, LSTM, vanilla Transformer, and Deep Signature baselines in accuracy, robustness, and model compactness. These results demonstrate that combining signature transforms with attention-based architectures provides an effective and scalable framework for parameter inference in stochastic systems with rough or persistent temporal structure.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "该论文提出SigMA（Signature Multi-head Attention）神经网络架构，将路径签名与多头自注意力机制结合，用于学习分数布朗运动驱动的随机微分方程参数。该方法针对具有粗糙动态和长程依赖的系统建模，如量化金融中的分数布朗运动、分数Ornstein-Uhlenbeck和粗糙Heston模型。研究聚焦于通过合成生成路径进行参数估计，探讨路径签名在深度学习架构中如何平衡估计精度与模型复杂度。",
    "fetch_date": "2025-12-24",
    "id": "20251224_a46aba2c"
  },
  {
    "title": "Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes",
    "url": "https://arxiv.org/pdf/2512.14991v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "We study reinforcement learning for controlled diffusion processes with unbounded continuous state spaces, bounded continuous actions, and polynomially growing rewards: settings that arise naturally in finance, economics, and operations research. To overcome the challenges of continuous and high-dimensional domains, we introduce a model-based algorithm that adaptively partitions the joint state-action space. The algorithm maintains estimators of drift, volatility, and rewards within each partition, refining the discretization whenever estimation bias exceeds statistical confidence. This adaptive scheme balances exploration and approximation, enabling efficient learning in unbounded domains. Our analysis establishes regret bounds that depend on the problem horizon, state dimension, reward growth order, and a newly defined notion of zooming dimension tailored to unbounded diffusion processes. The bounds recover existing results for bounded settings as a special case, while extending theoretical guarantees to a broader class of diffusion-type problems. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "本文研究针对具有无界连续状态空间、有界连续动作和多项式增长奖励的受控扩散过程的强化学习——这些设定自然出现在金融、经济和运筹学中。为克服连续高维领域的挑战，我们提出一种基于模型的算法，自适应地划分联合状态-动作空间。该算法在每个分区内维护漂移、波动率和奖励的估计器，并在估计偏差超过统计置信度时细化离散化。这种自适应方案平衡了探索与近似，使得在无界域中高效学习成为可能。我们的分析建立了遗憾界，其依赖于问题时域、状态维度、奖励增长阶数以及为无界扩散过程定制的新定义的“缩放维度”概念。这些界限将现有有界设定结果作为特例恢复，同时将理论保证扩展到更广泛的扩散类问题。最后，我们通过数值实验验证了方法的有效性，包括在高维问题中的应用。",
    "fetch_date": "2025-12-24",
    "id": "20251224_140ee511"
  },
  {
    "title": "Modelling financial time series with $φ^{4}$ quantum field theory",
    "url": "https://arxiv.org/pdf/2512.17225v1",
    "source": "ArXiv",
    "date": "2025-12-19",
    "abstract": "We use a $φ^{4}$ quantum field theory with inhomogeneous couplings and explicit symmetry-breaking to model an ensemble of financial time series from the S$\\&$P 500 index. The continuum nature of the $φ^4$ theory avoids the inaccuracies that occur in Ising-based models which require a discretization of the time series. We demonstrate this using the example of the 2008 global financial crisis. The $φ^{4}$ quantum field theory is expressive enough to reproduce the higher-order statistics such as the market kurtosis, which can serve as an indicator of possible market shocks. Accurate reproduction of high kurtosis is absent in binarized models. Therefore Ising models, despite being widely employed in econophysics, are incapable of fully representing empirical financial data, a limitation not present in the generalization of the $φ^{4}$ scalar field theory. We then investigate the scaling properties of the $φ^{4}$ machine learning algorithm and extract exponents which govern the behavior of the learned couplings (or weights and biases in ML language) in relation to the number of stocks in the model. Finally, we use our model to forecast the price changes of the AAPL, MSFT, and NVDA stocks. We conclude by discussing how the $φ^{4}$ scalar field theory could be used to build investment strategies and the possible intuitions that the QFT operations of dimensional compactification and renormalization can provide for financial modelling.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文使用具有非均匀耦合和显式对称性破缺的φ⁴量子场论来建模标普500指数中的金融时间序列集合。与需要离散化时间序列的伊辛模型相比，φ⁴理论的连续性质避免了不准确性，并能重现高阶统计量（如市场峰度），可作为市场冲击的指标。论文还研究了φ⁴机器学习算法的标度特性，并提取了控制学习耦合（或ML中的权重和偏置）与模型中股票数量关系的指数。最后，使用该模型预测了AAPL、MSFT和NVDA股票的价格变化。",
    "fetch_date": "2025-12-24",
    "id": "20251224_1cb49c57"
  },
  {
    "title": "Global universal approximation with Brownian signatures",
    "url": "https://arxiv.org/pdf/2512.16396v1",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "We establish $L^p$-type universal approximation theorems for general and non-anticipative functionals on suitable rough path spaces, showing that linear functionals acting on signatures of time-extended rough paths are dense with respect to an $L^p$-distance. To that end, we derive global universal approximation theorems for weighted rough path spaces. We demonstrate that these $L^p$-type universal approximation theorems apply in particular to Brownian motion. As a consequence, linear functionals on the signature of the time-extended Brownian motion can approximate any $p$-integrable stochastic process adapted to the Brownian filtration, including solutions to stochastic differential equations.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文在加权粗糙路径空间上建立了L^p型全局通用逼近定理，证明了对时间扩展粗糙路径的签名进行线性泛函作用在L^p距离意义下是稠密的。特别地，这些定理适用于布朗运动，因此布朗运动时间扩展签名的线性泛函可以逼近任何适应于布朗滤波的p可积随机过程，包括随机微分方程的解。",
    "fetch_date": "2025-12-24",
    "id": "20251224_94b3ca35"
  },
  {
    "title": "Adaptive Weighted Genetic Algorithm-Optimized SVR for Robust Long-Term Forecasting of Global Stock Indices for investment decisions",
    "url": "https://arxiv.org/pdf/2512.15113v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "Long-term price forecasting remains a formidable challenge due to the inherent uncertainty over the long term, despite some success in short-term predictions. Nonetheless, accurate long-term forecasts are essential for high-net-worth individuals, institutional investors, and traders. The proposed improved genetic algorithm-optimized support vector regression (IGA-SVR) model is specifically designed for long-term price prediction of global indices. The performance of the IGA-SVR model is rigorously evaluated and compared against the state-of-the-art baseline models, the Long Short-Term Memory (LSTM), and the forward-validating genetic algorithm optimized support vector regression (OGA-SVR). Extensive testing was conducted on the five global indices, namely Nifty, Dow Jones Industrial Average (DJI), DAX Performance Index (DAX), Nikkei 225 (N225), and Shanghai Stock Exchange Composite Index (SSE) from 2021 to 2024 of daily price prediction up to a year. Overall, the proposed IGA-SVR model achieved a reduction in MAPE by 19.87% compared to LSTM and 50.03% compared to OGA-SVR, demonstrating its superior performance in long-term daily price forecasting of global indices. Further, the execution time for LSTM was approximately 20 times higher than that of IGA-SVR, highlighting the high accuracy and computational efficiency of the proposed model. The genetic algorithm selects the optimal hyperparameters of SVR by minimizing the arithmetic mean of the Mean Absolute Percentage Error (MAPE) calculated over the full training dataset and the most recent five years of training data. This purposefully designed training methodology adjusts for recent trends while retaining long-term trend information, thereby offering enhanced generalization compared to the LSTM and rolling-forward validation approach employed by OGA-SVR, which forgets long-term trends and suffers from recency bias.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文提出了一种改进的遗传算法优化支持向量回归（IGA-SVR）模型，专门用于全球股票指数的长期价格预测。在2021年至2024年期间，对Nifty、道琼斯工业平均指数（DJI）、DAX绩效指数（DAX）、日经225指数（N225）和上证综合指数（SSE）等五个全球指数进行了长达一年的每日价格预测测试。结果表明，与LSTM和OGA-SVR相比，IGA-SVR模型在平均绝对百分比误差（MAPE）上分别降低了19.87%和50.03%，显示出其在长期预测中的优越性能。",
    "fetch_date": "2025-12-24",
    "id": "20251224_b3187dce"
  },
  {
    "title": "Arbitrage-Free Pricing with Diffusion-Dependent Jumps",
    "url": "https://arxiv.org/pdf/2512.15071v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "Standard jump-diffusion models assume independence between jumps and diffusion components. We develop a multi-type jump-diffusion model where jump occurrence and magnitude depend on contemporaneous diffusion movements. Unlike previous one-sided models that create arbitrage opportunities, our framework includes upward and downward jumps triggered by both large upward and large downward diffusion increments. We derive the explicit no-arbitrage condition linking the physical drift to model parameters and market risk premia by constructing an Equivalent Martingale Measure using Girsanov's theorem and a normalized Esscher transform. This condition provides a rigorous foundation for arbitrage-free pricing in models with diffusion-dependent jumps.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "标准跳跃扩散模型假设跳跃与扩散成分相互独立。本文开发了一种多类型跳跃扩散模型，其中跳跃的发生和幅度取决于同期的扩散运动。与以往可能产生套利机会的单边模型不同，我们的框架包含由大幅向上和向下扩散增量触发的向上和向下跳跃。通过使用Girsanov定理和归一化Esscher变换构建等价鞅测度，我们推导出将物理漂移与模型参数及市场风险溢价联系起来的明确无套利条件。该条件为具有扩散依赖跳跃的模型中的无套利定价提供了严格基础。",
    "fetch_date": "2025-12-24",
    "id": "20251224_33dbfdbc"
  },
  {
    "title": "Optimal Signal Extraction from Order Flow: A Matched Filter Perspective on Normalization and Market Microstructure",
    "url": "https://arxiv.org/pdf/2512.18648v1",
    "source": "ArXiv",
    "date": "2025-12-21",
    "abstract": "We demonstrate that the choice of normalization for order flow intensity is fundamental to signal extraction in finance, not merely a technical detail. Through theoretical modeling, Monte Carlo simulation, and empirical validation using Korean market data, we prove that market capitalization normalization acts as a ``matched filter'' for informed trading signals, achieving 1.32--1.97$\\times$ higher correlation with future returns compared to traditional trading value normalization. The key insight is that informed traders scale positions by firm value (market capitalization), while noise traders respond to daily liquidity (trading volume), creating heteroskedastic corruption when normalizing by trading volume. By reframing the normalization problem using signal processing theory, we show that dividing order flow by market capitalization preserves the information signal while traditional volume normalization multiplies the signal by inverse turnover -- a highly volatile quantity. Our theoretical predictions are robust across parameter specifications and validated by empirical evidence showing 482\\% improvement in explanatory power. These findings have immediate implications for high-frequency trading algorithms, risk factor construction, and information-based trading strategies.",
    "broker": "Cornell Univ",
    "score": 9,
    "summary": "本文论证了订单流强度归一化方法的选择对信号提取至关重要，而不仅仅是技术细节。通过理论建模、蒙特卡洛模拟和韩国市场数据的实证验证，证明市值归一化可作为知情交易信号的“匹配滤波器”，相比传统的交易额归一化，与未来收益的相关性提高1.32-1.97倍。核心观点是：知情交易者按公司价值（市值）调整头寸，而噪声交易者则响应日流动性（交易量），使用交易量归一化会导致异方差干扰。通过信号处理理论重新构建归一化问题，发现除以市值能保留信息信号，而传统的交易量归一化会将信号乘以逆换手率——一个高度波动的变量。理论预测在不同参数设定下均稳健，实证证据显示解释力提升482%。这些发现对高频交易、算法交易和风险模型具有直接应用价值。",
    "fetch_date": "2025-12-24",
    "id": "20251224_eb1783a9"
  },
  {
    "title": "Switching between states and the COVID-19 turbulence",
    "url": "https://arxiv.org/pdf/2512.20477v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "In Aarab (2020), I examine U.S. stock return predictability across economic regimes and document evidence of time-varying expected returns across market states in the long run. The analysis introduces a state-switching specification in which the market state is proxied by the slope of the yield curve, and proposes an Aligned Economic Index built from the popular predictors of Welch and Goyal (2008) (augmented with bond and equity premium measures). The Aligned Economic Index under the state-switching model exhibits statistically and economically meaningful in-sample ($R^2 = 5.9\\%$) and out-of-sample ($R^2_{\\text{oos}} = 4.12\\%$) predictive power across both recessions and expansions, while outperforming a range of widely used predictors. In this work, I examine the added value for professional practitioners by computing the economic gains for a mean-variance investor and find substantial added benefit of using the new index under the state switching model across all market states. The Aligned Economic Index can thus be implemented on a consistent real-time basis. These findings are crucial for both academics and practitioners as expansions are much longer-lived than recessions. Finally, I extend the empirical exercises by incorporating data through September 2020 and document sizable gains from using the Aligned Economic Index, relative to more traditional approaches, during the COVID-19 market turbulence.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文通过引入状态切换模型（以收益率曲线斜率作为市场状态代理变量）和构建对齐经济指数（基于Welch和Goyal（2008）的经典预测因子，并加入债券和股权溢价指标），实证显示该指数在样本内（R²=5.9%）和样本外（R²oos=4.12%）均对美股收益具有统计及经济意义的预测能力，且优于多种常用预测因子。研究进一步通过均值-方差投资者模型验证了该模型在所有市场状态下均能带来显著经济收益，并强调该指数可实时应用于实践。这些发现对从业者尤为重要，因为经济扩张期远长于衰退期。",
    "fetch_date": "2025-12-24",
    "id": "20251224_a39154aa"
  },
  {
    "title": "The Aligned Economic Index & The State Switching Model",
    "url": "https://arxiv.org/pdf/2512.20460v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "A growing empirical literature suggests that equity-premium predictability is state dependent, with much of the forecasting power concentrated around recessionary periods \\parencite{Henkel2011,DanglHalling2012,Devpura2018}. I study U.S. stock return predictability across economic regimes and document strong evidence of time-varying expected returns across both expansionary and contractionary states. I contribute in two ways. First, I introduce a state-switching predictive regression in which the market state is defined in real time using the slope of the yield curve. Relative to the standard one-state predictive regression, the state-switching specification increases both in-sample and out-of-sample performance for the set of popular predictors considered by \\textcite{WelchGoyal2008}, improving the out-of-sample performance of most predictors in economically meaningful ways. Second, I propose a new aggregate predictor, the Aligned Economic Index, constructed via partial least squares (PLS). Under the state-switching model, the Aligned Economic Index exhibits statistically and economically significant predictive power in sample and out of sample, and it outperforms widely used benchmark predictors and alternative predictor-combination methods.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文研究了美国股票收益在不同经济状态下的可预测性，提出了两个对实战交易有价值的贡献：一是引入基于收益率曲线斜率实时定义市场状态的状态切换预测回归模型，相比传统单状态模型显著提高了样本内和样本外预测性能；二是通过偏最小二乘法构建了新的聚合预测指标——对齐经济指数，在状态切换模型下展现出统计和经济意义上显著的样本内外预测能力。论文聚焦于经济状态依赖的股票溢价预测，其状态切换模型和对齐经济指数可直接应用于实战中的择时和风险管理策略。",
    "fetch_date": "2025-12-24",
    "id": "20251224_23ae3263"
  },
  {
    "title": "GIFfluence: A Visual Approach to Investor Sentiment and the Stock Market",
    "url": "https://arxiv.org/pdf/2512.20027v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "We study dynamic visual representations as a proxy for investor sentiment about the stock market. Our sentiment index, GIFsentiment, is constructed from millions of posts in the Graphics Interchange Format (GIF) on a leading investment social media platform. GIFsentiment correlates with seasonal mood variations and the severity of COVID lockdowns. It is positively associated with contemporaneous market returns and negatively predicts returns for up to four weeks, even after controlling for other sentiment and attention measures. These effects are stronger among portfolios that are more susceptible to mispricing. GIFsentiment positively predicts trading volume, market volatility, and flows toward equity funds and away from debt funds. Our evidence suggests that GIFsentiment is a proxy for misperceptions that are later corrected.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文提出了一种基于投资社交媒体平台GIF帖子的投资者情绪指标GIFsentiment。研究发现：1）该指标与季节性情绪波动和疫情封锁严重程度相关；2）与同期市场收益正相关，并能负向预测未来四周收益（控制其他情绪指标后仍显著）；3）对易受错误定价影响的投资组合预测效果更强；4）能正向预测交易量、市场波动率以及资金从债券基金流向股票基金。证据表明GIFsentiment可作为市场错误认知的代理指标，这些认知后续会被修正。",
    "fetch_date": "2025-12-24",
    "id": "20251224_78339dde"
  },
  {
    "title": "Covariance-Aware Simplex Projection for Cardinality-Constrained Portfolio Optimization",
    "url": "https://arxiv.org/pdf/2512.19986v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "Metaheuristic algorithms for cardinality-constrained portfolio optimization require repair operators to map infeasible candidates onto the feasible region. Standard Euclidean projection treats assets as independent and can ignore the covariance structure that governs portfolio risk, potentially producing less diversified portfolios. This paper introduces Covariance-Aware Simplex Projection (CASP), a two-stage repair operator that (i) selects a target number of assets using volatility-normalized scores and (ii) projects the candidate weights using a covariance-aware geometry aligned with tracking-error risk. This provides a portfolio-theoretic foundation for using a covariance-induced distance in repair operators. On S&P 500 data (2020-2024), CASP-Basic delivers materially lower portfolio variance than standard Euclidean repair without relying on return estimates, with improvements that are robust across assets and statistically significant. Ablation results indicate that volatility-normalized selection drives most of the variance reduction, while the covariance-aware projection provides an additional, consistent improvement. We further show that optional return-aware extensions can improve Sharpe ratios, and out-of-sample tests confirm that gains transfer to realized performance. CASP integrates as a drop-in replacement for Euclidean projection in metaheuristic portfolio optimizers.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文提出了一种用于基数约束投资组合优化的协方差感知单纯形投影方法。针对元启发式算法中修复算子将不可行候选解映射到可行区域时忽略协方差结构的问题，该方法采用两阶段修复：首先基于波动率归一化评分选择目标资产数量，然后使用与跟踪误差风险对齐的协方差感知几何进行权重投影。在S&P 500数据上的实证表明，该方法在不依赖收益预测的情况下显著降低了投资组合方差，且改进具有统计显著性。消融实验显示波动率归一化选择贡献了主要方差降低，而协方差感知投影提供了额外的稳定改进。",
    "fetch_date": "2025-12-24",
    "id": "20251224_432db6dc"
  },
  {
    "title": "Needles in a haystack: using forensic network science to uncover insider trading",
    "url": "https://arxiv.org/pdf/2512.18918v1",
    "source": "ArXiv",
    "date": "2025-12-21",
    "abstract": "Although the automation and digitisation of anti-financial crime investigation has made significant progress in recent years, detecting insider trading remains a unique challenge, partly due to the limited availability of labelled data. To address this challenge, we propose using a data-driven networks approach that flags groups of corporate insiders who report coordinated transactions that are indicative of insider trading. Specifically, we leverage data on 2.9 million trades reported to the U.S. Securities and Exchange Commission (SEC) by company insiders (C-suite executives, board members and major shareholders) between 2014 and 2024. Our proposed algorithm constructs weighted edges between insiders based on the temporal similarity of their trades over the 10-year timeframe. Within this network we then uncover trends that indicate insider trading by focusing on central nodes and anomalous subgraphs. To highlight the validity of our approach we evaluate our findings with reference to two null models, generated by running our algorithm on synthetic empirically calibrated and shuffled datasets. The results indicate that our approach can be used to detect pairs or clusters of insiders whose behaviour suggests insider trading and/or market manipulation.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文提出了一种利用法证网络科学检测内幕交易的数据驱动网络方法。通过分析2014-2024年间美国证券交易委员会（SEC）收到的290万笔公司内部人（高管、董事会成员和大股东）交易报告，该算法基于交易时间相似性构建内部人之间的加权边网络，并通过识别中心节点和异常子图来揭示内幕交易模式。研究使用合成经验校准和随机数据集生成的零模型验证了方法的有效性，表明该方法能有效检测协同交易的内幕交易对或集群。",
    "fetch_date": "2025-12-24",
    "id": "20251224_944d270d"
  },
  {
    "title": "Quantitative Financial Modeling for Sri Lankan Markets: Approach Combining NLP, Clustering and Time-Series Forecasting",
    "url": "https://arxiv.org/pdf/2512.20216v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "This research introduces a novel quantitative methodology tailored for quantitative finance applications, enabling banks, stockbrokers, and investors to predict economic regimes and market signals in emerging markets, specifically Sri Lankan stock indices (S&P SL20 and ASPI) by integrating Environmental, Social, and Governance (ESG) sentiment analysis with macroeconomic indicators and advanced time-series forecasting. Designed to leverage quantitative techniques for enhanced risk assessment, portfolio optimization, and trading strategies in volatile environments, the architecture employs FinBERT, a transformer-based NLP model, to extract sentiment from ESG texts, followed by unsupervised clustering (UMAP/HDBSCAN) to identify 5 latent ESG regimes, validated via PCA. These regimes are mapped to economic conditions using a dense neural network and gradient boosting classifier, achieving 84.04% training and 82.0% validation accuracy. Concurrently, time-series models (SRNN, MLP, LSTM, GRU) forecast daily closing prices, with GRU attaining an R-squared of 0.801 and LSTM delivering 52.78% directional accuracy on intraday data. A strong correlation between S&P SL20 and S&P 500, observed through moving average and volatility trend plots, further bolsters forecasting precision. A rule-based fusion logic merges ESG and time-series outputs for final market signals. By addressing literature gaps that overlook emerging markets and holistic integration, this quant-driven framework combines global correlations and local sentiment analysis to offer scalable, accurate tools for quantitative finance professionals navigating complex markets like Sri Lanka.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "该研究为斯里兰卡市场（S&P SL20和ASPI指数）提出了一种新颖的量化金融建模方法，通过整合ESG情感分析（使用FinBERT模型）、宏观经济指标和先进的时间序列预测技术（包括SRNN、MLP、LSTM、GRU），旨在预测经济状态和市场信号。该方法采用无监督聚类（UMAP/HDBSCAN）识别出5个潜在的ESG状态，并通过密集神经网络和梯度提升分类器将其映射到经济条件，训练和验证准确率分别达到84.04%和82.0%。在时间序列预测方面，GRU模型的R平方为0.801，LSTM在日内数据上的方向准确性为52.78%。研究还观察到S&P SL20与S&P 500之间存在强相关性。该框架旨在增强风险评估、投资组合优化和交易策略，适用于波动环境中的新兴市场。",
    "fetch_date": "2025-12-24",
    "id": "20251224_6cec85b9"
  },
  {
    "title": "Pricing of wrapped Bitcoin and Ethereum on-chain options",
    "url": "https://arxiv.org/pdf/2512.20190v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "This paper measures price differences between Hegic option quotes on Arbitrum and a model-based benchmark built on Black--Scholes model with regime-sensitive volatility estimated via a two-regime MS-AR-(GJR)-GARCH model. Using option-level feasible GLS, we find benchmark prices exceed Hegic quotes on average, especially for call options. The price spread rises with order size, strike, maturity, and estimated volatility, and falls with trading volume. By underlying, wrapped Bitcoin options show larger and more persistent spreads, while Ethereum options are closer to the benchmark. The framework offers a data-driven analysis for monitoring and calibrating on-chain option pricing logic.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "该论文通过对比Hegic在Arbitrum上的期权报价与基于两区制MS-AR-(GJR)-GARCH模型估计波动率的Black-Scholes基准模型，发现基准价格普遍高于Hegic报价（尤其是看涨期权）。价差随订单规模、行权价、期限和估计波动率增加而扩大，随交易量增加而缩小。其中，包装比特币期权价差更大且更持久，以太坊期权则更接近基准。该框架为监控和校准链上期权定价逻辑提供了数据驱动的分析方法。",
    "fetch_date": "2025-12-24",
    "id": "20251224_6243b8b8"
  },
  {
    "title": "Equilibrium Liquidity and Risk Offsetting in Decentralised Markets",
    "url": "https://arxiv.org/pdf/2512.19838v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "We develop an economic model of decentralised exchanges (DEXs) in which risk-averse liquidity providers (LPs) manage risk in a centralised exchange (CEX) based on preferences, information, and trading costs. Rational, risk-averse LPs anticipate the frictions associated with replication and manage risk primarily by reducing the reserves supplied to the DEX. Greater aversion reduces the equilibrium viability of liquidity provision, resulting in thinner markets and lower trading volumes. Greater uninformed demand supports deeper liquidity, whereas higher fundamental price volatility erodes it. Finally, while moderate anticipated price changes can improve LP performance, larger changes require more intensive trading in the CEX, generate higher replication costs, and induce LPs to reduce liquidity supply.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文构建了一个去中心化交易所（DEX）的经济模型，研究风险厌恶的流动性提供者（LPs）如何基于偏好、信息与交易成本，在中心化交易所（CEX）管理风险。理性且风险厌恶的LPs会预判与复制相关的摩擦，主要通过减少向DEX提供的储备来管理风险。更高的风险厌恶会降低流动性提供的均衡可行性，导致市场更薄、交易量更低。更大的非知情需求支持更深的流动性，而更高的基础价格波动则会削弱流动性。最后，虽然适度的预期价格变动可能改善LP表现，但更大的变动需要在CEX进行更密集的交易，产生更高的复制成本，并促使LPs减少流动性供给。",
    "fetch_date": "2025-12-24",
    "id": "20251224_27c66c3f"
  },
  {
    "title": "How to choose my stochastic volatility parameters? A review",
    "url": "https://arxiv.org/pdf/2512.19821v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "Based on the existing literature, this article presents the different ways of choosing the parameters of stochastic volatility models in general, in the context of pricing financial derivative contracts. This includes the use of stochastic volatility inside stochastic local volatility models.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "基于现有文献，本文综述了在金融衍生品定价背景下，选择随机波动率模型参数的各种方法，包括在随机局部波动率模型中使用随机波动率。",
    "fetch_date": "2025-12-24",
    "id": "20251224_faddc8fe"
  },
  {
    "title": "Counterexamples for FX Options Interpolations -- Part II",
    "url": "https://arxiv.org/pdf/2512.19625v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "This follow-up article analyzes the impact of foreign exchange option interpolation on the vanilla option implied volatilities. In particular different exact interpolations of broker quotes may lead to different implied volatilities at the 10$Δ$ and 25$Δ$ Puts and Calls.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "这篇后续文章分析了外汇期权插值对普通期权隐含波动率的影响。具体而言，经纪商报价的不同精确插值方法可能导致10Δ和25Δ看跌期权与看涨期权的隐含波动率出现差异。",
    "fetch_date": "2025-12-24",
    "id": "20251224_bee73e28"
  },
  {
    "title": "Counterexamples for FX Options Interpolations -- Part I",
    "url": "https://arxiv.org/pdf/2512.19621v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "This article provides a list of counterexamples, where some of the popular fx option interpolations break down. Interpolation of FX option prices (or equivalently volatilities), is key to risk-manage not only vanilla FX option books, but also more exotic derivatives which are typically valued with local volatility or local stochastic volatilility models.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文列举了外汇期权插值方法失效的反例，指出插值对于风险管理至关重要，不仅涉及普通外汇期权，也影响使用局部波动率或局部随机波动率模型定价的奇异衍生品。",
    "fetch_date": "2025-12-24",
    "id": "20251224_43d5d092"
  },
  {
    "title": "Heston vol-of-vol and the VVIX",
    "url": "https://arxiv.org/pdf/2512.19611v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "The Heston stochastic volatility model is arguably, the most popular stochastic volatility model used to price and risk manage exotic derivatives. In spite of this, it is not necessarily easy to calibrate to the market and obtain stable exotic option prices with this model. This paper focuses on the vol-of-vol parameter and its relation with the volatility of volatility index (VVIX) level. Four different approaches to estimate the VVIX in the Heston model are presented: two based on the known transition density of the variance, one analytical approximation, and one based on the Heston PDE which computes the value directly out of the underlying SPX500. Finally we explore their use to improve calibration stability.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文聚焦于Heston随机波动率模型中的波动率波动率参数及其与波动率波动率指数（VVIX）水平的关系。提出了四种在Heston模型中估计VVIX的方法：两种基于已知的方差转移密度，一种解析近似方法，以及一种基于Heston偏微分方程直接从标普500指数计算的方法。最后探讨了这些方法在提高模型校准稳定性方面的应用。",
    "fetch_date": "2025-12-24",
    "id": "20251224_dad4d8e3"
  },
  {
    "title": "Learning General Policies with Policy Gradient Methods",
    "url": "https://arxiv.org/pdf/2512.19366v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "While reinforcement learning methods have delivered remarkable results in a number of settings, generalization, i.e., the ability to produce policies that generalize in a reliable and systematic way, has remained a challenge. The problem of generalization has been addressed formally in classical planning where provable correct policies that generalize over all instances of a given domain have been learned using combinatorial methods. The aim of this work is to bring these two research threads together to illuminate the conditions under which (deep) reinforcement learning approaches, and in particular, policy optimization methods, can be used to learn policies that generalize like combinatorial methods do. We draw on lessons learned from previous combinatorial and deep learning approaches, and extend them in a convenient way. From the former, we model policies as state transition classifiers, as (ground) actions are not general and change from instance to instance. From the latter, we use graph neural networks (GNNs) adapted to deal with relational structures for representing value functions over planning states, and in our case, policies. With these ingredients in place, we find that actor-critic methods can be used to learn policies that generalize almost as well as those obtained using combinatorial approaches while avoiding the scalability bottleneck and the use of feature pools. Moreover, the limitations of the DRL methods on the benchmarks considered have little to do with deep learning or reinforcement learning algorithms, and result from the well-understood expressive limitations of GNNs, and the tradeoff between optimality and generalization (general policies cannot be optimal in some domains). Both of these limitations are addressed without changing the basic DRL methods by adding derived predicates and an alternative cost structure to optimize.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文探讨了强化学习方法（特别是策略梯度方法）在何种条件下能学习到具有泛化能力的策略，类似于组合方法在经典规划中所实现的。作者结合了组合方法与深度学习的思路，将策略建模为状态转移分类器（因为具体动作会随问题实例变化），并使用图神经网络（GNNs）来处理关系结构以表示规划状态的价值函数和策略。研究旨在弥合强化学习与可证明泛化的组合方法之间的差距，但重点在于理论框架与条件分析，而非直接应用于实战交易场景。",
    "fetch_date": "2025-12-24",
    "id": "20251224_5412cd38"
  },
  {
    "title": "Institutional Backing and Crypto Volatility: A Hybrid Framework for DeFi Stabilization",
    "url": "https://arxiv.org/pdf/2512.19251v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "Decentralized finance (DeFi) lacks centralized oversight, often resulting in heightened volatility. In contrast, centralized finance (CeFi) offers a more stable environment with institutional safeguards. Institutional backing can play a stabilizing role in a hybrid structure (HyFi), enhancing transparency, governance, and market discipline. This study investigates whether HyFi-like cryptocurrencies, those backed by institutions, exhibit lower price risk than fully decentralized counterparts. Using daily data for 18 major cryptocurrencies from January 2020 to November 2024, we estimate panel EGLS models with fixed, random, and dynamic specifications. Results show that HyFi-like assets consistently experience lower price risk, with this effect intensifying during periods of elevated market volatility. The negative interaction between HyFi status and market-wide volatility confirms their stabilizing role. Conversely, greater decentralization is strongly associated with increased volatility, particularly during periods of market stress. Robustness checks using quantile regressions and pre-/post-Terra Luna subsamples reinforce these findings, with stronger effects observed in high-volatility quantiles and post-crisis conditions. These results highlight the importance of institutional architecture in enhancing the resilience of digital asset markets.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文探讨了去中心化金融（DeFi）因缺乏中心化监管而波动性较高，而中心化金融（CeFi）通过机构保障提供更稳定环境。研究发现，在混合结构（HyFi）中，机构支持能通过增强透明度、治理和市场纪律发挥稳定作用。基于2020年1月至2024年11月18种主要加密货币的日度数据，面板EGLS模型显示，具有机构支持的HyFi类资产价格风险较低，且在市场波动加剧时期稳定作用更明显。相反，去中心化程度越高，波动性越强，尤其在市场压力时期。分位数回归及Terra Luna事件前后子样本的稳健性检验支持了这些结论。",
    "fetch_date": "2025-12-24",
    "id": "20251224_36795ecf"
  }
]