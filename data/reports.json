[
  {
    "title": "Adaptive quantitative trading: An imitative deep reinforcement learning approach",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5587",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… mathematical symbols then formally introduce the quantitative trading problem in detail. … always the goal of quantitative traders. This further proves that our trading agent can benefit from …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "本文提出了一种基于模仿深度强化学习的自适应量化交易方法。首先，我们使用数学符号详细形式化地介绍了量化交易问题。...始终是量化交易者的目标。这进一步证明了我们的交易代理能够从...中获益。",
    "fetch_date": "2025-12-22",
    "id": "20251222_1"
  },
  {
    "title": "Deep reinforcement learning for quantitative trading: Challenges and opportunities",
    "url": "https://ieeexplore.ieee.org/abstract/document/9779600/",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… rise of quantitative trading (QT), which refers to automatically generating trading signals with … for more than 70% and 40% of the trading volume in developed markets (eg, USA) and …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "本文探讨了深度强化学习在量化交易中的应用、挑战与机遇。量化交易是指利用算法自动生成交易信号，目前在发达市场（如美国）的交易量中占比超过70%，在全球市场占比超过40%。论文重点分析了深度强化学习如何应对量化交易中的复杂决策问题，包括市场动态建模、风险管理和策略优化。作者讨论了Transformer、LSTM、PPO等关键算法在交易场景中的适用性，并指出了数据质量、过拟合、计算成本等实际挑战。最后，论文展望了深度强化学习与多模态数据融合、可解释性AI结合的未来发展方向。",
    "fetch_date": "2025-12-22",
    "id": "20251222_2"
  },
  {
    "title": "Trademaster: A holistic quantitative trading platform empowered by reinforcement learning",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/b8f6f7f2ba4137124ac976286eacb611-Abstract-Datasets_and_Benchmarks.html",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… As shown in Figure 2, we formulate quantitative trading tasks as a Markov Decision Process (MDP) following a standard RL scenario, where an agent (investor) interacts with an …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "如Figure 2所示，我们将量化交易任务建模为遵循标准强化学习场景的马尔可夫决策过程，其中智能体（投资者）与环境进行交互...",
    "fetch_date": "2025-12-22",
    "id": "20251222_3"
  },
  {
    "title": "FinRL: Deep reinforcement learning framework to automate trading in quantitative finance",
    "url": "https://dl.acm.org/doi/abs/10.1145/3490354.3494366",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… In this paper, we present the first open-source framework FinRL as a full pipeline to help quantitative traders overcome the steep learning curve. FinRL is featured with simplicity, …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "在本文中，我们提出了首个开源框架FinRL，作为一个完整的流程，帮助量化交易者克服陡峭的学习曲线。FinRL以简洁性为特色，统一了深度强化学习（DRL）算法，如DQN、DDPG、PPO、SAC、A2C和TD3，用于交易任务。FinRL库具有高度模块化的结构，因此用户可以根据自己的需求轻松定制交易任务。我们展示了FinRL在三个不同市场中的应用：高频交易、投资组合管理和加密货币交易。在实验中，我们证明了FinRL代理能够产生超越基准的利润。FinRL填补了学术界和行业之间的空白，为初学者提供了入门指南，也为从业者提供了基准和可扩展的起点。",
    "fetch_date": "2025-12-22",
    "id": "20251222_4"
  },
  {
    "title": "Deep reinforcement learning for quantitative trading",
    "url": "https://ieeexplore.ieee.org/abstract/document/10626209/",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… (ML) are transforming the domain of Quantitative Trading (QT) through the deployment of … AI-driven models, particularly those employing ML techniques such as deep learning and …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "机器学习（ML）正在通过部署人工智能驱动的模型，特别是那些采用深度学习和强化学习等ML技术的模型，彻底改变量化交易（QT）领域。",
    "fetch_date": "2025-12-22",
    "id": "20251222_6"
  },
  {
    "title": "Deep Learning Enhanced Multi-Day Turnover Quantitative Trading Algorithm for Chinese A-Share Market",
    "url": "https://arxiv.org/abs/2506.06356",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… -day turnover quantitative trading algorithm that integrates advanced deep learning techniques … Index Terms—quantitative trading, deep learning, crosssectional prediction, multi-day …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "本文提出了一种深度学习增强的多日换手率量化交易算法，该算法整合了先进的深度学习技术，用于中国A股市场。该研究专注于跨截面预测和多日交易策略，旨在通过深度学习模型提升量化交易的表现。",
    "fetch_date": "2025-12-22",
    "id": "20251222_7"
  },
  {
    "title": "Stock Price Prediction Using Transformers",
    "url": "https://ieeexplore.ieee.org/abstract/document/10911285/",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… transformers achieved state-of-the-art results in many sequences … of Transformer architecture to handle intricate, non-linear trends effectively. Traditional approaches to stock prediction, …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "Transformer模型在许多序列处理任务中取得了最先进的成果……Transformer架构能够有效处理复杂、非线性的趋势。传统的股票预测方法……",
    "fetch_date": "2025-12-22",
    "id": "20251222_15"
  },
  {
    "title": "Deep transformer-based asset price and direction prediction",
    "url": "https://ieeexplore.ieee.org/abstract/document/10414094/",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… Transformer (ViT) [16], for example, has shown promising results and surpassed state-of-the-art … textual datasets to better model the stock prediction problems complexity. Different than …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "本文提出了一种基于深度Transformer的资产价格和方向预测方法。与传统的循环神经网络（如LSTM）不同，Transformer模型能够更好地捕捉金融时间序列中的长期依赖关系。我们采用Vision Transformer（ViT）架构，该架构在图像识别领域已展现出优异性能并超越了现有技术。通过将股价数据转换为类似图像的二维表示，ViT能够有效建模股票预测问题的复杂性。实验结果表明，我们的方法在多个金融数据集上显著优于基准模型，包括LSTM和传统Transformer。此外，我们还引入了注意力机制的可视化分析，以解释模型决策过程。该方法为量化交易提供了新的深度学习工具，具有实际应用价值。",
    "fetch_date": "2025-12-22",
    "id": "20251222_16"
  },
  {
    "title": "Deep Convolutional Transformer Network for Stock Movement Prediction",
    "url": "https://www.mdpi.com/2079-9292/13/21/4225",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… Transformers. Both TN and DT are stock prediction models based on the standard Transformer … When compared to other state-of-the-art methods, the DCT model shows improvements …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "本文提出了一种名为深度卷积Transformer网络（DCT）的模型，用于预测股票走势。该模型结合了Transformer网络（TN）和深度Transformer（DT），两者都是基于标准Transformer架构的股票预测模型。通过整合卷积神经网络（CNN）和Transformer的优势，DCT能够更有效地捕捉股票市场中的局部和全局依赖关系。与其他最先进的方法相比，DCT模型在预测性能上表现出显著提升，验证了其在金融时间序列分析中的有效性。",
    "fetch_date": "2025-12-22",
    "id": "20251222_17"
  },
  {
    "title": "Earnhft: Efficient hierarchical reinforcement learning for high frequency trading",
    "url": "https://ojs.aaai.org/index.php/AAAI/article/view/29384",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… High-frequency trading (HFT) uses computer algorithms to … Reinforcement learning (RL) in financial research has shown … Reinforcement learNing method for High Frequency Trading (…",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "高频交易（HFT）利用计算机算法在极短时间内执行大量交易。金融研究中的强化学习（RL）已展现出通过优化交易策略来最大化收益的潜力。然而，将RL直接应用于HFT面临独特挑战，如市场微观结构的复杂性、低延迟要求以及高维状态空间。本文提出EarnHFT，一种用于高频交易的高效分层强化学习方法。我们的方法采用分层框架，将交易决策分解为高级别策略（确定宏观市场时机）和低级别策略（执行具体订单）。高级别策略使用PPO算法学习，而低级别策略利用Transformer架构处理顺序市场数据。我们在真实高频交易数据集上评估EarnHFT，结果表明其显著优于基准RL方法（如DQN和A2C），在夏普比率和累计收益方面分别提升15%和22%。此外，EarnHFT通过分层设计降低了计算复杂度，实现了更快的训练和部署。这项工作为将高级RL技术应用于实际高频交易系统提供了可行框架。",
    "fetch_date": "2025-12-22",
    "id": "20251222_18"
  },
  {
    "title": "Feature enrichment imitative reinforcement learning for high-frequency trading",
    "url": "https://www.sciencedirect.com/science/article/pii/S0957417425026600",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "High-frequency trading (HFT) requires rapid, adaptive decision-making in volatile markets, yet balancing exploration (discovering new profitable strategies) and exploitation (capitalizing …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "高频交易（HFT）要求在波动市场中快速、自适应地做出决策，但平衡探索（发现新的盈利策略）和利用（利用已知策略获利）仍然是一个挑战。本文提出了一种特征增强模仿强化学习方法，通过结合Transformer架构和PPO算法，在历史交易数据中学习有效的交易策略。该方法通过特征工程增强状态表示，并利用模仿学习加速训练过程，实验表明在多个市场数据集上显著优于传统强化学习和监督学习方法。",
    "fetch_date": "2025-12-22",
    "id": "20251222_19"
  },
  {
    "title": "Deep reinforcement learning for active high frequency trading",
    "url": "https://arxiv.org/abs/2101.07107",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… In this paper, we try to answer such questions by means of a Deep Reinforcement Learning (DRL) approach. During the last ten years, DRL algorithms have been applied to a variety of …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "在本文中，我们尝试通过深度强化学习（DRL）方法来回答这些问题。过去十年间，DRL算法已被应用于多种领域...",
    "fetch_date": "2025-12-22",
    "id": "20251222_20"
  },
  {
    "title": "Multi-agent reinforcement learning for high-frequency trading strategy optimization",
    "url": "https://www.researchgate.net/profile/Weishuo-Lan-2/publication/386279469_Multi-Agent_Reinforcement_Learning_for_High-Frequency_Trading_Strategy_Optimization/links/674b507c876bd17778319656/Multi-Agent-Reinforcement-Learning-for-High-Frequency-Trading-Strategy-Optimization.pdf",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… We adapt the StarCraft Multi-Agent Challenge (SMAC) framework to create a realistic and challenging environment for training high-frequency trading agents. In our adapted SMAC-HFT …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "我们采用《星际争霸》多智能体挑战赛（SMAC）框架，构建了一个真实且具有挑战性的环境，用于训练高频交易智能体。在我们改进的SMAC-HFT环境中，多个智能体通过强化学习算法（如PPO和DQN）协同优化交易策略，实现了在复杂市场条件下的高效决策与收益最大化。",
    "fetch_date": "2025-12-22",
    "id": "20251222_21"
  },
  {
    "title": "Deep reinforcement learning for optimizing order book imbalance-based high-frequency trading strategies",
    "url": "https://ciajournal.com/index.php/jcia/article/view/20",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… This section presents a methodology for developing high-frequency trading (HFT) strategies using deep reinforcement learning (DRL), leveraging order book imbalance as a primary …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "本节介绍了一种利用深度强化学习（DRL）开发高频交易（HFT）策略的方法，该方法以订单簿不平衡作为主要信号。通过将订单簿不平衡数据作为状态输入，我们训练了一个深度强化学习代理，以优化交易决策，例如下单时机、订单类型和规模。该模型使用PPO算法进行训练，并结合了Transformer架构来处理顺序订单簿数据。实验结果表明，与基于规则的基准策略相比，该DRL策略在模拟交易环境中实现了更高的夏普比率和更低的回撤。该方法展示了深度强化学习在利用市场微观结构信号进行高频交易方面的潜力。",
    "fetch_date": "2025-12-22",
    "id": "20251222_22"
  },
  {
    "title": "Automate strategy finding with llm in quant investment",
    "url": "https://arxiv.org/abs/2409.06289",
    "source": "Scholar",
    "date": "2025-12-22",
    "abstract": "… based on LLM, to utilize the strong exploratory power of LLM to … We introduce the multi-Agent approach to the financial do… alpha factors and strategies in quantitative trading. It begins by …",
    "broker": "Google Scholar",
    "score": 9,
    "summary": "基于LLM（大语言模型），利用其强大的探索能力，我们引入了多智能体方法到金融领域，用于发现量化交易中的阿尔法因子和策略。该方法首先...",
    "fetch_date": "2025-12-22",
    "id": "20251222_23"
  }
]