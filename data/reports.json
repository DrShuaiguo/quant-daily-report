[
  {
    "title": "Interpretable Deep Learning for Stock Returns: A Consensus-Bottleneck Asset Pricing Model",
    "url": "https://arxiv.org/pdf/2512.16251v2",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "We introduce the Consensus-Bottleneck Asset Pricing Model (CB-APM), a partially interpretable neural network that replicates the reasoning processes of sell-side analysts by capturing how dispersed investor beliefs are compressed into asset prices through a consensus formation process. By modeling this \"bottleneck\" to summarize firm- and macro-level information, CB-APM not only predicts future risk premiums of U.S. equities but also links belief aggregation to expected returns in a structurally interpretable manner. The model improves long-horizon return forecasts and outperforms standard deep learning approaches in both predictive accuracy and explanatory power. Comprehensive portfolio analyses show that CB-APM's out-of-sample predictions translate into economically meaningful payoffs, with monotonic return differentials and stable long-short performance across regularization settings. Empirically, CB-APM leverages consensus as a regularizer to amplify long-horizon predictability and yields interpretable consensus-based components that clarify how information is priced in returns. Moreover, regression and Gibbons-Ross-Shanken (GRS)-based pricing diagnostics reveal that the learned consensus representations capture priced variation only partially spanned by traditional factor models, demonstrating that CB-APM uncovers belief-driven structure in expected returns beyond the canonical factor space. Overall, CB-APM provides an interpretable and empirically grounded framework for understanding belief-driven return dynamics.",
    "broker": "Cornell Univ",
    "score": 9,
    "summary": "我们提出了共识瓶颈资产定价模型（CB-APM），这是一种部分可解释的神经网络，通过捕捉分散的投资者信念如何通过共识形成过程压缩为资产价格，来复制卖方分析师推理过程。该模型通过建模这一“瓶颈”来汇总公司和宏观层面的信息，不仅预测美国股票的未来风险溢价，还在结构上以可解释的方式将信念聚合与预期回报联系起来。CB-APM改进了长期回报预测，在预测准确性和解释力方面均优于标准深度学习方法。全面的投资组合分析表明，CB-APM的样本外预测转化为具有经济意义的回报，具有单调的回报差异和跨正则化设置的稳定多空表现。实证上，CB-APM利用共识作为正则化器来增强长期可预测性，并产生基于共识的可解释组件，阐明信息如何在回报中定价。此外，回归和基于Gibbons-Ross-Shanken（GRS）的定价诊断揭示了所学内容。",
    "fetch_date": "2025-12-24",
    "id": "20251224_da05e7f2"
  },
  {
    "title": "Reinforcement learning for quantitative trading",
    "url": "https://dl.acm.org/doi/abs/10.1145/3582560",
    "source": "Scholar",
    "date": "2025-12-24",
    "abstract": "… we used are reinforcement learning, quantitative finance, algorithmic trading, portfolio … a brief overview of financial markets and quantitative trading. Then, we introduce the preliminaries …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "该论文探讨了强化学习在量化交易中的应用，涵盖量化金融、算法交易和投资组合管理等领域。文章首先概述了金融市场和量化交易的基本概念，随后介绍了强化学习的理论基础及其在交易策略优化中的实际应用。",
    "fetch_date": "2025-12-24",
    "id": "20251224_3a476d40"
  },
  {
    "title": "Adaptive quantitative trading: An imitative deep reinforcement learning approach",
    "url": "https://aaai.org/ojs/index.php/AAAI/article/view/5587",
    "source": "Scholar",
    "date": "2025-12-24",
    "abstract": "… mathematical symbols then formally introduce the quantitative trading problem in detail. … always the goal of quantitative traders. This further proves that our trading agent can benefit from …",
    "broker": "Google Scholar",
    "score": 8,
    "summary": "《自适应量化交易：一种模仿深度强化学习方法》提出了一种基于深度强化学习的交易代理，能够从市场数据中学习并自适应调整交易策略。该方法通过模仿学习结合强化学习框架，旨在实现持续盈利这一量化交易的核心目标。论文表明该交易代理能够从历史数据中受益并优化交易决策，具有较高的实战应用潜力。",
    "fetch_date": "2025-12-24",
    "id": "20251224_766e09bf"
  },
  {
    "title": "Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems",
    "url": "https://arxiv.org/pdf/2512.18317v1",
    "source": "ArXiv",
    "date": "2025-12-20",
    "abstract": "This paper presents a trustworthy reinforcement learning approach for the control of industrial compressed air systems. We develop a framework that enables safe and energy-efficient operation under realistic boundary conditions and introduce a multi-level explainability pipeline combining input perturbation tests, gradient-based sensitivity analysis, and SHAP (SHapley Additive exPlanations) feature attribution. An empirical evaluation across multiple compressor configurations shows that the learned policy is physically plausible, anticipates future demand, and consistently respects system boundaries. Compared to the installed industrial controller, the proposed approach reduces unnecessary overpressure and achieves energy savings of approximately 4\\,\\% without relying on explicit physics models. The results further indicate that system pressure and forecast information dominate policy decisions, while compressor-level inputs play a secondary role. Overall, the combination of efficiency gains, predictive behavior, and transparent validation supports the trustworthy deployment of reinforcement learning in industrial energy systems.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文提出了一种可信赖的强化学习方法，用于工业压缩空气系统的控制。该框架能够在实际边界条件下实现安全、节能的运行，并引入了结合输入扰动测试、基于梯度的敏感性分析和SHAP（Shapley Additive exPlanations）特征归因的多层次可解释性管道。对多种压缩机配置的实证评估表明，学习到的策略在物理上是合理的，能够预测未来需求，并始终尊重系统边界。与已安装的工业控制器相比，所提出的方法减少了不必要的过压，在不依赖显式物理模型的情况下实现了约4%的节能。结果进一步表明，系统压力和预测信息主导了策略决策，而压缩机级别的输入则起次要作用。总体而言，效率提升、预测行为和透明验证的结合支持了强化学习在工业能源系统中的可信赖部署。",
    "fetch_date": "2025-12-24",
    "id": "20251224_4eec8973"
  },
  {
    "title": "Asymptotic and finite-sample distributions of one- and two-sample empirical relative entropy, with application to change-point detection",
    "url": "https://arxiv.org/pdf/2512.16411v1",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "Relative entropy, as a divergence metric between two distributions, can be used for offline change-point detection and extends classical methods that mainly rely on moment-based discrepancies. To build a statistical test suitable for this context, we study the distribution of empirical relative entropy and derive several types of approximations: concentration inequalities for finite samples, asymptotic distributions, and Berry-Esseen bounds in a pre-asymptotic regime. For the latter, we introduce a new approach to obtain Berry-Esseen inequalities for nonlinear functions of sum statistics under some convexity assumptions. Our theoretical contributions cover both one- and two-sample empirical relative entropies. We then detail a change-point detection procedure built on relative entropy and compare it, through extensive simulations, with classical methods based on moments or on information criteria. Finally, we illustrate its practical relevance on two real datasets involving temperature series and volatility of stock indices.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文研究了经验相对熵的分布，推导了有限样本的集中不等式、渐近分布以及前渐近状态下的Berry-Esseen界，并提出了一种基于相对熵的变点检测方法。通过模拟和真实数据（包括股票指数波动率）验证了该方法相对于基于矩或信息准则的传统方法的实用性。",
    "fetch_date": "2025-12-24",
    "id": "20251224_c7720f56"
  },
  {
    "title": "Design of a Decentralized Fixed-Income Lending Automated Market Maker Protocol Supporting Arbitrary Maturities",
    "url": "https://arxiv.org/pdf/2512.16080v1",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "In decentralized finance (DeFi), designing fixed-income lending automated market makers (AMMs) is extremely challenging due to time-related complexities. Moreover, existing protocols only support single-maturity lending. Building upon the BondMM protocol, this paper argues that its mathematical invariants are sufficiently elegant to be generalized to arbitrary maturities. This paper thus propose an improved design, BondMM-A, which supports lending activities of any maturity. By integrating fixed-income instruments of varying maturities into a single smart contract, BondMM-A offers users and liquidity providers (LPs) greater operational freedom and capital efficiency. Experimental results show that BondMM-A performs excellently in terms of interest rate stability and financial robustness.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "在去中心化金融（DeFi）中，由于时间相关的复杂性，设计固定收益借贷自动做市商（AMM）极具挑战性。现有协议仅支持单一期限借贷。本文基于BondMM协议，论证其数学不变量足够优雅，可推广至任意期限。因此，本文提出改进设计BondMM-A，支持任何期限的借贷活动。通过将不同期限的固定收益工具整合到单一智能合约中，BondMM-A为用户和流动性提供者（LPs）提供更大的操作自由和资本效率。实验结果表明，BondMM-A在利率稳定性和金融稳健性方面表现优异。",
    "fetch_date": "2025-12-24",
    "id": "20251224_c04304c9"
  },
  {
    "title": "Multi-Objective Bayesian Optimization of Deep Reinforcement Learning for Environmental, Social, and Governance (ESG) Financial Portfolio Management",
    "url": "https://arxiv.org/pdf/2512.14992v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "DRL agents circumvent the issue of classic models in the sense that they do not make assumptions like the financial returns being normally distributed and are able to deal with any information like the ESG score if they are configured to gain a reward that makes an objective better. However, the performance of DRL agents has high variability and it is very sensible to the value of their hyperparameters. Bayesian optimization is a class of methods that are suited to the optimization of black-box functions, that is, functions whose analytical expression is unknown, are noisy and expensive to evaluate. The hyperparameter tuning problem of DRL algorithms perfectly suits this scenario. As training an agent just for one objective is a very expensive period, requiring millions of timesteps, instead of optimizing an objective being a mixture of a risk-performance metric and an ESG metric, we choose to separate the objective and solve the multi-objective scenario to obtain an optimal Pareto set of portfolios representing the best tradeoff between the Sharpe ratio and the ESG mean score of the portfolio and leaving to the investor the choice of the final portfolio. We conducted our experiments using environments encoded within the OpenAI Gym, adapted from the FinRL platform. The experiments are carried out in the Dow Jones Industrial Average (DJIA) and the NASDAQ markets in terms of the Sharpe ratio achieved by the agent and the mean ESG score of the portfolio. We compare the performance of the obtained Pareto sets in hypervolume terms illustrating how portfolios are the best trade-off between the Sharpe ratio and mean ESG score. Also, we show the usefulness of our proposed methodology by comparing the obtained hypervolume with one achieved by a Random Search methodology on the DRL hyperparameter space.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文提出了一种用于环境、社会和治理（ESG）金融投资组合管理的多目标贝叶斯优化深度强化学习方法。深度强化学习（DRL）代理无需假设金融收益服从正态分布，并能处理ESG评分等信息，但其性能对超参数高度敏感。贝叶斯优化适用于优化黑盒函数，DRL的超参数调优正符合此场景。由于单目标训练成本高昂（需数百万时间步），作者将目标分离，通过多目标优化获得代表夏普比率与投资组合ESG平均评分之间最佳权衡的帕累托最优投资组合集，最终由投资者选择具体组合。",
    "fetch_date": "2025-12-24",
    "id": "20251224_e237fd82"
  },
  {
    "title": "Systemic Risk Radar: A Multi-Layer Graph Framework for Early Market Crash Warning",
    "url": "https://arxiv.org/pdf/2512.17185v1",
    "source": "ArXiv",
    "date": "2025-12-19",
    "abstract": "Financial crises emerge when structural vulnerabilities accumulate across sectors, markets, and investor behavior. Predicting these systemic transitions is challenging because they arise from evolving interactions between market participants, not isolated price movements alone. We present Systemic Risk Radar (SRR), a framework that models financial markets as multi-layer graphs to detect early signs of systemic fragility and crash-regime transitions.\n  We evaluate SRR across three major crises: the Dot-com crash, the Global Financial Crisis, and the COVID-19 shock. Our experiments compare snapshot GNNs, a simplified temporal GNN prototype, and standard baselines (logistic regression and Random Forest). Results show that structural network information provides useful early-warning signals compared to feature-based models alone.\n  This correlation-based instantiation of SRR demonstrates that graph-derived features capture meaningful changes in market structure during stress events. The findings motivate extending SRR with additional graph layers (sector/factor exposure, sentiment) and more expressive temporal architectures (LSTM/GRU or Transformer encoders) to better handle diverse crisis types.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "《系统性风险雷达：用于早期市场崩盘预警的多层图框架》提出了一种将金融市场建模为多层图以检测系统性脆弱性和崩盘状态转换早期迹象的框架。该研究评估了SRR在互联网泡沫、全球金融危机和COVID-19冲击三个重大危机中的表现，实验表明结构网络信息相比纯特征模型能提供更有用的早期预警信号。虽然该框架展示了图衍生特征在压力事件期间捕捉市场结构有意义变化的能力，但当前实现主要基于相关性分析，属于理论验证阶段。论文建议通过添加更多图层（行业/因子暴露、情绪）和更强大的时序架构（LSTM/GRU或Transformer编码器）来扩展SRR，这为实战交易系统开发提供了有价值的理论框架和方向指引。",
    "fetch_date": "2025-12-24",
    "id": "20251224_7b111b14"
  },
  {
    "title": "An Efficient Machine Learning Framework for Option Pricing via Fourier Transform",
    "url": "https://arxiv.org/pdf/2512.16115v1",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "The increasing need for rapid recalibration of option pricing models in dynamic markets places stringent computational demands on data generation and valuation algorithms. In this work, we propose a hybrid algorithmic framework that integrates the smooth offset algorithm (SOA) with supervised machine learning models for the fast pricing of multiple path-independent options under exponential Lévy dynamics. Building upon the SOA-generated dataset, we train neural networks, random forests, and gradient boosted decision trees to construct surrogate pricing operators. Extensive numerical experiments demonstrate that, once trained, these surrogates achieve order-of-magnitude acceleration over direct SOA evaluation. Importantly, the proposed framework overcomes key numerical limitations inherent to fast Fourier transform-based methods, including the consistency of input data and the instability in deep out-of-the-money option pricing.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "动态市场中期权定价模型快速重新校准的需求日益增长，这对数据生成和估值算法提出了严格的计算要求。本文提出了一种混合算法框架，将平滑偏移算法（SOA）与监督机器学习模型相结合，用于在指数Lévy动态下快速定价多种路径无关期权。基于SOA生成的数据集，我们训练神经网络、随机森林和梯度提升决策树来构建替代定价算子。大量数值实验表明，一旦训练完成，这些替代模型相比直接SOA评估实现了数量级的加速。重要的是，所提出的框架克服了基于快速傅里叶变换方法固有的关键数值限制，包括输入数据的一致性和深度虚值期权定价的不稳定性。",
    "fetch_date": "2025-12-24",
    "id": "20251224_21c43b5a"
  },
  {
    "title": "SigMA: Path Signatures and Multi-head Attention for Learning Parameters in fBm-driven SDEs",
    "url": "https://arxiv.org/pdf/2512.15088v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "Stochastic differential equations (SDEs) driven by fractional Brownian motion (fBm) are increasingly used to model systems with rough dynamics and long-range dependence, such as those arising in quantitative finance and reliability engineering. However, these processes are non-Markovian and lack a semimartingale structure, rendering many classical parameter estimation techniques inapplicable or computationally intractable beyond very specific cases. This work investigates two central questions: (i) whether integrating path signatures into deep learning architectures can improve the trade-off between estimation accuracy and model complexity, and (ii) what constitutes an effective architecture for leveraging signatures as feature maps. We introduce SigMA (Signature Multi-head Attention), a neural architecture that integrates path signatures with multi-head self-attention, supported by a convolutional preprocessing layer and a multilayer perceptron for effective feature encoding. SigMA learns model parameters from synthetically generated paths of fBm-driven SDEs, including fractional Brownian motion, fractional Ornstein-Uhlenbeck, and rough Heston models, with a particular focus on estimating the Hurst parameter and on joint multi-parameter inference, and it generalizes robustly to unseen trajectories. Extensive experiments on synthetic data and two real-world datasets (i.e., equity-index realized volatility and Li-ion battery degradation) show that SigMA consistently outperforms CNN, LSTM, vanilla Transformer, and Deep Signature baselines in accuracy, robustness, and model compactness. These results demonstrate that combining signature transforms with attention-based architectures provides an effective and scalable framework for parameter inference in stochastic systems with rough or persistent temporal structure.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "该论文提出SigMA（Signature Multi-head Attention）神经网络架构，将路径签名与多头自注意力机制结合，用于学习分数布朗运动驱动的随机微分方程参数。该方法针对具有粗糙动态和长程依赖的系统建模，如量化金融中的分数布朗运动、分数Ornstein-Uhlenbeck和粗糙Heston模型。研究聚焦于通过合成生成路径进行参数估计，探讨路径签名在深度学习架构中如何平衡估计精度与模型复杂度。",
    "fetch_date": "2025-12-24",
    "id": "20251224_a46aba2c"
  },
  {
    "title": "Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes",
    "url": "https://arxiv.org/pdf/2512.14991v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "We study reinforcement learning for controlled diffusion processes with unbounded continuous state spaces, bounded continuous actions, and polynomially growing rewards: settings that arise naturally in finance, economics, and operations research. To overcome the challenges of continuous and high-dimensional domains, we introduce a model-based algorithm that adaptively partitions the joint state-action space. The algorithm maintains estimators of drift, volatility, and rewards within each partition, refining the discretization whenever estimation bias exceeds statistical confidence. This adaptive scheme balances exploration and approximation, enabling efficient learning in unbounded domains. Our analysis establishes regret bounds that depend on the problem horizon, state dimension, reward growth order, and a newly defined notion of zooming dimension tailored to unbounded diffusion processes. The bounds recover existing results for bounded settings as a special case, while extending theoretical guarantees to a broader class of diffusion-type problems. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "本文研究针对具有无界连续状态空间、有界连续动作和多项式增长奖励的受控扩散过程的强化学习——这些设定自然出现在金融、经济和运筹学中。为克服连续高维领域的挑战，我们提出一种基于模型的算法，自适应地划分联合状态-动作空间。该算法在每个分区内维护漂移、波动率和奖励的估计器，并在估计偏差超过统计置信度时细化离散化。这种自适应方案平衡了探索与近似，使得在无界域中高效学习成为可能。我们的分析建立了遗憾界，其依赖于问题时域、状态维度、奖励增长阶数以及为无界扩散过程定制的新定义的“缩放维度”概念。这些界限将现有有界设定结果作为特例恢复，同时将理论保证扩展到更广泛的扩散类问题。最后，我们通过数值实验验证了方法的有效性，包括在高维问题中的应用。",
    "fetch_date": "2025-12-24",
    "id": "20251224_140ee511"
  },
  {
    "title": "Modelling financial time series with $φ^{4}$ quantum field theory",
    "url": "https://arxiv.org/pdf/2512.17225v1",
    "source": "ArXiv",
    "date": "2025-12-19",
    "abstract": "We use a $φ^{4}$ quantum field theory with inhomogeneous couplings and explicit symmetry-breaking to model an ensemble of financial time series from the S$\\&$P 500 index. The continuum nature of the $φ^4$ theory avoids the inaccuracies that occur in Ising-based models which require a discretization of the time series. We demonstrate this using the example of the 2008 global financial crisis. The $φ^{4}$ quantum field theory is expressive enough to reproduce the higher-order statistics such as the market kurtosis, which can serve as an indicator of possible market shocks. Accurate reproduction of high kurtosis is absent in binarized models. Therefore Ising models, despite being widely employed in econophysics, are incapable of fully representing empirical financial data, a limitation not present in the generalization of the $φ^{4}$ scalar field theory. We then investigate the scaling properties of the $φ^{4}$ machine learning algorithm and extract exponents which govern the behavior of the learned couplings (or weights and biases in ML language) in relation to the number of stocks in the model. Finally, we use our model to forecast the price changes of the AAPL, MSFT, and NVDA stocks. We conclude by discussing how the $φ^{4}$ scalar field theory could be used to build investment strategies and the possible intuitions that the QFT operations of dimensional compactification and renormalization can provide for financial modelling.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文使用具有非均匀耦合和显式对称性破缺的φ⁴量子场论来建模标普500指数中的金融时间序列集合。与需要离散化时间序列的伊辛模型相比，φ⁴理论的连续性质避免了不准确性，并能重现高阶统计量（如市场峰度），可作为市场冲击的指标。论文还研究了φ⁴机器学习算法的标度特性，并提取了控制学习耦合（或ML中的权重和偏置）与模型中股票数量关系的指数。最后，使用该模型预测了AAPL、MSFT和NVDA股票的价格变化。",
    "fetch_date": "2025-12-24",
    "id": "20251224_1cb49c57"
  },
  {
    "title": "Global universal approximation with Brownian signatures",
    "url": "https://arxiv.org/pdf/2512.16396v1",
    "source": "ArXiv",
    "date": "2025-12-18",
    "abstract": "We establish $L^p$-type universal approximation theorems for general and non-anticipative functionals on suitable rough path spaces, showing that linear functionals acting on signatures of time-extended rough paths are dense with respect to an $L^p$-distance. To that end, we derive global universal approximation theorems for weighted rough path spaces. We demonstrate that these $L^p$-type universal approximation theorems apply in particular to Brownian motion. As a consequence, linear functionals on the signature of the time-extended Brownian motion can approximate any $p$-integrable stochastic process adapted to the Brownian filtration, including solutions to stochastic differential equations.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文在加权粗糙路径空间上建立了L^p型全局通用逼近定理，证明了对时间扩展粗糙路径的签名进行线性泛函作用在L^p距离意义下是稠密的。特别地，这些定理适用于布朗运动，因此布朗运动时间扩展签名的线性泛函可以逼近任何适应于布朗滤波的p可积随机过程，包括随机微分方程的解。",
    "fetch_date": "2025-12-24",
    "id": "20251224_94b3ca35"
  },
  {
    "title": "Adaptive Weighted Genetic Algorithm-Optimized SVR for Robust Long-Term Forecasting of Global Stock Indices for investment decisions",
    "url": "https://arxiv.org/pdf/2512.15113v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "Long-term price forecasting remains a formidable challenge due to the inherent uncertainty over the long term, despite some success in short-term predictions. Nonetheless, accurate long-term forecasts are essential for high-net-worth individuals, institutional investors, and traders. The proposed improved genetic algorithm-optimized support vector regression (IGA-SVR) model is specifically designed for long-term price prediction of global indices. The performance of the IGA-SVR model is rigorously evaluated and compared against the state-of-the-art baseline models, the Long Short-Term Memory (LSTM), and the forward-validating genetic algorithm optimized support vector regression (OGA-SVR). Extensive testing was conducted on the five global indices, namely Nifty, Dow Jones Industrial Average (DJI), DAX Performance Index (DAX), Nikkei 225 (N225), and Shanghai Stock Exchange Composite Index (SSE) from 2021 to 2024 of daily price prediction up to a year. Overall, the proposed IGA-SVR model achieved a reduction in MAPE by 19.87% compared to LSTM and 50.03% compared to OGA-SVR, demonstrating its superior performance in long-term daily price forecasting of global indices. Further, the execution time for LSTM was approximately 20 times higher than that of IGA-SVR, highlighting the high accuracy and computational efficiency of the proposed model. The genetic algorithm selects the optimal hyperparameters of SVR by minimizing the arithmetic mean of the Mean Absolute Percentage Error (MAPE) calculated over the full training dataset and the most recent five years of training data. This purposefully designed training methodology adjusts for recent trends while retaining long-term trend information, thereby offering enhanced generalization compared to the LSTM and rolling-forward validation approach employed by OGA-SVR, which forgets long-term trends and suffers from recency bias.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文提出了一种改进的遗传算法优化支持向量回归（IGA-SVR）模型，专门用于全球股票指数的长期价格预测。在2021年至2024年期间，对Nifty、道琼斯工业平均指数（DJI）、DAX绩效指数（DAX）、日经225指数（N225）和上证综合指数（SSE）等五个全球指数进行了长达一年的每日价格预测测试。结果表明，与LSTM和OGA-SVR相比，IGA-SVR模型在平均绝对百分比误差（MAPE）上分别降低了19.87%和50.03%，显示出其在长期预测中的优越性能。",
    "fetch_date": "2025-12-24",
    "id": "20251224_b3187dce"
  },
  {
    "title": "Arbitrage-Free Pricing with Diffusion-Dependent Jumps",
    "url": "https://arxiv.org/pdf/2512.15071v1",
    "source": "ArXiv",
    "date": "2025-12-17",
    "abstract": "Standard jump-diffusion models assume independence between jumps and diffusion components. We develop a multi-type jump-diffusion model where jump occurrence and magnitude depend on contemporaneous diffusion movements. Unlike previous one-sided models that create arbitrage opportunities, our framework includes upward and downward jumps triggered by both large upward and large downward diffusion increments. We derive the explicit no-arbitrage condition linking the physical drift to model parameters and market risk premia by constructing an Equivalent Martingale Measure using Girsanov's theorem and a normalized Esscher transform. This condition provides a rigorous foundation for arbitrage-free pricing in models with diffusion-dependent jumps.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "标准跳跃扩散模型假设跳跃与扩散成分相互独立。本文开发了一种多类型跳跃扩散模型，其中跳跃的发生和幅度取决于同期的扩散运动。与以往可能产生套利机会的单边模型不同，我们的框架包含由大幅向上和向下扩散增量触发的向上和向下跳跃。通过使用Girsanov定理和归一化Esscher变换构建等价鞅测度，我们推导出将物理漂移与模型参数及市场风险溢价联系起来的明确无套利条件。该条件为具有扩散依赖跳跃的模型中的无套利定价提供了严格基础。",
    "fetch_date": "2025-12-24",
    "id": "20251224_33dbfdbc"
  },
  {
    "title": "Optimal Signal Extraction from Order Flow: A Matched Filter Perspective on Normalization and Market Microstructure",
    "url": "https://arxiv.org/pdf/2512.18648v1",
    "source": "ArXiv",
    "date": "2025-12-21",
    "abstract": "We demonstrate that the choice of normalization for order flow intensity is fundamental to signal extraction in finance, not merely a technical detail. Through theoretical modeling, Monte Carlo simulation, and empirical validation using Korean market data, we prove that market capitalization normalization acts as a ``matched filter'' for informed trading signals, achieving 1.32--1.97$\\times$ higher correlation with future returns compared to traditional trading value normalization. The key insight is that informed traders scale positions by firm value (market capitalization), while noise traders respond to daily liquidity (trading volume), creating heteroskedastic corruption when normalizing by trading volume. By reframing the normalization problem using signal processing theory, we show that dividing order flow by market capitalization preserves the information signal while traditional volume normalization multiplies the signal by inverse turnover -- a highly volatile quantity. Our theoretical predictions are robust across parameter specifications and validated by empirical evidence showing 482\\% improvement in explanatory power. These findings have immediate implications for high-frequency trading algorithms, risk factor construction, and information-based trading strategies.",
    "broker": "Cornell Univ",
    "score": 9,
    "summary": "本文论证了订单流强度归一化方法的选择对信号提取至关重要，而不仅仅是技术细节。通过理论建模、蒙特卡洛模拟和韩国市场数据的实证验证，证明市值归一化可作为知情交易信号的“匹配滤波器”，相比传统的交易额归一化，与未来收益的相关性提高1.32-1.97倍。核心观点是：知情交易者按公司价值（市值）调整头寸，而噪声交易者则响应日流动性（交易量），使用交易量归一化会导致异方差干扰。通过信号处理理论重新构建归一化问题，发现除以市值能保留信息信号，而传统的交易量归一化会将信号乘以逆换手率——一个高度波动的变量。理论预测在不同参数设定下均稳健，实证证据显示解释力提升482%。这些发现对高频交易、算法交易和风险模型具有直接应用价值。",
    "fetch_date": "2025-12-24",
    "id": "20251224_eb1783a9"
  },
  {
    "title": "Switching between states and the COVID-19 turbulence",
    "url": "https://arxiv.org/pdf/2512.20477v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "In Aarab (2020), I examine U.S. stock return predictability across economic regimes and document evidence of time-varying expected returns across market states in the long run. The analysis introduces a state-switching specification in which the market state is proxied by the slope of the yield curve, and proposes an Aligned Economic Index built from the popular predictors of Welch and Goyal (2008) (augmented with bond and equity premium measures). The Aligned Economic Index under the state-switching model exhibits statistically and economically meaningful in-sample ($R^2 = 5.9\\%$) and out-of-sample ($R^2_{\\text{oos}} = 4.12\\%$) predictive power across both recessions and expansions, while outperforming a range of widely used predictors. In this work, I examine the added value for professional practitioners by computing the economic gains for a mean-variance investor and find substantial added benefit of using the new index under the state switching model across all market states. The Aligned Economic Index can thus be implemented on a consistent real-time basis. These findings are crucial for both academics and practitioners as expansions are much longer-lived than recessions. Finally, I extend the empirical exercises by incorporating data through September 2020 and document sizable gains from using the Aligned Economic Index, relative to more traditional approaches, during the COVID-19 market turbulence.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文通过引入状态切换模型（以收益率曲线斜率作为市场状态代理变量）和构建对齐经济指数（基于Welch和Goyal（2008）的经典预测因子，并加入债券和股权溢价指标），实证显示该指数在样本内（R²=5.9%）和样本外（R²oos=4.12%）均对美股收益具有统计及经济意义的预测能力，且优于多种常用预测因子。研究进一步通过均值-方差投资者模型验证了该模型在所有市场状态下均能带来显著经济收益，并强调该指数可实时应用于实践。这些发现对从业者尤为重要，因为经济扩张期远长于衰退期。",
    "fetch_date": "2025-12-24",
    "id": "20251224_a39154aa"
  },
  {
    "title": "The Aligned Economic Index & The State Switching Model",
    "url": "https://arxiv.org/pdf/2512.20460v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "A growing empirical literature suggests that equity-premium predictability is state dependent, with much of the forecasting power concentrated around recessionary periods \\parencite{Henkel2011,DanglHalling2012,Devpura2018}. I study U.S. stock return predictability across economic regimes and document strong evidence of time-varying expected returns across both expansionary and contractionary states. I contribute in two ways. First, I introduce a state-switching predictive regression in which the market state is defined in real time using the slope of the yield curve. Relative to the standard one-state predictive regression, the state-switching specification increases both in-sample and out-of-sample performance for the set of popular predictors considered by \\textcite{WelchGoyal2008}, improving the out-of-sample performance of most predictors in economically meaningful ways. Second, I propose a new aggregate predictor, the Aligned Economic Index, constructed via partial least squares (PLS). Under the state-switching model, the Aligned Economic Index exhibits statistically and economically significant predictive power in sample and out of sample, and it outperforms widely used benchmark predictors and alternative predictor-combination methods.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文研究了美国股票收益在不同经济状态下的可预测性，提出了两个对实战交易有价值的贡献：一是引入基于收益率曲线斜率实时定义市场状态的状态切换预测回归模型，相比传统单状态模型显著提高了样本内和样本外预测性能；二是通过偏最小二乘法构建了新的聚合预测指标——对齐经济指数，在状态切换模型下展现出统计和经济意义上显著的样本内外预测能力。论文聚焦于经济状态依赖的股票溢价预测，其状态切换模型和对齐经济指数可直接应用于实战中的择时和风险管理策略。",
    "fetch_date": "2025-12-24",
    "id": "20251224_23ae3263"
  },
  {
    "title": "GIFfluence: A Visual Approach to Investor Sentiment and the Stock Market",
    "url": "https://arxiv.org/pdf/2512.20027v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "We study dynamic visual representations as a proxy for investor sentiment about the stock market. Our sentiment index, GIFsentiment, is constructed from millions of posts in the Graphics Interchange Format (GIF) on a leading investment social media platform. GIFsentiment correlates with seasonal mood variations and the severity of COVID lockdowns. It is positively associated with contemporaneous market returns and negatively predicts returns for up to four weeks, even after controlling for other sentiment and attention measures. These effects are stronger among portfolios that are more susceptible to mispricing. GIFsentiment positively predicts trading volume, market volatility, and flows toward equity funds and away from debt funds. Our evidence suggests that GIFsentiment is a proxy for misperceptions that are later corrected.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文提出了一种基于投资社交媒体平台GIF帖子的投资者情绪指标GIFsentiment。研究发现：1）该指标与季节性情绪波动和疫情封锁严重程度相关；2）与同期市场收益正相关，并能负向预测未来四周收益（控制其他情绪指标后仍显著）；3）对易受错误定价影响的投资组合预测效果更强；4）能正向预测交易量、市场波动率以及资金从债券基金流向股票基金。证据表明GIFsentiment可作为市场错误认知的代理指标，这些认知后续会被修正。",
    "fetch_date": "2025-12-24",
    "id": "20251224_78339dde"
  },
  {
    "title": "Covariance-Aware Simplex Projection for Cardinality-Constrained Portfolio Optimization",
    "url": "https://arxiv.org/pdf/2512.19986v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "Metaheuristic algorithms for cardinality-constrained portfolio optimization require repair operators to map infeasible candidates onto the feasible region. Standard Euclidean projection treats assets as independent and can ignore the covariance structure that governs portfolio risk, potentially producing less diversified portfolios. This paper introduces Covariance-Aware Simplex Projection (CASP), a two-stage repair operator that (i) selects a target number of assets using volatility-normalized scores and (ii) projects the candidate weights using a covariance-aware geometry aligned with tracking-error risk. This provides a portfolio-theoretic foundation for using a covariance-induced distance in repair operators. On S&P 500 data (2020-2024), CASP-Basic delivers materially lower portfolio variance than standard Euclidean repair without relying on return estimates, with improvements that are robust across assets and statistically significant. Ablation results indicate that volatility-normalized selection drives most of the variance reduction, while the covariance-aware projection provides an additional, consistent improvement. We further show that optional return-aware extensions can improve Sharpe ratios, and out-of-sample tests confirm that gains transfer to realized performance. CASP integrates as a drop-in replacement for Euclidean projection in metaheuristic portfolio optimizers.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "本文提出了一种用于基数约束投资组合优化的协方差感知单纯形投影方法。针对元启发式算法中修复算子将不可行候选解映射到可行区域时忽略协方差结构的问题，该方法采用两阶段修复：首先基于波动率归一化评分选择目标资产数量，然后使用与跟踪误差风险对齐的协方差感知几何进行权重投影。在S&P 500数据上的实证表明，该方法在不依赖收益预测的情况下显著降低了投资组合方差，且改进具有统计显著性。消融实验显示波动率归一化选择贡献了主要方差降低，而协方差感知投影提供了额外的稳定改进。",
    "fetch_date": "2025-12-24",
    "id": "20251224_432db6dc"
  },
  {
    "title": "Needles in a haystack: using forensic network science to uncover insider trading",
    "url": "https://arxiv.org/pdf/2512.18918v1",
    "source": "ArXiv",
    "date": "2025-12-21",
    "abstract": "Although the automation and digitisation of anti-financial crime investigation has made significant progress in recent years, detecting insider trading remains a unique challenge, partly due to the limited availability of labelled data. To address this challenge, we propose using a data-driven networks approach that flags groups of corporate insiders who report coordinated transactions that are indicative of insider trading. Specifically, we leverage data on 2.9 million trades reported to the U.S. Securities and Exchange Commission (SEC) by company insiders (C-suite executives, board members and major shareholders) between 2014 and 2024. Our proposed algorithm constructs weighted edges between insiders based on the temporal similarity of their trades over the 10-year timeframe. Within this network we then uncover trends that indicate insider trading by focusing on central nodes and anomalous subgraphs. To highlight the validity of our approach we evaluate our findings with reference to two null models, generated by running our algorithm on synthetic empirically calibrated and shuffled datasets. The results indicate that our approach can be used to detect pairs or clusters of insiders whose behaviour suggests insider trading and/or market manipulation.",
    "broker": "Cornell Univ",
    "score": 7,
    "summary": "该论文提出了一种利用法证网络科学检测内幕交易的数据驱动网络方法。通过分析2014-2024年间美国证券交易委员会（SEC）收到的290万笔公司内部人（高管、董事会成员和大股东）交易报告，该算法基于交易时间相似性构建内部人之间的加权边网络，并通过识别中心节点和异常子图来揭示内幕交易模式。研究使用合成经验校准和随机数据集生成的零模型验证了方法的有效性，表明该方法能有效检测协同交易的内幕交易对或集群。",
    "fetch_date": "2025-12-24",
    "id": "20251224_944d270d"
  },
  {
    "title": "Quantitative Financial Modeling for Sri Lankan Markets: Approach Combining NLP, Clustering and Time-Series Forecasting",
    "url": "https://arxiv.org/pdf/2512.20216v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "This research introduces a novel quantitative methodology tailored for quantitative finance applications, enabling banks, stockbrokers, and investors to predict economic regimes and market signals in emerging markets, specifically Sri Lankan stock indices (S&P SL20 and ASPI) by integrating Environmental, Social, and Governance (ESG) sentiment analysis with macroeconomic indicators and advanced time-series forecasting. Designed to leverage quantitative techniques for enhanced risk assessment, portfolio optimization, and trading strategies in volatile environments, the architecture employs FinBERT, a transformer-based NLP model, to extract sentiment from ESG texts, followed by unsupervised clustering (UMAP/HDBSCAN) to identify 5 latent ESG regimes, validated via PCA. These regimes are mapped to economic conditions using a dense neural network and gradient boosting classifier, achieving 84.04% training and 82.0% validation accuracy. Concurrently, time-series models (SRNN, MLP, LSTM, GRU) forecast daily closing prices, with GRU attaining an R-squared of 0.801 and LSTM delivering 52.78% directional accuracy on intraday data. A strong correlation between S&P SL20 and S&P 500, observed through moving average and volatility trend plots, further bolsters forecasting precision. A rule-based fusion logic merges ESG and time-series outputs for final market signals. By addressing literature gaps that overlook emerging markets and holistic integration, this quant-driven framework combines global correlations and local sentiment analysis to offer scalable, accurate tools for quantitative finance professionals navigating complex markets like Sri Lanka.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "该研究为斯里兰卡市场（S&P SL20和ASPI指数）提出了一种新颖的量化金融建模方法，通过整合ESG情感分析（使用FinBERT模型）、宏观经济指标和先进的时间序列预测技术（包括SRNN、MLP、LSTM、GRU），旨在预测经济状态和市场信号。该方法采用无监督聚类（UMAP/HDBSCAN）识别出5个潜在的ESG状态，并通过密集神经网络和梯度提升分类器将其映射到经济条件，训练和验证准确率分别达到84.04%和82.0%。在时间序列预测方面，GRU模型的R平方为0.801，LSTM在日内数据上的方向准确性为52.78%。研究还观察到S&P SL20与S&P 500之间存在强相关性。该框架旨在增强风险评估、投资组合优化和交易策略，适用于波动环境中的新兴市场。",
    "fetch_date": "2025-12-24",
    "id": "20251224_6cec85b9"
  },
  {
    "title": "Pricing of wrapped Bitcoin and Ethereum on-chain options",
    "url": "https://arxiv.org/pdf/2512.20190v1",
    "source": "ArXiv",
    "date": "2025-12-23",
    "abstract": "This paper measures price differences between Hegic option quotes on Arbitrum and a model-based benchmark built on Black--Scholes model with regime-sensitive volatility estimated via a two-regime MS-AR-(GJR)-GARCH model. Using option-level feasible GLS, we find benchmark prices exceed Hegic quotes on average, especially for call options. The price spread rises with order size, strike, maturity, and estimated volatility, and falls with trading volume. By underlying, wrapped Bitcoin options show larger and more persistent spreads, while Ethereum options are closer to the benchmark. The framework offers a data-driven analysis for monitoring and calibrating on-chain option pricing logic.",
    "broker": "Cornell Univ",
    "score": 6,
    "summary": "该论文通过对比Hegic在Arbitrum上的期权报价与基于两区制MS-AR-(GJR)-GARCH模型估计波动率的Black-Scholes基准模型，发现基准价格普遍高于Hegic报价（尤其是看涨期权）。价差随订单规模、行权价、期限和估计波动率增加而扩大，随交易量增加而缩小。其中，包装比特币期权价差更大且更持久，以太坊期权则更接近基准。该框架为监控和校准链上期权定价逻辑提供了数据驱动的分析方法。",
    "fetch_date": "2025-12-24",
    "id": "20251224_6243b8b8"
  },
  {
    "title": "Equilibrium Liquidity and Risk Offsetting in Decentralised Markets",
    "url": "https://arxiv.org/pdf/2512.19838v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "We develop an economic model of decentralised exchanges (DEXs) in which risk-averse liquidity providers (LPs) manage risk in a centralised exchange (CEX) based on preferences, information, and trading costs. Rational, risk-averse LPs anticipate the frictions associated with replication and manage risk primarily by reducing the reserves supplied to the DEX. Greater aversion reduces the equilibrium viability of liquidity provision, resulting in thinner markets and lower trading volumes. Greater uninformed demand supports deeper liquidity, whereas higher fundamental price volatility erodes it. Finally, while moderate anticipated price changes can improve LP performance, larger changes require more intensive trading in the CEX, generate higher replication costs, and induce LPs to reduce liquidity supply.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文构建了一个去中心化交易所（DEX）的经济模型，研究风险厌恶的流动性提供者（LPs）如何基于偏好、信息与交易成本，在中心化交易所（CEX）管理风险。理性且风险厌恶的LPs会预判与复制相关的摩擦，主要通过减少向DEX提供的储备来管理风险。更高的风险厌恶会降低流动性提供的均衡可行性，导致市场更薄、交易量更低。更大的非知情需求支持更深的流动性，而更高的基础价格波动则会削弱流动性。最后，虽然适度的预期价格变动可能改善LP表现，但更大的变动需要在CEX进行更密集的交易，产生更高的复制成本，并促使LPs减少流动性供给。",
    "fetch_date": "2025-12-24",
    "id": "20251224_27c66c3f"
  },
  {
    "title": "How to choose my stochastic volatility parameters? A review",
    "url": "https://arxiv.org/pdf/2512.19821v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "Based on the existing literature, this article presents the different ways of choosing the parameters of stochastic volatility models in general, in the context of pricing financial derivative contracts. This includes the use of stochastic volatility inside stochastic local volatility models.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "基于现有文献，本文综述了在金融衍生品定价背景下，选择随机波动率模型参数的各种方法，包括在随机局部波动率模型中使用随机波动率。",
    "fetch_date": "2025-12-24",
    "id": "20251224_faddc8fe"
  },
  {
    "title": "Counterexamples for FX Options Interpolations -- Part II",
    "url": "https://arxiv.org/pdf/2512.19625v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "This follow-up article analyzes the impact of foreign exchange option interpolation on the vanilla option implied volatilities. In particular different exact interpolations of broker quotes may lead to different implied volatilities at the 10$Δ$ and 25$Δ$ Puts and Calls.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "这篇后续文章分析了外汇期权插值对普通期权隐含波动率的影响。具体而言，经纪商报价的不同精确插值方法可能导致10Δ和25Δ看跌期权与看涨期权的隐含波动率出现差异。",
    "fetch_date": "2025-12-24",
    "id": "20251224_bee73e28"
  },
  {
    "title": "Counterexamples for FX Options Interpolations -- Part I",
    "url": "https://arxiv.org/pdf/2512.19621v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "This article provides a list of counterexamples, where some of the popular fx option interpolations break down. Interpolation of FX option prices (or equivalently volatilities), is key to risk-manage not only vanilla FX option books, but also more exotic derivatives which are typically valued with local volatility or local stochastic volatilility models.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文列举了外汇期权插值方法失效的反例，指出插值对于风险管理至关重要，不仅涉及普通外汇期权，也影响使用局部波动率或局部随机波动率模型定价的奇异衍生品。",
    "fetch_date": "2025-12-24",
    "id": "20251224_43d5d092"
  },
  {
    "title": "Heston vol-of-vol and the VVIX",
    "url": "https://arxiv.org/pdf/2512.19611v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "The Heston stochastic volatility model is arguably, the most popular stochastic volatility model used to price and risk manage exotic derivatives. In spite of this, it is not necessarily easy to calibrate to the market and obtain stable exotic option prices with this model. This paper focuses on the vol-of-vol parameter and its relation with the volatility of volatility index (VVIX) level. Four different approaches to estimate the VVIX in the Heston model are presented: two based on the known transition density of the variance, one analytical approximation, and one based on the Heston PDE which computes the value directly out of the underlying SPX500. Finally we explore their use to improve calibration stability.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "本文聚焦于Heston随机波动率模型中的波动率波动率参数及其与波动率波动率指数（VVIX）水平的关系。提出了四种在Heston模型中估计VVIX的方法：两种基于已知的方差转移密度，一种解析近似方法，以及一种基于Heston偏微分方程直接从标普500指数计算的方法。最后探讨了这些方法在提高模型校准稳定性方面的应用。",
    "fetch_date": "2025-12-24",
    "id": "20251224_dad4d8e3"
  },
  {
    "title": "Learning General Policies with Policy Gradient Methods",
    "url": "https://arxiv.org/pdf/2512.19366v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "While reinforcement learning methods have delivered remarkable results in a number of settings, generalization, i.e., the ability to produce policies that generalize in a reliable and systematic way, has remained a challenge. The problem of generalization has been addressed formally in classical planning where provable correct policies that generalize over all instances of a given domain have been learned using combinatorial methods. The aim of this work is to bring these two research threads together to illuminate the conditions under which (deep) reinforcement learning approaches, and in particular, policy optimization methods, can be used to learn policies that generalize like combinatorial methods do. We draw on lessons learned from previous combinatorial and deep learning approaches, and extend them in a convenient way. From the former, we model policies as state transition classifiers, as (ground) actions are not general and change from instance to instance. From the latter, we use graph neural networks (GNNs) adapted to deal with relational structures for representing value functions over planning states, and in our case, policies. With these ingredients in place, we find that actor-critic methods can be used to learn policies that generalize almost as well as those obtained using combinatorial approaches while avoiding the scalability bottleneck and the use of feature pools. Moreover, the limitations of the DRL methods on the benchmarks considered have little to do with deep learning or reinforcement learning algorithms, and result from the well-understood expressive limitations of GNNs, and the tradeoff between optimality and generalization (general policies cannot be optimal in some domains). Both of these limitations are addressed without changing the basic DRL methods by adding derived predicates and an alternative cost structure to optimize.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文探讨了强化学习方法（特别是策略梯度方法）在何种条件下能学习到具有泛化能力的策略，类似于组合方法在经典规划中所实现的。作者结合了组合方法与深度学习的思路，将策略建模为状态转移分类器（因为具体动作会随问题实例变化），并使用图神经网络（GNNs）来处理关系结构以表示规划状态的价值函数和策略。研究旨在弥合强化学习与可证明泛化的组合方法之间的差距，但重点在于理论框架与条件分析，而非直接应用于实战交易场景。",
    "fetch_date": "2025-12-24",
    "id": "20251224_5412cd38"
  },
  {
    "title": "Institutional Backing and Crypto Volatility: A Hybrid Framework for DeFi Stabilization",
    "url": "https://arxiv.org/pdf/2512.19251v1",
    "source": "ArXiv",
    "date": "2025-12-22",
    "abstract": "Decentralized finance (DeFi) lacks centralized oversight, often resulting in heightened volatility. In contrast, centralized finance (CeFi) offers a more stable environment with institutional safeguards. Institutional backing can play a stabilizing role in a hybrid structure (HyFi), enhancing transparency, governance, and market discipline. This study investigates whether HyFi-like cryptocurrencies, those backed by institutions, exhibit lower price risk than fully decentralized counterparts. Using daily data for 18 major cryptocurrencies from January 2020 to November 2024, we estimate panel EGLS models with fixed, random, and dynamic specifications. Results show that HyFi-like assets consistently experience lower price risk, with this effect intensifying during periods of elevated market volatility. The negative interaction between HyFi status and market-wide volatility confirms their stabilizing role. Conversely, greater decentralization is strongly associated with increased volatility, particularly during periods of market stress. Robustness checks using quantile regressions and pre-/post-Terra Luna subsamples reinforce these findings, with stronger effects observed in high-volatility quantiles and post-crisis conditions. These results highlight the importance of institutional architecture in enhancing the resilience of digital asset markets.",
    "broker": "Cornell Univ",
    "score": 4,
    "summary": "该论文探讨了去中心化金融（DeFi）因缺乏中心化监管而波动性较高，而中心化金融（CeFi）通过机构保障提供更稳定环境。研究发现，在混合结构（HyFi）中，机构支持能通过增强透明度、治理和市场纪律发挥稳定作用。基于2020年1月至2024年11月18种主要加密货币的日度数据，面板EGLS模型显示，具有机构支持的HyFi类资产价格风险较低，且在市场波动加剧时期稳定作用更明显。相反，去中心化程度越高，波动性越强，尤其在市场压力时期。分位数回归及Terra Luna事件前后子样本的稳健性检验支持了这些结论。",
    "fetch_date": "2025-12-24",
    "id": "20251224_36795ecf"
  }
]