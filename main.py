import os
import json
import datetime
import requests
import smtplib
import arxiv
from email.mime.text import MIMEText
from email.header import Header
from openai import OpenAI
from serpapi import GoogleSearch

# ==========================================
#              1. å…¨å±€é…ç½®åŒºåŸŸ (CONFIG)
#           âš™ï¸ æ‰€æœ‰å‚æ•°éƒ½åœ¨è¿™é‡Œä¿®æ”¹ï¼
# ==========================================

CONFIG = {
    # --- åŸºç¡€è·¯å¾„ä¸é˜ˆå€¼ ---
    "DATA_FILE": "data/reports.json", 
    "MAX_HISTORY": 500,               # å†å²è®°å½•ä¿ç•™æ¡æ•°
    "MIN_SCORE": 5.0,                 # æ”¶å½•é—¨æ§› (ä½äºæ­¤åˆ†ç›´æ¥ä¸¢å¼ƒ)
    "PUSH_THRESHOLD": 6.0,            # æ¨é€é—¨æ§› (é«˜äºæ­¤åˆ†æ‰å‘é’‰é’‰)
    
    # --- æ•°é‡æ§åˆ¶ (No Magic Numbers!) ---
    "FINAL_SAVE_COUNT": 15,           # æ¯å¤©æœ€ç»ˆæ”¶å½•å¹¶å‘é€é‚®ä»¶çš„æœ€å¤§ç¯‡æ•°
    "DINGTALK_PUSH_LIMIT": 5,         # é’‰é’‰æœ€å¤šæ¨é€å‡ ç¯‡ (é˜²æ­¢åˆ·å±)
    
    # --- æŠ“å–æºè®¾ç½® ---
    "FETCH_COUNT_ARXIV": 30,          # ArXiv åŸå§‹æŠ“å–é‡
    "FETCH_COUNT_GOOGLE_PER_QUERY": 5,# Google æ¯ä¸ªå…³é”®è¯æŠ“å–é‡
    
    # --- æ–‡æœ¬å¤„ç† ---
    "MAX_TEXT_LENGTH_FOR_AI": 1200,   # å–‚ç»™ AI çš„æ‘˜è¦æœ€å¤§é•¿åº¦ (å­—ç¬¦æ•°)
    
    # --- æœç´¢æ—¶é—´èŒƒå›´ ---
    "SEARCH_YEAR": "2024",            # æœç´¢å“ªä¸€å¹´ä¹‹åçš„æ–‡ç« 
    
    # --- ArXiv å…³é”®è¯ ---
    "ARXIV_KEYWORDS": [
        "quantitative finance",
        "factor model",
        "portfolio optimization",
        "deep learning trading",      
        "reinforcement learning trading", 
        "machine learning trading",   
        "algorithm trading",          
        "market microstructure",
        "risk premia"
    ],
    
    # --- Google Scholar å…³é”®è¯ ---
    # æ³¨æ„ï¼šè¿™é‡Œçš„ year ä¼šåœ¨ä»£ç é‡ŒåŠ¨æ€æ›¿æ¢
    "GOOGLE_QUERIES": [
        'quantitative trading "reinforcement learning"', 
        'quantitative trading "deep learning"',          
        '"algorithmic trading" strategy'                 
    ]
}

# ==========================================
#              2. ç¯å¢ƒå˜é‡åŠ è½½
# ==========================================
LLM_API_KEY = os.environ.get("LLM_API_KEY")
DINGTALK_WEBHOOK = os.environ.get("DINGTALK_WEBHOOK")
EMAIL_USER = os.environ.get("EMAIL_USER")
EMAIL_PASS = os.environ.get("EMAIL_PASS")
SERPAPI_KEY = os.environ.get("SERPAPI_KEY")

# åˆå§‹åŒ– AI
client = OpenAI(api_key=LLM_API_KEY, base_url="https://api.deepseek.com")

# ==========================================
#              3. æ ¸å¿ƒæŠ“å–é€»è¾‘
# ==========================================

def fetch_arxiv():
    """æŠ“å– ArXiv"""
    print(f"--- æ­£åœ¨æŠ“å– ArXiv ---")
    keywords_query = " OR ".join([f'"{k}"' for k in CONFIG['ARXIV_KEYWORDS']])
    query = f'(cat:q-fin.* OR cat:cs.AI) AND ({keywords_query})'
    
    try:
        search = arxiv.Search(
            query=query,
            max_results=CONFIG['FETCH_COUNT_ARXIV'],
            sort_by=arxiv.SortCriterion.SubmittedDate
        )
        results = []
        for r in search.results():
            # é€‚é…æ–°ç‰ˆ arxiv åº“: categories æ˜¯ list of strings
            if not any(tag.startswith(('q-fin', 'cs', 'stat')) for tag in r.categories):
                continue

            results.append({
                "title": r.title,
                "url": r.pdf_url,
                "source": "ArXiv",
                "date": r.published.strftime("%Y-%m-%d"),
                "abstract": r.summary,
                "broker": "Cornell Univ" 
            })
        print(f"ArXiv æŠ“å–åˆ° {len(results)} æ¡")
        return results
    except Exception as e:
        print(f"ArXiv æŠ“å–å¤±è´¥: {e}")
        return []

def fetch_google_scholar():
    """æŠ“å– Google Scholar"""
    if not SERPAPI_KEY:
        print("æœªé…ç½® SERPAPI_KEYï¼Œè·³è¿‡")
        return []
        
    print(f"--- æ­£åœ¨æŠ“å– Google Scholar ---")
    all_results = []
    
    for base_query in CONFIG['GOOGLE_QUERIES']:
        # åŠ¨æ€æ‹¼æ¥å¹´ä»½: query + " after:2024"
        query_with_year = f'{base_query} after:{CONFIG["SEARCH_YEAR"]}'
        
        try:
            print(f"æœç´¢: {query_with_year} ...")
            params = {
                "engine": "google_scholar",
                "q": query_with_year,
                "api_key": SERPAPI_KEY,
                "num": CONFIG['FETCH_COUNT_GOOGLE_PER_QUERY'],
                "hl": "en"
            }
            search = GoogleSearch(params)
            data = search.get_dict()
            organic_results = data.get("organic_results", [])
            
            for item in organic_results:
                if 'link' not in item: continue
                all_results.append({
                    "title": item.get("title"),
                    "url": item.get("link"),
                    "source": "Scholar",
                    "date": datetime.datetime.now().strftime("%Y-%m-%d"),
                    "abstract": item.get("snippet", item.get("title")),
                    "broker": "Google Scholar"
                })
        except Exception as e:
            print(f"Scholar æŸ¥è¯¢å‡ºé”™: {e}")
            
    return all_results

# ==========================================
#              4. æ™ºèƒ½åˆ†æä¸ç¿»è¯‘
# ==========================================

def analyze_with_llm(item):
    """AI è¯„åˆ†ä¸ç¿»è¯‘"""
    try:
        # ä½¿ç”¨é…ç½®é‡Œçš„é•¿åº¦é™åˆ¶
        abstract_text = item['abstract'][:CONFIG['MAX_TEXT_LENGTH_FOR_AI']]
        
        prompt = f"""
        ä½ æ˜¯ä¸€åèµ„æ·±çš„é‡åŒ–äº¤æ˜“ç ”ç©¶å‘˜ã€‚è¯·é˜…è¯»ä»¥ä¸‹è‹±æ–‡è®ºæ–‡çš„æ ‡é¢˜å’Œæ‘˜è¦ã€‚
        
        ä»»åŠ¡ï¼š
        1. è¯„åˆ† (0-10åˆ†)ï¼š"å¼ºåŒ–å­¦ä¹ /æ·±åº¦å­¦ä¹ +äº¤æ˜“"ç±»è®ºæ–‡ç»™8åˆ†ä»¥ä¸Šï¼Œçº¯ç†è®ºæ•°å­¦ç»™4åˆ†ä»¥ä¸‹ã€‚
        2. ä¸­æ–‡æ‘˜è¦ï¼šè¯·å°†è‹±æ–‡æ‘˜è¦ç¿»è¯‘æˆé€šä¿—æµç•…çš„ä¸­æ–‡ã€‚ç¿»è¯‘æ—¶è¯·ä¿ç•™å…³é”®çš„ç®—æ³•åç§°ï¼ˆå¦‚ Transformer, LSTM, PPO ç­‰ï¼‰ä¸ç¿»è¯‘ã€‚
        
        è®ºæ–‡æ ‡é¢˜: {item['title']}
        åŸæ–‡æ‘˜è¦: {abstract_text}
        
        è¯·ä¸¥æ ¼æŒ‰ JSON æ ¼å¼è¿”å›ï¼š
        {{
            "score": <æ•°å­—>,
            "summary": "<è¿™é‡Œå¡«ä¸­æ–‡ç¿»è¯‘å†…å®¹>"
        }}
        """
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        print(f"LLM åˆ†æå¤±è´¥: {e}")
        return {"score": 6.0, "summary": "AI ç¿»è¯‘å¤±è´¥ï¼Œè¯·æŸ¥çœ‹åŸæ–‡ã€‚"}

def send_dingtalk(msg_markdown):
    """å‘é€é’‰é’‰"""
    if not DINGTALK_WEBHOOK: return
    try:
        headers = {"Content-Type": "application/json"}
        data = {
            "msgtype": "markdown",
            "markdown": {
                "title": "é‡åŒ–æ—¥æŠ¥",
                "text": msg_markdown
            }
        }
        requests.post(DINGTALK_WEBHOOK, json=data)
    except Exception as e:
        print(f"é’‰é’‰å‘é€å¤±è´¥: {e}")

def send_email(subject, html_content):
    """å‘é€é‚®ä»¶"""
    if not EMAIL_USER or not EMAIL_PASS: return
    try:
        msg = MIMEText(html_content, 'html', 'utf-8')
        msg['Subject'] = Header(subject, 'utf-8')
        msg['From'] = EMAIL_USER
        msg['To'] = EMAIL_USER 
        
        smtp = smtplib.SMTP_SSL('smtp.qq.com', 465)
        smtp.login(EMAIL_USER, EMAIL_PASS)
        smtp.send_message(msg)
        smtp.quit()
    except Exception as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥: {e}")

# ==========================================
#              5. ä¸»ç¨‹åºå…¥å£
# ==========================================

def main():
    print(">>> ä»»åŠ¡å¼€å§‹")
    
    # 1. åŠ è½½å†å²
    history_ids = []
    if os.path.exists(CONFIG["DATA_FILE"]):
        try:
            with open(CONFIG["DATA_FILE"], 'r', encoding='utf-8') as f:
                old_data = json.load(f)
                history_ids = [item.get('title') for item in old_data]
        except: pass

    # 2. æŠ“å– (Scholar åœ¨å‰ï¼ŒArXiv åœ¨åï¼Œå…¬å¹³ç«äº‰)
    raw_items = []
    raw_items += fetch_google_scholar()
    raw_items += fetch_arxiv()
    
    print(f">>> å…±æŠ“å–åˆ° {len(raw_items)} æ¡ï¼Œå¼€å§‹ AI ç¿»è¯‘ä¸è¯„åˆ†...")

    # 3. AI åˆ†æ (æ—  break é™åˆ¶ï¼Œå…¨é‡è·‘)
    processed_items = []
    
    for item in raw_items:
        if item['title'] in history_ids: continue
            
        print(f"æ­£åœ¨åˆ†æ: {item['title'][:40]}...")
        result = analyze_with_llm(item)
        
        if result['score'] >= CONFIG['MIN_SCORE']:
            item['score'] = result['score']
            item['summary'] = result['summary']
            item['fetch_date'] = datetime.datetime.now().strftime("%Y-%m-%d")
            item['id'] = datetime.datetime.now().strftime("%Y%m%d") + "_" + str(len(processed_items))
            processed_items.append(item)
            
    # 4. æ’åºä¸æˆªæ–­ (ä½¿ç”¨é…ç½®å‚æ•°)
    processed_items.sort(key=lambda x: x['score'], reverse=True)
    
    # å–å‰ N å (ä½¿ç”¨ CONFIG['FINAL_SAVE_COUNT'])
    new_qualified = processed_items[:CONFIG['FINAL_SAVE_COUNT']]
    
    print(f">>> ç»ç­›é€‰ï¼Œå…±æœ‰ {len(new_qualified)} æ¡å…¥é€‰æ—¥æŠ¥")

    # 5. æ¨é€
    if new_qualified:
        # A. ä¿å­˜
        if os.path.exists(CONFIG["DATA_FILE"]):
            with open(CONFIG["DATA_FILE"], 'r', encoding='utf-8') as f:
                current = json.load(f)
        else: current = []
        final_data = new_qualified + current
        with open(CONFIG["DATA_FILE"], 'w', encoding='utf-8') as f:
            json.dump(final_data[:CONFIG['MAX_HISTORY']], f, ensure_ascii=False, indent=2)

        # B. é’‰é’‰æ¨é€
        top_picks = [r for r in new_qualified if r['score'] >= CONFIG['PUSH_THRESHOLD']]
        if top_picks:
            # é™åˆ¶é’‰é’‰æ¨é€æ•°é‡ (ä½¿ç”¨ CONFIG['DINGTALK_PUSH_LIMIT'])
            push_limit = CONFIG['DINGTALK_PUSH_LIMIT']
            push_list = top_picks[:push_limit]
            
            ding_md = "# ğŸ“… ä»Šæ—¥é‡åŒ–è®ºæ–‡æ‘˜è¦\n\n"
            for r in push_list:
                ding_md += f"### {r['title']}\n"
                ding_md += f"**{r['score']}åˆ†** | {r['source']}\n\n"
                ding_md += f"> **ä¸­æ–‡æ‘˜è¦**ï¼š\n> {r['summary']}\n\n"
                ding_md += f"[ğŸ“„ åŸæ–‡é“¾æ¥]({r['url']})\n\n---\n"
            send_dingtalk(ding_md)

        # C. é‚®ä»¶æ¨é€
        email_html = "<h2>ğŸ“… ä»Šæ—¥é‡åŒ–äº¤æ˜“å­¦æœ¯ç²¾é€‰</h2><hr>"
        for r in new_qualified:
            color = "red" if r['score'] >= 8 else "black"
            email_html += f"""
            <div style='margin-bottom:20px; padding:15px; border:1px solid #ddd; border-radius:5px;'>
                <h3 style='margin-top:0'><a href='{r['url']}'>{r['title']}</a> <span style='color:{color}'>({r['score']}åˆ†)</span></h3>
                <p style='color:#666; font-size:12px'>{r['source']} | {r['date']}</p>
                <div style='background:#f9f9f9; padding:10px; border-left:4px solid #1890ff;'>
                    <p style='margin:0; font-weight:bold;'>ğŸ‡¨ğŸ‡³ ä¸­æ–‡æ‘˜è¦ï¼š</p>
                    <p style='margin-top:5px; line-height:1.6;'>{r['summary']}</p>
                </div>
            </div>
            """
        send_email(f"é‡åŒ–æ—¥æŠ¥ ({datetime.date.today()}) - {len(new_qualified)}ç¯‡ AI ç²¾è¯»", email_html)
        
    else:
        print(">>> æ— æ›´æ–°ã€‚")

if __name__ == "__main__":
    main()
